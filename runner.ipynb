{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mmm9886/miniconda3/envs/clrnet/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import cv2\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import pytorch_warmup as warmup\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "\n",
    "from clrnet.models.registry import build_net\n",
    "from clrnet.engine.registry import build_trainer, build_evaluator\n",
    "from clrnet.engine.optimizer import build_optimizer\n",
    "from clrnet.engine.scheduler import build_scheduler\n",
    "from clrnet.datasets import build_dataloader\n",
    "from clrnet.utils.recorder import build_recorder\n",
    "from clrnet.utils.net_utils import save_model, load_network, resume_network\n",
    "from clrnet.utils.recorder import build_recorder\n",
    "from mmcv.parallel import MMDataParallel\n",
    "from nets.nn import DarkNet\n",
    "from utils import util\n",
    "\n",
    "\n",
    "# yolo\n",
    "\n",
    "from utils.dataset import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from clrnet.utils.config import Config\n",
    "\n",
    "cfg = Config.fromfile(\"configs/clrnet/clr_resnet18_culane.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.load_from = None\n",
    "cfg.resume_from = None\n",
    "cfg.finetune_from = None\n",
    "cfg.view = None\n",
    "cfg.seed = 0\n",
    "cfg.gpus = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(cfg.seed)\n",
    "np.random.seed(cfg.seed)\n",
    "random.seed(cfg.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_lane = build_dataloader(cfg.dataset.train,\n",
    "                                        cfg,\n",
    "                                        is_train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7f291911d2b0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader_lane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "parser = argparse.ArgumentParser()\n",
    "args = parser.parse_args(args=[])\n",
    "args.input_size = 640\n",
    "args.batch_size = 32\n",
    "args.local_rank = 0\n",
    "args.world_size = 1\n",
    "args.epoch = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import os\n",
    "import glob\n",
    "from torch.utils import data\n",
    "\n",
    "with open(os.path.join('utils', 'args.yaml'), errors='ignore') as f:\n",
    "    params = yaml.safe_load(f)\n",
    "\n",
    "folder_path = \"/data/bdd100k/images/train2017/\"\n",
    "filenames = glob.glob(os.path.join(folder_path, '*'))\n",
    "\n",
    "train_dataset_obj = Dataset(filenames, args.input_size, params, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_obj = data.DataLoader(train_dataset_obj, 18, False, num_workers=8,\n",
    "                             pin_memory=True, collate_fn=Dataset.collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7f28d40dc730>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = torch.load(\"/home/mmm9886/Desktop/Capstone_Implementation/YOLOv8-pt copy/weights/best.pt\")\n",
    "darknet_backbone = state_dict['model'].net\n",
    "darknet_backbone = darknet_backbone.float()\n",
    "darknet_backbone = darknet_backbone.to(device)\n",
    "darknet_neck = state_dict['model'].fpn\n",
    "darknet_neck = darknet_neck.float()\n",
    "darknet_neck = darknet_neck.to(device)\n",
    "darknet_head = state_dict['model'].head\n",
    "darknet_head = darknet_head.float()\n",
    "darknet_head = darknet_head.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "for params in state_dict['model'].parameters():\n",
    "    print(params.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = torch.load(\"/home/mmm9886/Desktop/Capstone_Implementation/YOLOv8-pt copy 3/weights/best.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pretrained model:  https://download.pytorch.org/models/resnet18-5c106cde.pth\n"
     ]
    }
   ],
   "source": [
    "net = build_net(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Module.parameters at 0x7f28d40cae40>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11774387\n",
      "3011043\n"
     ]
    }
   ],
   "source": [
    "print(sum(p.numel() for p in net.parameters()))\n",
    "print(sum(p.numel() for p in state_dict[\"model\"].parameters()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47097548 6022086\n"
     ]
    }
   ],
   "source": [
    "print(param_size_clrnet, param_size_yolov8n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "130108"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buffer_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CLRHead(\n",
       "  (prior_embeddings): Embedding(192, 3)\n",
       "  (seg_decoder): SegDecoder(\n",
       "    (dropout): Dropout2d(p=0.1, inplace=False)\n",
       "    (conv): Conv2d(192, 5, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (reg_modules): ModuleList(\n",
       "    (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (3): ReLU(inplace=True)\n",
       "  )\n",
       "  (cls_modules): ModuleList(\n",
       "    (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (3): ReLU(inplace=True)\n",
       "  )\n",
       "  (roi_gather): ROIGather(\n",
       "    (f_key): ConvModule(\n",
       "      (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (activate): ReLU(inplace=True)\n",
       "    )\n",
       "    (f_query): Sequential(\n",
       "      (0): Conv1d(192, 192, kernel_size=(1,), stride=(1,), groups=192)\n",
       "      (1): ReLU()\n",
       "    )\n",
       "    (f_value): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (W): Conv1d(192, 192, kernel_size=(1,), stride=(1,), groups=192)\n",
       "    (resize): FeatureResize()\n",
       "    (convs): ModuleList(\n",
       "      (0): ConvModule(\n",
       "        (conv): Conv2d(64, 48, kernel_size=(9, 1), stride=(1, 1), padding=(4, 0), bias=False)\n",
       "        (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activate): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): ConvModule(\n",
       "        (conv): Conv2d(64, 48, kernel_size=(9, 1), stride=(1, 1), padding=(4, 0), bias=False)\n",
       "        (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activate): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): ConvModule(\n",
       "        (conv): Conv2d(64, 48, kernel_size=(9, 1), stride=(1, 1), padding=(4, 0), bias=False)\n",
       "        (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activate): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (catconv): ModuleList(\n",
       "      (0): ConvModule(\n",
       "        (conv): Conv2d(48, 64, kernel_size=(9, 1), stride=(1, 1), padding=(4, 0), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activate): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): ConvModule(\n",
       "        (conv): Conv2d(96, 64, kernel_size=(9, 1), stride=(1, 1), padding=(4, 0), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activate): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): ConvModule(\n",
       "        (conv): Conv2d(144, 64, kernel_size=(9, 1), stride=(1, 1), padding=(4, 0), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activate): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (fc): Linear(in_features=2304, out_features=64, bias=True)\n",
       "    (fc_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (reg_layers): Linear(in_features=64, out_features=76, bias=True)\n",
       "  (cls_layers): Linear(in_features=64, out_features=2, bias=True)\n",
       "  (criterion): NLLLoss()\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections import OrderedDict\n",
    "# state_dict = torch.load('/home/mmm9886/Desktop/Capstone_Implementation/clrnet/work_dirs/clr/r18_culane/20250111_141413_lr_6e-04_b_24/ckpt/9.pth', map_location=torch.device(\"cuda:1\"))\n",
    "# prefix_to_keep = \"module.heads.\"\n",
    "# filtered_od = OrderedDict((k, v) for k, v in state_dict[\"net\"].items() if k.startswith(prefix_to_keep))\n",
    "# filtered_od = {k.replace(\"module.heads.\", \"\"): v for k, v in filtered_od.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "clrnet_head = net.heads\n",
    "# clrnet_head.load_state_dict(filtered_od)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YOLOL(torch.nn.Module):\n",
    "    def __init__(self, backbone, neck, yolo_head, clrhead):\n",
    "        super(YOLOL, self).__init__()\n",
    "        self.backbone = backbone\n",
    "        self.neck = neck\n",
    "        self.yolo_head = yolo_head\n",
    "        self.clrhead = clrhead\n",
    "        \n",
    "        self.offset_2 = torch.nn.Conv2d(512, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "        self.offset_1 = torch.nn.Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) \n",
    "        self.offset_0 = torch.nn.Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "    def forward(self, x, task_id):\n",
    "        # Get the outputs from the neck\n",
    "        out = self.backbone(x['img'] if isinstance(x, dict) else x)\n",
    "        out0, out1, out2 = self.neck(out)\n",
    "        \n",
    "        \n",
    "        # Apply Conv2d layers to each output\n",
    "        if task_id == 0: # lane detection\n",
    "            out0 = self.offset_0(out0)\n",
    "            out1 = self.offset_1(out1)\n",
    "            out2 = self.offset_2(out2)\n",
    "            if self.training:\n",
    "                output = self.clrhead([out0, out1, out2], batch = x)\n",
    "            else:\n",
    "                output = self.clrhead([out0, out1, out2])\n",
    "        else: # object detection\n",
    "            output = self.yolo_head([out0, out1, out2])\n",
    "        \n",
    "        return output\n",
    "    \n",
    "def reset_weights(m):\n",
    "    if isinstance(m, torch.nn.Linear):  # Add other layer types if needed\n",
    "        torch.nn.init.kaiming_normal_(m.weight)  # He initialization\n",
    "        if m.bias is not None:\n",
    "            torch.nn.init.zeros_(m.bias)  # Reset bias to 0\n",
    "        \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from multitask import YOLOL\n",
    "model_pc = YOLOL(darknet_backbone, darknet_neck, darknet_head, clrnet_head)\n",
    "model_pc.load_state_dict(torch.load(\"/home/mmm9886/Desktop/Capstone_Implementation/clrnet/weights/pcgrad_control_v8n_model2_best.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from multitask_cross_stitch import YOLOL\n",
    "model_pc_cs = YOLOL(darknet_backbone, darknet_head, clrnet_head)\n",
    "model_pc_cs_scale = YOLOL(darknet_backbone, darknet_head, clrnet_head)\n",
    "\n",
    "model_pc_cs.load_state_dict(torch.load(\"/home/mmm9886/Desktop/Capstone_Implementation/clrnet/weights/pcgrad_divergentneck_cross_stitch_model2_v8n_best.pt\"))\n",
    "model_pc_cs_scale.load_state_dict(torch.load(\"/home/mmm9886/Desktop/Capstone_Implementation/clrnet/weights/pcgrad_divergentneck_cross_stitch_model_scaled_v8n_best.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from multitask_cross_stitch import YOLOL\n",
    "model_cross_stitch = YOLOL(darknet_backbone, darknet_head, clrnet_head)\n",
    "model_cross_stitch.load_state_dict(torch.load('/home/mmm9886/Desktop/Capstone_Implementation/clrnet/weights/pcgrad_divergentneck_cross_stitch_model_scaled2_v8n_last.pt'))\n",
    "\n",
    "# from multitask import YOLOL\n",
    "# model_control = YOLOL(darknet_backbone, darknet_neck, darknet_head, clrnet_head)\n",
    "# model_control.load_state_dict(torch.load('/home/mmm9886/Desktop/Capstone_Implementation/clrnet/weights/pcgrad_control_v8n_model2_best.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for YOLOL:\n\tMissing key(s) in state_dict: \"backbone.p1.0.conv.weight\", \"backbone.p1.0.norm.weight\", \"backbone.p1.0.norm.bias\", \"backbone.p1.0.norm.running_mean\", \"backbone.p1.0.norm.running_var\", \"backbone.p2.0.conv.weight\", \"backbone.p2.0.norm.weight\", \"backbone.p2.0.norm.bias\", \"backbone.p2.0.norm.running_mean\", \"backbone.p2.0.norm.running_var\", \"backbone.p2.1.conv1.conv.weight\", \"backbone.p2.1.conv1.norm.weight\", \"backbone.p2.1.conv1.norm.bias\", \"backbone.p2.1.conv1.norm.running_mean\", \"backbone.p2.1.conv1.norm.running_var\", \"backbone.p2.1.conv2.conv.weight\", \"backbone.p2.1.conv2.norm.weight\", \"backbone.p2.1.conv2.norm.bias\", \"backbone.p2.1.conv2.norm.running_mean\", \"backbone.p2.1.conv2.norm.running_var\", \"backbone.p2.1.conv3.conv.weight\", \"backbone.p2.1.conv3.norm.weight\", \"backbone.p2.1.conv3.norm.bias\", \"backbone.p2.1.conv3.norm.running_mean\", \"backbone.p2.1.conv3.norm.running_var\", \"backbone.p2.1.res_m.0.res_m.0.conv.weight\", \"backbone.p2.1.res_m.0.res_m.0.norm.weight\", \"backbone.p2.1.res_m.0.res_m.0.norm.bias\", \"backbone.p2.1.res_m.0.res_m.0.norm.running_mean\", \"backbone.p2.1.res_m.0.res_m.0.norm.running_var\", \"backbone.p2.1.res_m.0.res_m.1.conv.weight\", \"backbone.p2.1.res_m.0.res_m.1.norm.weight\", \"backbone.p2.1.res_m.0.res_m.1.norm.bias\", \"backbone.p2.1.res_m.0.res_m.1.norm.running_mean\", \"backbone.p2.1.res_m.0.res_m.1.norm.running_var\", \"backbone.p3.0.conv.weight\", \"backbone.p3.0.norm.weight\", \"backbone.p3.0.norm.bias\", \"backbone.p3.0.norm.running_mean\", \"backbone.p3.0.norm.running_var\", \"backbone.p3.1.conv1.conv.weight\", \"backbone.p3.1.conv1.norm.weight\", \"backbone.p3.1.conv1.norm.bias\", \"backbone.p3.1.conv1.norm.running_mean\", \"backbone.p3.1.conv1.norm.running_var\", \"backbone.p3.1.conv2.conv.weight\", \"backbone.p3.1.conv2.norm.weight\", \"backbone.p3.1.conv2.norm.bias\", \"backbone.p3.1.conv2.norm.running_mean\", \"backbone.p3.1.conv2.norm.running_var\", \"backbone.p3.1.conv3.conv.weight\", \"backbone.p3.1.conv3.norm.weight\", \"backbone.p3.1.conv3.norm.bias\", \"backbone.p3.1.conv3.norm.running_mean\", \"backbone.p3.1.conv3.norm.running_var\", \"backbone.p3.1.res_m.0.res_m.0.conv.weight\", \"backbone.p3.1.res_m.0.res_m.0.norm.weight\", \"backbone.p3.1.res_m.0.res_m.0.norm.bias\", \"backbone.p3.1.res_m.0.res_m.0.norm.running_mean\", \"backbone.p3.1.res_m.0.res_m.0.norm.running_var\", \"backbone.p3.1.res_m.0.res_m.1.conv.weight\", \"backbone.p3.1.res_m.0.res_m.1.norm.weight\", \"backbone.p3.1.res_m.0.res_m.1.norm.bias\", \"backbone.p3.1.res_m.0.res_m.1.norm.running_mean\", \"backbone.p3.1.res_m.0.res_m.1.norm.running_var\", \"backbone.p3.1.res_m.1.res_m.0.conv.weight\", \"backbone.p3.1.res_m.1.res_m.0.norm.weight\", \"backbone.p3.1.res_m.1.res_m.0.norm.bias\", \"backbone.p3.1.res_m.1.res_m.0.norm.running_mean\", \"backbone.p3.1.res_m.1.res_m.0.norm.running_var\", \"backbone.p3.1.res_m.1.res_m.1.conv.weight\", \"backbone.p3.1.res_m.1.res_m.1.norm.weight\", \"backbone.p3.1.res_m.1.res_m.1.norm.bias\", \"backbone.p3.1.res_m.1.res_m.1.norm.running_mean\", \"backbone.p3.1.res_m.1.res_m.1.norm.running_var\", \"backbone.p4.0.conv.weight\", \"backbone.p4.0.norm.weight\", \"backbone.p4.0.norm.bias\", \"backbone.p4.0.norm.running_mean\", \"backbone.p4.0.norm.running_var\", \"backbone.p4.1.conv1.conv.weight\", \"backbone.p4.1.conv1.norm.weight\", \"backbone.p4.1.conv1.norm.bias\", \"backbone.p4.1.conv1.norm.running_mean\", \"backbone.p4.1.conv1.norm.running_var\", \"backbone.p4.1.conv2.conv.weight\", \"backbone.p4.1.conv2.norm.weight\", \"backbone.p4.1.conv2.norm.bias\", \"backbone.p4.1.conv2.norm.running_mean\", \"backbone.p4.1.conv2.norm.running_var\", \"backbone.p4.1.conv3.conv.weight\", \"backbone.p4.1.conv3.norm.weight\", \"backbone.p4.1.conv3.norm.bias\", \"backbone.p4.1.conv3.norm.running_mean\", \"backbone.p4.1.conv3.norm.running_var\", \"backbone.p4.1.res_m.0.res_m.0.conv.weight\", \"backbone.p4.1.res_m.0.res_m.0.norm.weight\", \"backbone.p4.1.res_m.0.res_m.0.norm.bias\", \"backbone.p4.1.res_m.0.res_m.0.norm.running_mean\", \"backbone.p4.1.res_m.0.res_m.0.norm.running_var\", \"backbone.p4.1.res_m.0.res_m.1.conv.weight\", \"backbone.p4.1.res_m.0.res_m.1.norm.weight\", \"backbone.p4.1.res_m.0.res_m.1.norm.bias\", \"backbone.p4.1.res_m.0.res_m.1.norm.running_mean\", \"backbone.p4.1.res_m.0.res_m.1.norm.running_var\", \"backbone.p4.1.res_m.1.res_m.0.conv.weight\", \"backbone.p4.1.res_m.1.res_m.0.norm.weight\", \"backbone.p4.1.res_m.1.res_m.0.norm.bias\", \"backbone.p4.1.res_m.1.res_m.0.norm.running_mean\", \"backbone.p4.1.res_m.1.res_m.0.norm.running_var\", \"backbone.p4.1.res_m.1.res_m.1.conv.weight\", \"backbone.p4.1.res_m.1.res_m.1.norm.weight\", \"backbone.p4.1.res_m.1.res_m.1.norm.bias\", \"backbone.p4.1.res_m.1.res_m.1.norm.running_mean\", \"backbone.p4.1.res_m.1.res_m.1.norm.running_var\", \"backbone.p5.0.conv.weight\", \"backbone.p5.0.norm.weight\", \"backbone.p5.0.norm.bias\", \"backbone.p5.0.norm.running_mean\", \"backbone.p5.0.norm.running_var\", \"backbone.p5.1.conv1.conv.weight\", \"backbone.p5.1.conv1.norm.weight\", \"backbone.p5.1.conv1.norm.bias\", \"backbone.p5.1.conv1.norm.running_mean\", \"backbone.p5.1.conv1.norm.running_var\", \"backbone.p5.1.conv2.conv.weight\", \"backbone.p5.1.conv2.norm.weight\", \"backbone.p5.1.conv2.norm.bias\", \"backbone.p5.1.conv2.norm.running_mean\", \"backbone.p5.1.conv2.norm.running_var\", \"backbone.p5.1.conv3.conv.weight\", \"backbone.p5.1.conv3.norm.weight\", \"backbone.p5.1.conv3.norm.bias\", \"backbone.p5.1.conv3.norm.running_mean\", \"backbone.p5.1.conv3.norm.running_var\", \"backbone.p5.1.res_m.0.res_m.0.conv.weight\", \"backbone.p5.1.res_m.0.res_m.0.norm.weight\", \"backbone.p5.1.res_m.0.res_m.0.norm.bias\", \"backbone.p5.1.res_m.0.res_m.0.norm.running_mean\", \"backbone.p5.1.res_m.0.res_m.0.norm.running_var\", \"backbone.p5.1.res_m.0.res_m.1.conv.weight\", \"backbone.p5.1.res_m.0.res_m.1.norm.weight\", \"backbone.p5.1.res_m.0.res_m.1.norm.bias\", \"backbone.p5.1.res_m.0.res_m.1.norm.running_mean\", \"backbone.p5.1.res_m.0.res_m.1.norm.running_var\", \"backbone.p5.2.conv1.conv.weight\", \"backbone.p5.2.conv1.norm.weight\", \"backbone.p5.2.conv1.norm.bias\", \"backbone.p5.2.conv1.norm.running_mean\", \"backbone.p5.2.conv1.norm.running_var\", \"backbone.p5.2.conv2.conv.weight\", \"backbone.p5.2.conv2.norm.weight\", \"backbone.p5.2.conv2.norm.bias\", \"backbone.p5.2.conv2.norm.running_mean\", \"backbone.p5.2.conv2.norm.running_var\", \"neck.h1.conv1.conv.weight\", \"neck.h1.conv1.norm.weight\", \"neck.h1.conv1.norm.bias\", \"neck.h1.conv1.norm.running_mean\", \"neck.h1.conv1.norm.running_var\", \"neck.h1.conv2.conv.weight\", \"neck.h1.conv2.norm.weight\", \"neck.h1.conv2.norm.bias\", \"neck.h1.conv2.norm.running_mean\", \"neck.h1.conv2.norm.running_var\", \"neck.h1.conv3.conv.weight\", \"neck.h1.conv3.norm.weight\", \"neck.h1.conv3.norm.bias\", \"neck.h1.conv3.norm.running_mean\", \"neck.h1.conv3.norm.running_var\", \"neck.h1.res_m.0.res_m.0.conv.weight\", \"neck.h1.res_m.0.res_m.0.norm.weight\", \"neck.h1.res_m.0.res_m.0.norm.bias\", \"neck.h1.res_m.0.res_m.0.norm.running_mean\", \"neck.h1.res_m.0.res_m.0.norm.running_var\", \"neck.h1.res_m.0.res_m.1.conv.weight\", \"neck.h1.res_m.0.res_m.1.norm.weight\", \"neck.h1.res_m.0.res_m.1.norm.bias\", \"neck.h1.res_m.0.res_m.1.norm.running_mean\", \"neck.h1.res_m.0.res_m.1.norm.running_var\", \"neck.h2.conv1.conv.weight\", \"neck.h2.conv1.norm.weight\", \"neck.h2.conv1.norm.bias\", \"neck.h2.conv1.norm.running_mean\", \"neck.h2.conv1.norm.running_var\", \"neck.h2.conv2.conv.weight\", \"neck.h2.conv2.norm.weight\", \"neck.h2.conv2.norm.bias\", \"neck.h2.conv2.norm.running_mean\", \"neck.h2.conv2.norm.running_var\", \"neck.h2.conv3.conv.weight\", \"neck.h2.conv3.norm.weight\", \"neck.h2.conv3.norm.bias\", \"neck.h2.conv3.norm.running_mean\", \"neck.h2.conv3.norm.running_var\", \"neck.h2.res_m.0.res_m.0.conv.weight\", \"neck.h2.res_m.0.res_m.0.norm.weight\", \"neck.h2.res_m.0.res_m.0.norm.bias\", \"neck.h2.res_m.0.res_m.0.norm.running_mean\", \"neck.h2.res_m.0.res_m.0.norm.running_var\", \"neck.h2.res_m.0.res_m.1.conv.weight\", \"neck.h2.res_m.0.res_m.1.norm.weight\", \"neck.h2.res_m.0.res_m.1.norm.bias\", \"neck.h2.res_m.0.res_m.1.norm.running_mean\", \"neck.h2.res_m.0.res_m.1.norm.running_var\", \"neck.h3.conv.weight\", \"neck.h3.norm.weight\", \"neck.h3.norm.bias\", \"neck.h3.norm.running_mean\", \"neck.h3.norm.running_var\", \"neck.h4.conv1.conv.weight\", \"neck.h4.conv1.norm.weight\", \"neck.h4.conv1.norm.bias\", \"neck.h4.conv1.norm.running_mean\", \"neck.h4.conv1.norm.running_var\", \"neck.h4.conv2.conv.weight\", \"neck.h4.conv2.norm.weight\", \"neck.h4.conv2.norm.bias\", \"neck.h4.conv2.norm.running_mean\", \"neck.h4.conv2.norm.running_var\", \"neck.h4.conv3.conv.weight\", \"neck.h4.conv3.norm.weight\", \"neck.h4.conv3.norm.bias\", \"neck.h4.conv3.norm.running_mean\", \"neck.h4.conv3.norm.running_var\", \"neck.h4.res_m.0.res_m.0.conv.weight\", \"neck.h4.res_m.0.res_m.0.norm.weight\", \"neck.h4.res_m.0.res_m.0.norm.bias\", \"neck.h4.res_m.0.res_m.0.norm.running_mean\", \"neck.h4.res_m.0.res_m.0.norm.running_var\", \"neck.h4.res_m.0.res_m.1.conv.weight\", \"neck.h4.res_m.0.res_m.1.norm.weight\", \"neck.h4.res_m.0.res_m.1.norm.bias\", \"neck.h4.res_m.0.res_m.1.norm.running_mean\", \"neck.h4.res_m.0.res_m.1.norm.running_var\", \"neck.h5.conv.weight\", \"neck.h5.norm.weight\", \"neck.h5.norm.bias\", \"neck.h5.norm.running_mean\", \"neck.h5.norm.running_var\", \"neck.h6.conv1.conv.weight\", \"neck.h6.conv1.norm.weight\", \"neck.h6.conv1.norm.bias\", \"neck.h6.conv1.norm.running_mean\", \"neck.h6.conv1.norm.running_var\", \"neck.h6.conv2.conv.weight\", \"neck.h6.conv2.norm.weight\", \"neck.h6.conv2.norm.bias\", \"neck.h6.conv2.norm.running_mean\", \"neck.h6.conv2.norm.running_var\", \"neck.h6.conv3.conv.weight\", \"neck.h6.conv3.norm.weight\", \"neck.h6.conv3.norm.bias\", \"neck.h6.conv3.norm.running_mean\", \"neck.h6.conv3.norm.running_var\", \"neck.h6.res_m.0.res_m.0.conv.weight\", \"neck.h6.res_m.0.res_m.0.norm.weight\", \"neck.h6.res_m.0.res_m.0.norm.bias\", \"neck.h6.res_m.0.res_m.0.norm.running_mean\", \"neck.h6.res_m.0.res_m.0.norm.running_var\", \"neck.h6.res_m.0.res_m.1.conv.weight\", \"neck.h6.res_m.0.res_m.1.norm.weight\", \"neck.h6.res_m.0.res_m.1.norm.bias\", \"neck.h6.res_m.0.res_m.1.norm.running_mean\", \"neck.h6.res_m.0.res_m.1.norm.running_var\", \"yolo_head.dfl.conv.weight\", \"yolo_head.cls.0.0.conv.weight\", \"yolo_head.cls.0.0.norm.weight\", \"yolo_head.cls.0.0.norm.bias\", \"yolo_head.cls.0.0.norm.running_mean\", \"yolo_head.cls.0.0.norm.running_var\", \"yolo_head.cls.0.1.conv.weight\", \"yolo_head.cls.0.1.norm.weight\", \"yolo_head.cls.0.1.norm.bias\", \"yolo_head.cls.0.1.norm.running_mean\", \"yolo_head.cls.0.1.norm.running_var\", \"yolo_head.cls.0.2.weight\", \"yolo_head.cls.0.2.bias\", \"yolo_head.cls.1.0.conv.weight\", \"yolo_head.cls.1.0.norm.weight\", \"yolo_head.cls.1.0.norm.bias\", \"yolo_head.cls.1.0.norm.running_mean\", \"yolo_head.cls.1.0.norm.running_var\", \"yolo_head.cls.1.1.conv.weight\", \"yolo_head.cls.1.1.norm.weight\", \"yolo_head.cls.1.1.norm.bias\", \"yolo_head.cls.1.1.norm.running_mean\", \"yolo_head.cls.1.1.norm.running_var\", \"yolo_head.cls.1.2.weight\", \"yolo_head.cls.1.2.bias\", \"yolo_head.cls.2.0.conv.weight\", \"yolo_head.cls.2.0.norm.weight\", \"yolo_head.cls.2.0.norm.bias\", \"yolo_head.cls.2.0.norm.running_mean\", \"yolo_head.cls.2.0.norm.running_var\", \"yolo_head.cls.2.1.conv.weight\", \"yolo_head.cls.2.1.norm.weight\", \"yolo_head.cls.2.1.norm.bias\", \"yolo_head.cls.2.1.norm.running_mean\", \"yolo_head.cls.2.1.norm.running_var\", \"yolo_head.cls.2.2.weight\", \"yolo_head.cls.2.2.bias\", \"yolo_head.box.0.0.conv.weight\", \"yolo_head.box.0.0.norm.weight\", \"yolo_head.box.0.0.norm.bias\", \"yolo_head.box.0.0.norm.running_mean\", \"yolo_head.box.0.0.norm.running_var\", \"yolo_head.box.0.1.conv.weight\", \"yolo_head.box.0.1.norm.weight\", \"yolo_head.box.0.1.norm.bias\", \"yolo_head.box.0.1.norm.running_mean\", \"yolo_head.box.0.1.norm.running_var\", \"yolo_head.box.0.2.weight\", \"yolo_head.box.0.2.bias\", \"yolo_head.box.1.0.conv.weight\", \"yolo_head.box.1.0.norm.weight\", \"yolo_head.box.1.0.norm.bias\", \"yolo_head.box.1.0.norm.running_mean\", \"yolo_head.box.1.0.norm.running_var\", \"yolo_head.box.1.1.conv.weight\", \"yolo_head.box.1.1.norm.weight\", \"yolo_head.box.1.1.norm.bias\", \"yolo_head.box.1.1.norm.running_mean\", \"yolo_head.box.1.1.norm.running_var\", \"yolo_head.box.1.2.weight\", \"yolo_head.box.1.2.bias\", \"yolo_head.box.2.0.conv.weight\", \"yolo_head.box.2.0.norm.weight\", \"yolo_head.box.2.0.norm.bias\", \"yolo_head.box.2.0.norm.running_mean\", \"yolo_head.box.2.0.norm.running_var\", \"yolo_head.box.2.1.conv.weight\", \"yolo_head.box.2.1.norm.weight\", \"yolo_head.box.2.1.norm.bias\", \"yolo_head.box.2.1.norm.running_mean\", \"yolo_head.box.2.1.norm.running_var\", \"yolo_head.box.2.2.weight\", \"yolo_head.box.2.2.bias\", \"clrhead.sample_x_indexs\", \"clrhead.prior_feat_ys\", \"clrhead.prior_ys\", \"clrhead.priors\", \"clrhead.priors_on_featmap\", \"clrhead.prior_embeddings.weight\", \"clrhead.seg_decoder.conv.weight\", \"clrhead.seg_decoder.conv.bias\", \"clrhead.reg_modules.0.weight\", \"clrhead.reg_modules.0.bias\", \"clrhead.reg_modules.2.weight\", \"clrhead.reg_modules.2.bias\", \"clrhead.cls_modules.0.weight\", \"clrhead.cls_modules.0.bias\", \"clrhead.cls_modules.2.weight\", \"clrhead.cls_modules.2.bias\", \"clrhead.roi_gather.f_key.conv.weight\", \"clrhead.roi_gather.f_key.bn.weight\", \"clrhead.roi_gather.f_key.bn.bias\", \"clrhead.roi_gather.f_key.bn.running_mean\", \"clrhead.roi_gather.f_key.bn.running_var\", \"clrhead.roi_gather.f_query.0.weight\", \"clrhead.roi_gather.f_query.0.bias\", \"clrhead.roi_gather.f_value.weight\", \"clrhead.roi_gather.f_value.bias\", \"clrhead.roi_gather.W.weight\", \"clrhead.roi_gather.W.bias\", \"clrhead.roi_gather.convs.0.conv.weight\", \"clrhead.roi_gather.convs.0.bn.weight\", \"clrhead.roi_gather.convs.0.bn.bias\", \"clrhead.roi_gather.convs.0.bn.running_mean\", \"clrhead.roi_gather.convs.0.bn.running_var\", \"clrhead.roi_gather.convs.1.conv.weight\", \"clrhead.roi_gather.convs.1.bn.weight\", \"clrhead.roi_gather.convs.1.bn.bias\", \"clrhead.roi_gather.convs.1.bn.running_mean\", \"clrhead.roi_gather.convs.1.bn.running_var\", \"clrhead.roi_gather.convs.2.conv.weight\", \"clrhead.roi_gather.convs.2.bn.weight\", \"clrhead.roi_gather.convs.2.bn.bias\", \"clrhead.roi_gather.convs.2.bn.running_mean\", \"clrhead.roi_gather.convs.2.bn.running_var\", \"clrhead.roi_gather.catconv.0.conv.weight\", \"clrhead.roi_gather.catconv.0.bn.weight\", \"clrhead.roi_gather.catconv.0.bn.bias\", \"clrhead.roi_gather.catconv.0.bn.running_mean\", \"clrhead.roi_gather.catconv.0.bn.running_var\", \"clrhead.roi_gather.catconv.1.conv.weight\", \"clrhead.roi_gather.catconv.1.bn.weight\", \"clrhead.roi_gather.catconv.1.bn.bias\", \"clrhead.roi_gather.catconv.1.bn.running_mean\", \"clrhead.roi_gather.catconv.1.bn.running_var\", \"clrhead.roi_gather.catconv.2.conv.weight\", \"clrhead.roi_gather.catconv.2.bn.weight\", \"clrhead.roi_gather.catconv.2.bn.bias\", \"clrhead.roi_gather.catconv.2.bn.running_mean\", \"clrhead.roi_gather.catconv.2.bn.running_var\", \"clrhead.roi_gather.fc.weight\", \"clrhead.roi_gather.fc.bias\", \"clrhead.roi_gather.fc_norm.weight\", \"clrhead.roi_gather.fc_norm.bias\", \"clrhead.reg_layers.weight\", \"clrhead.reg_layers.bias\", \"clrhead.cls_layers.weight\", \"clrhead.cls_layers.bias\", \"clrhead.criterion.weight\", \"offset_2.weight\", \"offset_1.weight\", \"offset_0.weight\". \n\tUnexpected key(s) in state_dict: \"module.backbone.p1.0.conv.weight\", \"module.backbone.p1.0.norm.weight\", \"module.backbone.p1.0.norm.bias\", \"module.backbone.p1.0.norm.running_mean\", \"module.backbone.p1.0.norm.running_var\", \"module.backbone.p1.0.norm.num_batches_tracked\", \"module.backbone.p2.0.conv.weight\", \"module.backbone.p2.0.norm.weight\", \"module.backbone.p2.0.norm.bias\", \"module.backbone.p2.0.norm.running_mean\", \"module.backbone.p2.0.norm.running_var\", \"module.backbone.p2.0.norm.num_batches_tracked\", \"module.backbone.p2.1.conv1.conv.weight\", \"module.backbone.p2.1.conv1.norm.weight\", \"module.backbone.p2.1.conv1.norm.bias\", \"module.backbone.p2.1.conv1.norm.running_mean\", \"module.backbone.p2.1.conv1.norm.running_var\", \"module.backbone.p2.1.conv1.norm.num_batches_tracked\", \"module.backbone.p2.1.conv2.conv.weight\", \"module.backbone.p2.1.conv2.norm.weight\", \"module.backbone.p2.1.conv2.norm.bias\", \"module.backbone.p2.1.conv2.norm.running_mean\", \"module.backbone.p2.1.conv2.norm.running_var\", \"module.backbone.p2.1.conv2.norm.num_batches_tracked\", \"module.backbone.p2.1.conv3.conv.weight\", \"module.backbone.p2.1.conv3.norm.weight\", \"module.backbone.p2.1.conv3.norm.bias\", \"module.backbone.p2.1.conv3.norm.running_mean\", \"module.backbone.p2.1.conv3.norm.running_var\", \"module.backbone.p2.1.conv3.norm.num_batches_tracked\", \"module.backbone.p2.1.res_m.0.res_m.0.conv.weight\", \"module.backbone.p2.1.res_m.0.res_m.0.norm.weight\", \"module.backbone.p2.1.res_m.0.res_m.0.norm.bias\", \"module.backbone.p2.1.res_m.0.res_m.0.norm.running_mean\", \"module.backbone.p2.1.res_m.0.res_m.0.norm.running_var\", \"module.backbone.p2.1.res_m.0.res_m.0.norm.num_batches_tracked\", \"module.backbone.p2.1.res_m.0.res_m.1.conv.weight\", \"module.backbone.p2.1.res_m.0.res_m.1.norm.weight\", \"module.backbone.p2.1.res_m.0.res_m.1.norm.bias\", \"module.backbone.p2.1.res_m.0.res_m.1.norm.running_mean\", \"module.backbone.p2.1.res_m.0.res_m.1.norm.running_var\", \"module.backbone.p2.1.res_m.0.res_m.1.norm.num_batches_tracked\", \"module.backbone.p3.0.conv.weight\", \"module.backbone.p3.0.norm.weight\", \"module.backbone.p3.0.norm.bias\", \"module.backbone.p3.0.norm.running_mean\", \"module.backbone.p3.0.norm.running_var\", \"module.backbone.p3.0.norm.num_batches_tracked\", \"module.backbone.p3.1.conv1.conv.weight\", \"module.backbone.p3.1.conv1.norm.weight\", \"module.backbone.p3.1.conv1.norm.bias\", \"module.backbone.p3.1.conv1.norm.running_mean\", \"module.backbone.p3.1.conv1.norm.running_var\", \"module.backbone.p3.1.conv1.norm.num_batches_tracked\", \"module.backbone.p3.1.conv2.conv.weight\", \"module.backbone.p3.1.conv2.norm.weight\", \"module.backbone.p3.1.conv2.norm.bias\", \"module.backbone.p3.1.conv2.norm.running_mean\", \"module.backbone.p3.1.conv2.norm.running_var\", \"module.backbone.p3.1.conv2.norm.num_batches_tracked\", \"module.backbone.p3.1.conv3.conv.weight\", \"module.backbone.p3.1.conv3.norm.weight\", \"module.backbone.p3.1.conv3.norm.bias\", \"module.backbone.p3.1.conv3.norm.running_mean\", \"module.backbone.p3.1.conv3.norm.running_var\", \"module.backbone.p3.1.conv3.norm.num_batches_tracked\", \"module.backbone.p3.1.res_m.0.res_m.0.conv.weight\", \"module.backbone.p3.1.res_m.0.res_m.0.norm.weight\", \"module.backbone.p3.1.res_m.0.res_m.0.norm.bias\", \"module.backbone.p3.1.res_m.0.res_m.0.norm.running_mean\", \"module.backbone.p3.1.res_m.0.res_m.0.norm.running_var\", \"module.backbone.p3.1.res_m.0.res_m.0.norm.num_batches_tracked\", \"module.backbone.p3.1.res_m.0.res_m.1.conv.weight\", \"module.backbone.p3.1.res_m.0.res_m.1.norm.weight\", \"module.backbone.p3.1.res_m.0.res_m.1.norm.bias\", \"module.backbone.p3.1.res_m.0.res_m.1.norm.running_mean\", \"module.backbone.p3.1.res_m.0.res_m.1.norm.running_var\", \"module.backbone.p3.1.res_m.0.res_m.1.norm.num_batches_tracked\", \"module.backbone.p3.1.res_m.1.res_m.0.conv.weight\", \"module.backbone.p3.1.res_m.1.res_m.0.norm.weight\", \"module.backbone.p3.1.res_m.1.res_m.0.norm.bias\", \"module.backbone.p3.1.res_m.1.res_m.0.norm.running_mean\", \"module.backbone.p3.1.res_m.1.res_m.0.norm.running_var\", \"module.backbone.p3.1.res_m.1.res_m.0.norm.num_batches_tracked\", \"module.backbone.p3.1.res_m.1.res_m.1.conv.weight\", \"module.backbone.p3.1.res_m.1.res_m.1.norm.weight\", \"module.backbone.p3.1.res_m.1.res_m.1.norm.bias\", \"module.backbone.p3.1.res_m.1.res_m.1.norm.running_mean\", \"module.backbone.p3.1.res_m.1.res_m.1.norm.running_var\", \"module.backbone.p3.1.res_m.1.res_m.1.norm.num_batches_tracked\", \"module.backbone.p4.0.conv.weight\", \"module.backbone.p4.0.norm.weight\", \"module.backbone.p4.0.norm.bias\", \"module.backbone.p4.0.norm.running_mean\", \"module.backbone.p4.0.norm.running_var\", \"module.backbone.p4.0.norm.num_batches_tracked\", \"module.backbone.p4.1.conv1.conv.weight\", \"module.backbone.p4.1.conv1.norm.weight\", \"module.backbone.p4.1.conv1.norm.bias\", \"module.backbone.p4.1.conv1.norm.running_mean\", \"module.backbone.p4.1.conv1.norm.running_var\", \"module.backbone.p4.1.conv1.norm.num_batches_tracked\", \"module.backbone.p4.1.conv2.conv.weight\", \"module.backbone.p4.1.conv2.norm.weight\", \"module.backbone.p4.1.conv2.norm.bias\", \"module.backbone.p4.1.conv2.norm.running_mean\", \"module.backbone.p4.1.conv2.norm.running_var\", \"module.backbone.p4.1.conv2.norm.num_batches_tracked\", \"module.backbone.p4.1.conv3.conv.weight\", \"module.backbone.p4.1.conv3.norm.weight\", \"module.backbone.p4.1.conv3.norm.bias\", \"module.backbone.p4.1.conv3.norm.running_mean\", \"module.backbone.p4.1.conv3.norm.running_var\", \"module.backbone.p4.1.conv3.norm.num_batches_tracked\", \"module.backbone.p4.1.res_m.0.res_m.0.conv.weight\", \"module.backbone.p4.1.res_m.0.res_m.0.norm.weight\", \"module.backbone.p4.1.res_m.0.res_m.0.norm.bias\", \"module.backbone.p4.1.res_m.0.res_m.0.norm.running_mean\", \"module.backbone.p4.1.res_m.0.res_m.0.norm.running_var\", \"module.backbone.p4.1.res_m.0.res_m.0.norm.num_batches_tracked\", \"module.backbone.p4.1.res_m.0.res_m.1.conv.weight\", \"module.backbone.p4.1.res_m.0.res_m.1.norm.weight\", \"module.backbone.p4.1.res_m.0.res_m.1.norm.bias\", \"module.backbone.p4.1.res_m.0.res_m.1.norm.running_mean\", \"module.backbone.p4.1.res_m.0.res_m.1.norm.running_var\", \"module.backbone.p4.1.res_m.0.res_m.1.norm.num_batches_tracked\", \"module.backbone.p4.1.res_m.1.res_m.0.conv.weight\", \"module.backbone.p4.1.res_m.1.res_m.0.norm.weight\", \"module.backbone.p4.1.res_m.1.res_m.0.norm.bias\", \"module.backbone.p4.1.res_m.1.res_m.0.norm.running_mean\", \"module.backbone.p4.1.res_m.1.res_m.0.norm.running_var\", \"module.backbone.p4.1.res_m.1.res_m.0.norm.num_batches_tracked\", \"module.backbone.p4.1.res_m.1.res_m.1.conv.weight\", \"module.backbone.p4.1.res_m.1.res_m.1.norm.weight\", \"module.backbone.p4.1.res_m.1.res_m.1.norm.bias\", \"module.backbone.p4.1.res_m.1.res_m.1.norm.running_mean\", \"module.backbone.p4.1.res_m.1.res_m.1.norm.running_var\", \"module.backbone.p4.1.res_m.1.res_m.1.norm.num_batches_tracked\", \"module.backbone.p5.0.conv.weight\", \"module.backbone.p5.0.norm.weight\", \"module.backbone.p5.0.norm.bias\", \"module.backbone.p5.0.norm.running_mean\", \"module.backbone.p5.0.norm.running_var\", \"module.backbone.p5.0.norm.num_batches_tracked\", \"module.backbone.p5.1.conv1.conv.weight\", \"module.backbone.p5.1.conv1.norm.weight\", \"module.backbone.p5.1.conv1.norm.bias\", \"module.backbone.p5.1.conv1.norm.running_mean\", \"module.backbone.p5.1.conv1.norm.running_var\", \"module.backbone.p5.1.conv1.norm.num_batches_tracked\", \"module.backbone.p5.1.conv2.conv.weight\", \"module.backbone.p5.1.conv2.norm.weight\", \"module.backbone.p5.1.conv2.norm.bias\", \"module.backbone.p5.1.conv2.norm.running_mean\", \"module.backbone.p5.1.conv2.norm.running_var\", \"module.backbone.p5.1.conv2.norm.num_batches_tracked\", \"module.backbone.p5.1.conv3.conv.weight\", \"module.backbone.p5.1.conv3.norm.weight\", \"module.backbone.p5.1.conv3.norm.bias\", \"module.backbone.p5.1.conv3.norm.running_mean\", \"module.backbone.p5.1.conv3.norm.running_var\", \"module.backbone.p5.1.conv3.norm.num_batches_tracked\", \"module.backbone.p5.1.res_m.0.res_m.0.conv.weight\", \"module.backbone.p5.1.res_m.0.res_m.0.norm.weight\", \"module.backbone.p5.1.res_m.0.res_m.0.norm.bias\", \"module.backbone.p5.1.res_m.0.res_m.0.norm.running_mean\", \"module.backbone.p5.1.res_m.0.res_m.0.norm.running_var\", \"module.backbone.p5.1.res_m.0.res_m.0.norm.num_batches_tracked\", \"module.backbone.p5.1.res_m.0.res_m.1.conv.weight\", \"module.backbone.p5.1.res_m.0.res_m.1.norm.weight\", \"module.backbone.p5.1.res_m.0.res_m.1.norm.bias\", \"module.backbone.p5.1.res_m.0.res_m.1.norm.running_mean\", \"module.backbone.p5.1.res_m.0.res_m.1.norm.running_var\", \"module.backbone.p5.1.res_m.0.res_m.1.norm.num_batches_tracked\", \"module.backbone.p5.2.conv1.conv.weight\", \"module.backbone.p5.2.conv1.norm.weight\", \"module.backbone.p5.2.conv1.norm.bias\", \"module.backbone.p5.2.conv1.norm.running_mean\", \"module.backbone.p5.2.conv1.norm.running_var\", \"module.backbone.p5.2.conv1.norm.num_batches_tracked\", \"module.backbone.p5.2.conv2.conv.weight\", \"module.backbone.p5.2.conv2.norm.weight\", \"module.backbone.p5.2.conv2.norm.bias\", \"module.backbone.p5.2.conv2.norm.running_mean\", \"module.backbone.p5.2.conv2.norm.running_var\", \"module.backbone.p5.2.conv2.norm.num_batches_tracked\", \"module.neck.neck.h1.conv1.conv.weight\", \"module.neck.neck.h1.conv1.norm.weight\", \"module.neck.neck.h1.conv1.norm.bias\", \"module.neck.neck.h1.conv1.norm.running_mean\", \"module.neck.neck.h1.conv1.norm.running_var\", \"module.neck.neck.h1.conv1.norm.num_batches_tracked\", \"module.neck.neck.h1.conv2.conv.weight\", \"module.neck.neck.h1.conv2.norm.weight\", \"module.neck.neck.h1.conv2.norm.bias\", \"module.neck.neck.h1.conv2.norm.running_mean\", \"module.neck.neck.h1.conv2.norm.running_var\", \"module.neck.neck.h1.conv2.norm.num_batches_tracked\", \"module.neck.neck.h1.conv3.conv.weight\", \"module.neck.neck.h1.conv3.norm.weight\", \"module.neck.neck.h1.conv3.norm.bias\", \"module.neck.neck.h1.conv3.norm.running_mean\", \"module.neck.neck.h1.conv3.norm.running_var\", \"module.neck.neck.h1.conv3.norm.num_batches_tracked\", \"module.neck.neck.h1.res_m.0.res_m.0.conv.weight\", \"module.neck.neck.h1.res_m.0.res_m.0.norm.weight\", \"module.neck.neck.h1.res_m.0.res_m.0.norm.bias\", \"module.neck.neck.h1.res_m.0.res_m.0.norm.running_mean\", \"module.neck.neck.h1.res_m.0.res_m.0.norm.running_var\", \"module.neck.neck.h1.res_m.0.res_m.0.norm.num_batches_tracked\", \"module.neck.neck.h1.res_m.0.res_m.1.conv.weight\", \"module.neck.neck.h1.res_m.0.res_m.1.norm.weight\", \"module.neck.neck.h1.res_m.0.res_m.1.norm.bias\", \"module.neck.neck.h1.res_m.0.res_m.1.norm.running_mean\", \"module.neck.neck.h1.res_m.0.res_m.1.norm.running_var\", \"module.neck.neck.h1.res_m.0.res_m.1.norm.num_batches_tracked\", \"module.neck.neck.h2.conv1.conv.weight\", \"module.neck.neck.h2.conv1.norm.weight\", \"module.neck.neck.h2.conv1.norm.bias\", \"module.neck.neck.h2.conv1.norm.running_mean\", \"module.neck.neck.h2.conv1.norm.running_var\", \"module.neck.neck.h2.conv1.norm.num_batches_tracked\", \"module.neck.neck.h2.conv2.conv.weight\", \"module.neck.neck.h2.conv2.norm.weight\", \"module.neck.neck.h2.conv2.norm.bias\", \"module.neck.neck.h2.conv2.norm.running_mean\", \"module.neck.neck.h2.conv2.norm.running_var\", \"module.neck.neck.h2.conv2.norm.num_batches_tracked\", \"module.neck.neck.h2.conv3.conv.weight\", \"module.neck.neck.h2.conv3.norm.weight\", \"module.neck.neck.h2.conv3.norm.bias\", \"module.neck.neck.h2.conv3.norm.running_mean\", \"module.neck.neck.h2.conv3.norm.running_var\", \"module.neck.neck.h2.conv3.norm.num_batches_tracked\", \"module.neck.neck.h2.res_m.0.res_m.0.conv.weight\", \"module.neck.neck.h2.res_m.0.res_m.0.norm.weight\", \"module.neck.neck.h2.res_m.0.res_m.0.norm.bias\", \"module.neck.neck.h2.res_m.0.res_m.0.norm.running_mean\", \"module.neck.neck.h2.res_m.0.res_m.0.norm.running_var\", \"module.neck.neck.h2.res_m.0.res_m.0.norm.num_batches_tracked\", \"module.neck.neck.h2.res_m.0.res_m.1.conv.weight\", \"module.neck.neck.h2.res_m.0.res_m.1.norm.weight\", \"module.neck.neck.h2.res_m.0.res_m.1.norm.bias\", \"module.neck.neck.h2.res_m.0.res_m.1.norm.running_mean\", \"module.neck.neck.h2.res_m.0.res_m.1.norm.running_var\", \"module.neck.neck.h2.res_m.0.res_m.1.norm.num_batches_tracked\", \"module.neck.neck.h3.conv.weight\", \"module.neck.neck.h3.norm.weight\", \"module.neck.neck.h3.norm.bias\", \"module.neck.neck.h3.norm.running_mean\", \"module.neck.neck.h3.norm.running_var\", \"module.neck.neck.h3.norm.num_batches_tracked\", \"module.neck.neck.h4.conv1.conv.weight\", \"module.neck.neck.h4.conv1.norm.weight\", \"module.neck.neck.h4.conv1.norm.bias\", \"module.neck.neck.h4.conv1.norm.running_mean\", \"module.neck.neck.h4.conv1.norm.running_var\", \"module.neck.neck.h4.conv1.norm.num_batches_tracked\", \"module.neck.neck.h4.conv2.conv.weight\", \"module.neck.neck.h4.conv2.norm.weight\", \"module.neck.neck.h4.conv2.norm.bias\", \"module.neck.neck.h4.conv2.norm.running_mean\", \"module.neck.neck.h4.conv2.norm.running_var\", \"module.neck.neck.h4.conv2.norm.num_batches_tracked\", \"module.neck.neck.h4.conv3.conv.weight\", \"module.neck.neck.h4.conv3.norm.weight\", \"module.neck.neck.h4.conv3.norm.bias\", \"module.neck.neck.h4.conv3.norm.running_mean\", \"module.neck.neck.h4.conv3.norm.running_var\", \"module.neck.neck.h4.conv3.norm.num_batches_tracked\", \"module.neck.neck.h4.res_m.0.res_m.0.conv.weight\", \"module.neck.neck.h4.res_m.0.res_m.0.norm.weight\", \"module.neck.neck.h4.res_m.0.res_m.0.norm.bias\", \"module.neck.neck.h4.res_m.0.res_m.0.norm.running_mean\", \"module.neck.neck.h4.res_m.0.res_m.0.norm.running_var\", \"module.neck.neck.h4.res_m.0.res_m.0.norm.num_batches_tracked\", \"module.neck.neck.h4.res_m.0.res_m.1.conv.weight\", \"module.neck.neck.h4.res_m.0.res_m.1.norm.weight\", \"module.neck.neck.h4.res_m.0.res_m.1.norm.bias\", \"module.neck.neck.h4.res_m.0.res_m.1.norm.running_mean\", \"module.neck.neck.h4.res_m.0.res_m.1.norm.running_var\", \"module.neck.neck.h4.res_m.0.res_m.1.norm.num_batches_tracked\", \"module.neck.neck.h5.conv.weight\", \"module.neck.neck.h5.norm.weight\", \"module.neck.neck.h5.norm.bias\", \"module.neck.neck.h5.norm.running_mean\", \"module.neck.neck.h5.norm.running_var\", \"module.neck.neck.h5.norm.num_batches_tracked\", \"module.neck.neck.h6.conv1.conv.weight\", \"module.neck.neck.h6.conv1.norm.weight\", \"module.neck.neck.h6.conv1.norm.bias\", \"module.neck.neck.h6.conv1.norm.running_mean\", \"module.neck.neck.h6.conv1.norm.running_var\", \"module.neck.neck.h6.conv1.norm.num_batches_tracked\", \"module.neck.neck.h6.conv2.conv.weight\", \"module.neck.neck.h6.conv2.norm.weight\", \"module.neck.neck.h6.conv2.norm.bias\", \"module.neck.neck.h6.conv2.norm.running_mean\", \"module.neck.neck.h6.conv2.norm.running_var\", \"module.neck.neck.h6.conv2.norm.num_batches_tracked\", \"module.neck.neck.h6.conv3.conv.weight\", \"module.neck.neck.h6.conv3.norm.weight\", \"module.neck.neck.h6.conv3.norm.bias\", \"module.neck.neck.h6.conv3.norm.running_mean\", \"module.neck.neck.h6.conv3.norm.running_var\", \"module.neck.neck.h6.conv3.norm.num_batches_tracked\", \"module.neck.neck.h6.res_m.0.res_m.0.conv.weight\", \"module.neck.neck.h6.res_m.0.res_m.0.norm.weight\", \"module.neck.neck.h6.res_m.0.res_m.0.norm.bias\", \"module.neck.neck.h6.res_m.0.res_m.0.norm.running_mean\", \"module.neck.neck.h6.res_m.0.res_m.0.norm.running_var\", \"module.neck.neck.h6.res_m.0.res_m.0.norm.num_batches_tracked\", \"module.neck.neck.h6.res_m.0.res_m.1.conv.weight\", \"module.neck.neck.h6.res_m.0.res_m.1.norm.weight\", \"module.neck.neck.h6.res_m.0.res_m.1.norm.bias\", \"module.neck.neck.h6.res_m.0.res_m.1.norm.running_mean\", \"module.neck.neck.h6.res_m.0.res_m.1.norm.running_var\", \"module.neck.neck.h6.res_m.0.res_m.1.norm.num_batches_tracked\", \"module.neck.offset_2.weight\", \"module.neck.offset_1.weight\", \"module.neck.offset_0.weight\", \"module.heads.sample_x_indexs\", \"module.heads.prior_feat_ys\", \"module.heads.prior_ys\", \"module.heads.priors\", \"module.heads.priors_on_featmap\", \"module.heads.prior_embeddings.weight\", \"module.heads.seg_decoder.conv.weight\", \"module.heads.seg_decoder.conv.bias\", \"module.heads.reg_modules.0.weight\", \"module.heads.reg_modules.0.bias\", \"module.heads.reg_modules.2.weight\", \"module.heads.reg_modules.2.bias\", \"module.heads.cls_modules.0.weight\", \"module.heads.cls_modules.0.bias\", \"module.heads.cls_modules.2.weight\", \"module.heads.cls_modules.2.bias\", \"module.heads.roi_gather.f_key.conv.weight\", \"module.heads.roi_gather.f_key.bn.weight\", \"module.heads.roi_gather.f_key.bn.bias\", \"module.heads.roi_gather.f_key.bn.running_mean\", \"module.heads.roi_gather.f_key.bn.running_var\", \"module.heads.roi_gather.f_key.bn.num_batches_tracked\", \"module.heads.roi_gather.f_query.0.weight\", \"module.heads.roi_gather.f_query.0.bias\", \"module.heads.roi_gather.f_value.weight\", \"module.heads.roi_gather.f_value.bias\", \"module.heads.roi_gather.W.weight\", \"module.heads.roi_gather.W.bias\", \"module.heads.roi_gather.convs.0.conv.weight\", \"module.heads.roi_gather.convs.0.bn.weight\", \"module.heads.roi_gather.convs.0.bn.bias\", \"module.heads.roi_gather.convs.0.bn.running_mean\", \"module.heads.roi_gather.convs.0.bn.running_var\", \"module.heads.roi_gather.convs.0.bn.num_batches_tracked\", \"module.heads.roi_gather.convs.1.conv.weight\", \"module.heads.roi_gather.convs.1.bn.weight\", \"module.heads.roi_gather.convs.1.bn.bias\", \"module.heads.roi_gather.convs.1.bn.running_mean\", \"module.heads.roi_gather.convs.1.bn.running_var\", \"module.heads.roi_gather.convs.1.bn.num_batches_tracked\", \"module.heads.roi_gather.convs.2.conv.weight\", \"module.heads.roi_gather.convs.2.bn.weight\", \"module.heads.roi_gather.convs.2.bn.bias\", \"module.heads.roi_gather.convs.2.bn.running_mean\", \"module.heads.roi_gather.convs.2.bn.running_var\", \"module.heads.roi_gather.convs.2.bn.num_batches_tracked\", \"module.heads.roi_gather.catconv.0.conv.weight\", \"module.heads.roi_gather.catconv.0.bn.weight\", \"module.heads.roi_gather.catconv.0.bn.bias\", \"module.heads.roi_gather.catconv.0.bn.running_mean\", \"module.heads.roi_gather.catconv.0.bn.running_var\", \"module.heads.roi_gather.catconv.0.bn.num_batches_tracked\", \"module.heads.roi_gather.catconv.1.conv.weight\", \"module.heads.roi_gather.catconv.1.bn.weight\", \"module.heads.roi_gather.catconv.1.bn.bias\", \"module.heads.roi_gather.catconv.1.bn.running_mean\", \"module.heads.roi_gather.catconv.1.bn.running_var\", \"module.heads.roi_gather.catconv.1.bn.num_batches_tracked\", \"module.heads.roi_gather.catconv.2.conv.weight\", \"module.heads.roi_gather.catconv.2.bn.weight\", \"module.heads.roi_gather.catconv.2.bn.bias\", \"module.heads.roi_gather.catconv.2.bn.running_mean\", \"module.heads.roi_gather.catconv.2.bn.running_var\", \"module.heads.roi_gather.catconv.2.bn.num_batches_tracked\", \"module.heads.roi_gather.fc.weight\", \"module.heads.roi_gather.fc.bias\", \"module.heads.roi_gather.fc_norm.weight\", \"module.heads.roi_gather.fc_norm.bias\", \"module.heads.reg_layers.weight\", \"module.heads.reg_layers.bias\", \"module.heads.cls_layers.weight\", \"module.heads.cls_layers.bias\", \"module.heads.criterion.weight\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmultitask_s\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m YOLOL\n\u001b[1;32m      2\u001b[0m clrnet_yolo \u001b[38;5;241m=\u001b[39m YOLOL(darknet_backbone, darknet_neck, darknet_head, clrnet_head)\n\u001b[0;32m----> 3\u001b[0m \u001b[43mclrnet_yolo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/home/mmm9886/Desktop/Capstone_Implementation/clrnet/work_dirs/clr/r18_culane/20250111_141413_lr_6e-04_b_24_________/ckpt/9.pth\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnet\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/clrnet/lib/python3.8/site-packages/torch/nn/modules/module.py:1223\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   1218\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   1219\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   1220\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(k) \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[1;32m   1222\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 1223\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   1224\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   1225\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for YOLOL:\n\tMissing key(s) in state_dict: \"backbone.p1.0.conv.weight\", \"backbone.p1.0.norm.weight\", \"backbone.p1.0.norm.bias\", \"backbone.p1.0.norm.running_mean\", \"backbone.p1.0.norm.running_var\", \"backbone.p2.0.conv.weight\", \"backbone.p2.0.norm.weight\", \"backbone.p2.0.norm.bias\", \"backbone.p2.0.norm.running_mean\", \"backbone.p2.0.norm.running_var\", \"backbone.p2.1.conv1.conv.weight\", \"backbone.p2.1.conv1.norm.weight\", \"backbone.p2.1.conv1.norm.bias\", \"backbone.p2.1.conv1.norm.running_mean\", \"backbone.p2.1.conv1.norm.running_var\", \"backbone.p2.1.conv2.conv.weight\", \"backbone.p2.1.conv2.norm.weight\", \"backbone.p2.1.conv2.norm.bias\", \"backbone.p2.1.conv2.norm.running_mean\", \"backbone.p2.1.conv2.norm.running_var\", \"backbone.p2.1.conv3.conv.weight\", \"backbone.p2.1.conv3.norm.weight\", \"backbone.p2.1.conv3.norm.bias\", \"backbone.p2.1.conv3.norm.running_mean\", \"backbone.p2.1.conv3.norm.running_var\", \"backbone.p2.1.res_m.0.res_m.0.conv.weight\", \"backbone.p2.1.res_m.0.res_m.0.norm.weight\", \"backbone.p2.1.res_m.0.res_m.0.norm.bias\", \"backbone.p2.1.res_m.0.res_m.0.norm.running_mean\", \"backbone.p2.1.res_m.0.res_m.0.norm.running_var\", \"backbone.p2.1.res_m.0.res_m.1.conv.weight\", \"backbone.p2.1.res_m.0.res_m.1.norm.weight\", \"backbone.p2.1.res_m.0.res_m.1.norm.bias\", \"backbone.p2.1.res_m.0.res_m.1.norm.running_mean\", \"backbone.p2.1.res_m.0.res_m.1.norm.running_var\", \"backbone.p3.0.conv.weight\", \"backbone.p3.0.norm.weight\", \"backbone.p3.0.norm.bias\", \"backbone.p3.0.norm.running_mean\", \"backbone.p3.0.norm.running_var\", \"backbone.p3.1.conv1.conv.weight\", \"backbone.p3.1.conv1.norm.weight\", \"backbone.p3.1.conv1.norm.bias\", \"backbone.p3.1.conv1.norm.running_mean\", \"backbone.p3.1.conv1.norm.running_var\", \"backbone.p3.1.conv2.conv.weight\", \"backbone.p3.1.conv2.norm.weight\", \"backbone.p3.1.conv2.norm.bias\", \"backbone.p3.1.conv2.norm.running_mean\", \"backbone.p3.1.conv2.norm.running_var\", \"backbone.p3.1.conv3.conv.weight\", \"backbone.p3.1.conv3.norm.weight\", \"backbone.p3.1.conv3.norm.bias\", \"backbone.p3.1.conv3.norm.running_mean\", \"backbone.p3.1.conv3.norm.running_var\", \"backbone.p3.1.res_m.0.res_m.0.conv.weight\", \"backbone.p3.1.res_m.0.res_m.0.norm.weight\", \"backbone.p3.1.res_m.0.res_m.0.norm.bias\", \"backbone.p3.1.res_m.0.res_m.0.norm.running_mean\", \"backbone.p3.1.res_m.0.res_m.0.norm.running_var\", \"backbone.p3.1.res_m.0.res_m.1.conv.weight\", \"backbone.p3.1.res_m.0.res_m.1.norm.weight\", \"backbone.p3.1.res_m.0.res_m.1.norm.bias\", \"backbone.p3.1.res_m.0.res_m.1.norm.running_mean\", \"backbone.p3.1.res_m.0.res_m.1.norm.running_var\", \"backbone.p3.1.res_m.1.res_m.0.conv.weight\", \"backbone.p3.1.res_m.1.res_m.0.norm.weight\", \"backbone.p3.1.res_m.1.res_m.0.norm.bias\", \"backbone.p3.1.res_m.1.res_m.0.norm.running_mean\", \"backbone.p3.1.res_m.1.res_m.0.norm.running_var\", \"backbone.p3.1.res_m.1.res_m.1.conv.weight\", \"backbone.p3.1.res_m.1.res_m.1.norm.weight\", \"backbone.p3.1.res_m.1.res_m.1.norm.bias\", \"backbone.p3.1.res_m.1.res_m.1.norm.running_mean\", \"backbone.p3.1.res_m.1.res_m.1.norm.running_var\", \"backbone.p4.0.conv.weight\", \"backbone.p4.0.norm.weight\", \"backbone.p4.0.norm.bias\", \"backbone.p4.0.norm.running_mean\", \"backbone.p4.0.norm.running_var\", \"backbone.p4.1.conv1.conv.weight\", \"backbone.p4.1.conv1.norm.weight\", \"backbone.p4.1.conv1.norm.bias\", \"backbone.p4.1.conv1.norm.running_mean\", \"backbone.p4.1.conv1.norm.running_var\", \"backbone.p4.1.conv2.conv.weight\", \"backbone.p4.1.conv2.norm.weight\", \"backbone.p4.1.conv2.norm.bias\", \"backbone.p4.1.conv2.norm.running_mean\", \"backbone.p4.1.conv2.norm.running_var\", \"backbone.p4.1.conv3.conv.weight\", \"backbone.p4.1.conv3.norm.weight\", \"backbone.p4.1.conv3.norm.bias\", \"backbone.p4.1.conv3.norm.running_mean\", \"backbone.p4.1.conv3.norm.running_var\", \"backbone.p4.1.res_m.0.res_m.0.conv.weight\", \"backbone.p4.1.res_m.0.res_m.0.norm.weight\", \"backbone.p4.1.res_m.0.res_m.0.norm.bias\", \"backbone.p4.1.res_m.0.res_m.0.norm.running_mean\", \"backbone.p4.1.res_m.0.res_m.0.norm.running_var\", \"backbone.p4.1.res_m.0.res_m.1.conv.weight\", \"backbone.p4.1.res_m.0.res_m.1.norm.weight\", \"backbone.p4.1.res_m.0.res_m.1.norm.bias\", \"backbone.p4.1.res_m.0.res_m.1.norm.running_mean\", \"backbone.p4.1.res_m.0.res_m.1.norm.running_var\", \"backbone.p4.1.res_m.1.res_m.0.conv.weight\", \"backbone.p4.1.res_m.1.res_m.0.norm.weight\", \"backbone.p4.1.res_m.1.res_m.0.norm.bias\", \"backbone.p4.1.res_m.1.res_m.0.norm.running_mean\", \"backbone.p4.1.res_m.1.res_m.0.norm.running_var\", \"backbone.p4.1.res_m.1.res_m.1.conv.weight\", \"backbone.p4.1.res_m.1.res_m.1.norm.weight\", \"backbone.p4.1.res_m.1.res_m.1.norm.bias\", \"backbone.p4.1.res_m.1.res_m.1.norm.running_mean\", \"backbone.p4.1.res_m.1.res_m.1.norm.running_var\", \"backbone.p5.0.conv.weight\", \"backbone.p5.0.norm.weight\", \"backbone.p5.0.norm.bias\", \"backbone.p5.0.norm.running_mean\", \"backbone.p5.0.norm.running_var\", \"backbone.p5.1.conv1.conv.weight\", \"backbone.p5.1.conv1.norm.weight\", \"backbone.p5.1.conv1.norm.bias\", \"backbone.p5.1.conv1.norm.running_mean\", \"backbone.p5.1.conv1.norm.running_var\", \"backbone.p5.1.conv2.conv.weight\", \"backbone.p5.1.conv2.norm.weight\", \"backbone.p5.1.conv2.norm.bias\", \"backbone.p5.1.conv2.norm.running_mean\", \"backbone.p5.1.conv2.norm.running_var\", \"backbone.p5.1.conv3.conv.weight\", \"backbone.p5.1.conv3.norm.weight\", \"backbone.p5.1.conv3.norm.bias\", \"backbone.p5.1.conv3.norm.running_mean\", \"backbone.p5.1.conv3.norm.running_var\", \"backbone.p5.1.res_m.0.res_m.0.conv.weight\", \"backbone.p5.1.res_m.0.res_m.0.norm.weight\", \"backbone.p5.1.res_m.0.res_m.0.norm.bias\", \"backbone.p5.1.res_m.0.res_m.0.norm.running_mean\", \"backbone.p5.1.res_m.0.res_m.0.norm.running_var\", \"backbone.p5.1.res_m.0.res_m.1.conv.weight\", \"backbone.p5.1.res_m.0.res_m.1.norm.weight\", \"backbone.p5.1.res_m.0.res_m.1.norm.bias\", \"backbone.p5.1.res_m.0.res_m.1.norm.running_mean\", \"backbone.p5.1.res_m.0.res_m.1.norm.running_var\", \"backbone.p5.2.conv1.conv.weight\", \"backbone.p5.2.conv1.norm.weight\", \"backbone.p5.2.conv1.norm.bias\", \"backbone.p5.2.conv1.norm.running_mean\", \"backbone.p5.2.conv1.norm.running_var\", \"backbone.p5.2.conv2.conv.weight\", \"backbone.p5.2.conv2.norm.weight\", \"backbone.p5.2.conv2.norm.bias\", \"backbone.p5.2.conv2.norm.running_mean\", \"backbone.p5.2.conv2.norm.running_var\", \"neck.h1.conv1.conv.weight\", \"neck.h1.conv1.norm.weight\", \"neck.h1.conv1.norm.bias\", \"neck.h1.conv1.norm.running_mean\", \"neck.h1.conv1.norm.running_var\", \"neck.h1.conv2.conv.weight\", \"neck.h1.conv2.norm.weight\", \"neck.h1.conv2.norm.bias\", \"neck.h1.conv2.norm.running_mean\", \"neck.h1.conv2.norm.running_var\", \"neck.h1.conv3.conv.weight\", \"neck.h1.conv3.norm.weight\", \"neck.h1.conv3.norm.bias\", \"neck.h1.conv3.norm.running_mean\", \"neck.h1.conv3.norm.running_var\", \"neck.h1.res_m.0.res_m.0.conv.weight\", \"neck.h1.res_m.0.res_m.0.norm.weight\", \"neck.h1.res_m.0.res_m.0.norm.bias\", \"neck.h1.res_m.0.res_m.0.norm.running_mean\", \"neck.h1.res_m.0.res_m.0.norm.running_var\", \"neck.h1.res_m.0.res_m.1.conv.weight\", \"neck.h1.res_m.0.res_m.1.norm.weight\", \"neck.h1.res_m.0.res_m.1.norm.bias\", \"neck.h1.res_m.0.res_m.1.norm.running_mean\", \"neck.h1.res_m.0.res_m.1.norm.running_var\", \"neck.h2.conv1.conv.weight\", \"neck.h2.conv1.norm.weight\", \"neck.h2.conv1.norm.bias\", \"neck.h2.conv1.norm.running_mean\", \"neck.h2.conv1.norm.running_var\", \"neck.h2.conv2.conv.weight\", \"neck.h2.conv2.norm.weight\", \"neck.h2.conv2.norm.bias\", \"neck.h2.conv2.norm.running_mean\", \"neck.h2.conv2.norm.running_var\", \"neck.h2.conv3.conv.weight\", \"neck.h2.conv3.norm.weight\", \"neck.h2.conv3.norm.bias\", \"neck.h2.conv3.norm.running_mean\", \"neck.h2.conv3.norm.running_var\", \"neck.h2.res_m.0.res_m.0.conv.weight\", \"neck.h2.res_m.0.res_m.0.norm.weight\", \"neck.h2.res_m.0.res_m.0.norm.bias\", \"neck.h2.res_m.0.res_m.0.norm.running_mean\", \"neck.h2.res_m.0.res_m.0.norm.running_var\", \"neck.h2.res_m.0.res_m.1.conv.weight\", \"neck.h2.res_m.0.res_m.1.norm.weight\", \"neck.h2.res_m.0.res_m.1.norm.bias\", \"neck.h2.res_m.0.res_m.1.norm.running_mean\", \"neck.h2.res_m.0.res_m.1.norm.running_var\", \"neck.h3.conv.weight\", \"neck.h3.norm.weight\", \"neck.h3.norm.bias\", \"neck.h3.norm.running_mean\", \"neck.h3.norm.running_var\", \"neck.h4.conv1.conv.weight\", \"neck.h4.conv1.norm.weight\", \"neck.h4.conv1.norm.bias\", \"neck.h4.conv1.norm.running_mean\", \"neck.h4.conv1.norm.running_var\", \"neck.h4.conv2.conv.weight\", \"neck.h4.conv2.norm.weight\", \"neck.h4.conv2.norm.bias\", \"neck.h4.conv2.norm.running_mean\", \"neck.h4.conv2.norm.running_var\", \"neck.h4.conv3.conv.weight\", \"neck.h4.conv3.norm.weight\", \"neck.h4.conv3.norm.bias\", \"neck.h4.conv3.norm.running_mean\", \"neck.h4.conv3.norm.running_var\", \"neck.h4.res_m.0.res_m.0.conv.weight\", \"neck.h4.res_m.0.res_m.0.norm.weight\", \"neck.h4.res_m.0.res_m.0.norm.bias\", \"neck.h4.res_m.0.res_m.0.norm.running_mean\", \"neck.h4.res_m.0.res_m.0.norm.running_var\", \"neck.h4.res_m.0.res_m.1.conv.weight\", \"neck.h4.res_m.0.res_m.1.norm.weight\", \"neck.h4.res_m.0.res_m.1.norm.bias\", \"neck.h4.res_m.0.res_m.1.norm.running_mean\", \"neck.h4.res_m.0.res_m.1.norm.running_var\", \"neck.h5.conv.weight\", \"neck.h5.norm.weight\", \"neck.h5.norm.bias\", \"neck.h5.norm.running_mean\", \"neck.h5.norm.running_var\", \"neck.h6.conv1.conv.weight\", \"neck.h6.conv1.norm.weight\", \"neck.h6.conv1.norm.bias\", \"neck.h6.conv1.norm.running_mean\", \"neck.h6.conv1.norm.running_var\", \"neck.h6.conv2.conv.weight\", \"neck.h6.conv2.norm.weight\", \"neck.h6.conv2.norm.bias\", \"neck.h6.conv2.norm.running_mean\", \"neck.h6.conv2.norm.running_var\", \"neck.h6.conv3.conv.weight\", \"neck.h6.conv3.norm.weight\", \"neck.h6.conv3.norm.bias\", \"neck.h6.conv3.norm.running_mean\", \"neck.h6.conv3.norm.running_var\", \"neck.h6.res_m.0.res_m.0.conv.weight\", \"neck.h6.res_m.0.res_m.0.norm.weight\", \"neck.h6.res_m.0.res_m.0.norm.bias\", \"neck.h6.res_m.0.res_m.0.norm.running_mean\", \"neck.h6.res_m.0.res_m.0.norm.running_var\", \"neck.h6.res_m.0.res_m.1.conv.weight\", \"neck.h6.res_m.0.res_m.1.norm.weight\", \"neck.h6.res_m.0.res_m.1.norm.bias\", \"neck.h6.res_m.0.res_m.1.norm.running_mean\", \"neck.h6.res_m.0.res_m.1.norm.running_var\", \"yolo_head.dfl.conv.weight\", \"yolo_head.cls.0.0.conv.weight\", \"yolo_head.cls.0.0.norm.weight\", \"yolo_head.cls.0.0.norm.bias\", \"yolo_head.cls.0.0.norm.running_mean\", \"yolo_head.cls.0.0.norm.running_var\", \"yolo_head.cls.0.1.conv.weight\", \"yolo_head.cls.0.1.norm.weight\", \"yolo_head.cls.0.1.norm.bias\", \"yolo_head.cls.0.1.norm.running_mean\", \"yolo_head.cls.0.1.norm.running_var\", \"yolo_head.cls.0.2.weight\", \"yolo_head.cls.0.2.bias\", \"yolo_head.cls.1.0.conv.weight\", \"yolo_head.cls.1.0.norm.weight\", \"yolo_head.cls.1.0.norm.bias\", \"yolo_head.cls.1.0.norm.running_mean\", \"yolo_head.cls.1.0.norm.running_var\", \"yolo_head.cls.1.1.conv.weight\", \"yolo_head.cls.1.1.norm.weight\", \"yolo_head.cls.1.1.norm.bias\", \"yolo_head.cls.1.1.norm.running_mean\", \"yolo_head.cls.1.1.norm.running_var\", \"yolo_head.cls.1.2.weight\", \"yolo_head.cls.1.2.bias\", \"yolo_head.cls.2.0.conv.weight\", \"yolo_head.cls.2.0.norm.weight\", \"yolo_head.cls.2.0.norm.bias\", \"yolo_head.cls.2.0.norm.running_mean\", \"yolo_head.cls.2.0.norm.running_var\", \"yolo_head.cls.2.1.conv.weight\", \"yolo_head.cls.2.1.norm.weight\", \"yolo_head.cls.2.1.norm.bias\", \"yolo_head.cls.2.1.norm.running_mean\", \"yolo_head.cls.2.1.norm.running_var\", \"yolo_head.cls.2.2.weight\", \"yolo_head.cls.2.2.bias\", \"yolo_head.box.0.0.conv.weight\", \"yolo_head.box.0.0.norm.weight\", \"yolo_head.box.0.0.norm.bias\", \"yolo_head.box.0.0.norm.running_mean\", \"yolo_head.box.0.0.norm.running_var\", \"yolo_head.box.0.1.conv.weight\", \"yolo_head.box.0.1.norm.weight\", \"yolo_head.box.0.1.norm.bias\", \"yolo_head.box.0.1.norm.running_mean\", \"yolo_head.box.0.1.norm.running_var\", \"yolo_head.box.0.2.weight\", \"yolo_head.box.0.2.bias\", \"yolo_head.box.1.0.conv.weight\", \"yolo_head.box.1.0.norm.weight\", \"yolo_head.box.1.0.norm.bias\", \"yolo_head.box.1.0.norm.running_mean\", \"yolo_head.box.1.0.norm.running_var\", \"yolo_head.box.1.1.conv.weight\", \"yolo_head.box.1.1.norm.weight\", \"yolo_head.box.1.1.norm.bias\", \"yolo_head.box.1.1.norm.running_mean\", \"yolo_head.box.1.1.norm.running_var\", \"yolo_head.box.1.2.weight\", \"yolo_head.box.1.2.bias\", \"yolo_head.box.2.0.conv.weight\", \"yolo_head.box.2.0.norm.weight\", \"yolo_head.box.2.0.norm.bias\", \"yolo_head.box.2.0.norm.running_mean\", \"yolo_head.box.2.0.norm.running_var\", \"yolo_head.box.2.1.conv.weight\", \"yolo_head.box.2.1.norm.weight\", \"yolo_head.box.2.1.norm.bias\", \"yolo_head.box.2.1.norm.running_mean\", \"yolo_head.box.2.1.norm.running_var\", \"yolo_head.box.2.2.weight\", \"yolo_head.box.2.2.bias\", \"clrhead.sample_x_indexs\", \"clrhead.prior_feat_ys\", \"clrhead.prior_ys\", \"clrhead.priors\", \"clrhead.priors_on_featmap\", \"clrhead.prior_embeddings.weight\", \"clrhead.seg_decoder.conv.weight\", \"clrhead.seg_decoder.conv.bias\", \"clrhead.reg_modules.0.weight\", \"clrhead.reg_modules.0.bias\", \"clrhead.reg_modules.2.weight\", \"clrhead.reg_modules.2.bias\", \"clrhead.cls_modules.0.weight\", \"clrhead.cls_modules.0.bias\", \"clrhead.cls_modules.2.weight\", \"clrhead.cls_modules.2.bias\", \"clrhead.roi_gather.f_key.conv.weight\", \"clrhead.roi_gather.f_key.bn.weight\", \"clrhead.roi_gather.f_key.bn.bias\", \"clrhead.roi_gather.f_key.bn.running_mean\", \"clrhead.roi_gather.f_key.bn.running_var\", \"clrhead.roi_gather.f_query.0.weight\", \"clrhead.roi_gather.f_query.0.bias\", \"clrhead.roi_gather.f_value.weight\", \"clrhead.roi_gather.f_value.bias\", \"clrhead.roi_gather.W.weight\", \"clrhead.roi_gather.W.bias\", \"clrhead.roi_gather.convs.0.conv.weight\", \"clrhead.roi_gather.convs.0.bn.weight\", \"clrhead.roi_gather.convs.0.bn.bias\", \"clrhead.roi_gather.convs.0.bn.running_mean\", \"clrhead.roi_gather.convs.0.bn.running_var\", \"clrhead.roi_gather.convs.1.conv.weight\", \"clrhead.roi_gather.convs.1.bn.weight\", \"clrhead.roi_gather.convs.1.bn.bias\", \"clrhead.roi_gather.convs.1.bn.running_mean\", \"clrhead.roi_gather.convs.1.bn.running_var\", \"clrhead.roi_gather.convs.2.conv.weight\", \"clrhead.roi_gather.convs.2.bn.weight\", \"clrhead.roi_gather.convs.2.bn.bias\", \"clrhead.roi_gather.convs.2.bn.running_mean\", \"clrhead.roi_gather.convs.2.bn.running_var\", \"clrhead.roi_gather.catconv.0.conv.weight\", \"clrhead.roi_gather.catconv.0.bn.weight\", \"clrhead.roi_gather.catconv.0.bn.bias\", \"clrhead.roi_gather.catconv.0.bn.running_mean\", \"clrhead.roi_gather.catconv.0.bn.running_var\", \"clrhead.roi_gather.catconv.1.conv.weight\", \"clrhead.roi_gather.catconv.1.bn.weight\", \"clrhead.roi_gather.catconv.1.bn.bias\", \"clrhead.roi_gather.catconv.1.bn.running_mean\", \"clrhead.roi_gather.catconv.1.bn.running_var\", \"clrhead.roi_gather.catconv.2.conv.weight\", \"clrhead.roi_gather.catconv.2.bn.weight\", \"clrhead.roi_gather.catconv.2.bn.bias\", \"clrhead.roi_gather.catconv.2.bn.running_mean\", \"clrhead.roi_gather.catconv.2.bn.running_var\", \"clrhead.roi_gather.fc.weight\", \"clrhead.roi_gather.fc.bias\", \"clrhead.roi_gather.fc_norm.weight\", \"clrhead.roi_gather.fc_norm.bias\", \"clrhead.reg_layers.weight\", \"clrhead.reg_layers.bias\", \"clrhead.cls_layers.weight\", \"clrhead.cls_layers.bias\", \"clrhead.criterion.weight\", \"offset_2.weight\", \"offset_1.weight\", \"offset_0.weight\". \n\tUnexpected key(s) in state_dict: \"module.backbone.p1.0.conv.weight\", \"module.backbone.p1.0.norm.weight\", \"module.backbone.p1.0.norm.bias\", \"module.backbone.p1.0.norm.running_mean\", \"module.backbone.p1.0.norm.running_var\", \"module.backbone.p1.0.norm.num_batches_tracked\", \"module.backbone.p2.0.conv.weight\", \"module.backbone.p2.0.norm.weight\", \"module.backbone.p2.0.norm.bias\", \"module.backbone.p2.0.norm.running_mean\", \"module.backbone.p2.0.norm.running_var\", \"module.backbone.p2.0.norm.num_batches_tracked\", \"module.backbone.p2.1.conv1.conv.weight\", \"module.backbone.p2.1.conv1.norm.weight\", \"module.backbone.p2.1.conv1.norm.bias\", \"module.backbone.p2.1.conv1.norm.running_mean\", \"module.backbone.p2.1.conv1.norm.running_var\", \"module.backbone.p2.1.conv1.norm.num_batches_tracked\", \"module.backbone.p2.1.conv2.conv.weight\", \"module.backbone.p2.1.conv2.norm.weight\", \"module.backbone.p2.1.conv2.norm.bias\", \"module.backbone.p2.1.conv2.norm.running_mean\", \"module.backbone.p2.1.conv2.norm.running_var\", \"module.backbone.p2.1.conv2.norm.num_batches_tracked\", \"module.backbone.p2.1.conv3.conv.weight\", \"module.backbone.p2.1.conv3.norm.weight\", \"module.backbone.p2.1.conv3.norm.bias\", \"module.backbone.p2.1.conv3.norm.running_mean\", \"module.backbone.p2.1.conv3.norm.running_var\", \"module.backbone.p2.1.conv3.norm.num_batches_tracked\", \"module.backbone.p2.1.res_m.0.res_m.0.conv.weight\", \"module.backbone.p2.1.res_m.0.res_m.0.norm.weight\", \"module.backbone.p2.1.res_m.0.res_m.0.norm.bias\", \"module.backbone.p2.1.res_m.0.res_m.0.norm.running_mean\", \"module.backbone.p2.1.res_m.0.res_m.0.norm.running_var\", \"module.backbone.p2.1.res_m.0.res_m.0.norm.num_batches_tracked\", \"module.backbone.p2.1.res_m.0.res_m.1.conv.weight\", \"module.backbone.p2.1.res_m.0.res_m.1.norm.weight\", \"module.backbone.p2.1.res_m.0.res_m.1.norm.bias\", \"module.backbone.p2.1.res_m.0.res_m.1.norm.running_mean\", \"module.backbone.p2.1.res_m.0.res_m.1.norm.running_var\", \"module.backbone.p2.1.res_m.0.res_m.1.norm.num_batches_tracked\", \"module.backbone.p3.0.conv.weight\", \"module.backbone.p3.0.norm.weight\", \"module.backbone.p3.0.norm.bias\", \"module.backbone.p3.0.norm.running_mean\", \"module.backbone.p3.0.norm.running_var\", \"module.backbone.p3.0.norm.num_batches_tracked\", \"module.backbone.p3.1.conv1.conv.weight\", \"module.backbone.p3.1.conv1.norm.weight\", \"module.backbone.p3.1.conv1.norm.bias\", \"module.backbone.p3.1.conv1.norm.running_mean\", \"module.backbone.p3.1.conv1.norm.running_var\", \"module.backbone.p3.1.conv1.norm.num_batches_tracked\", \"module.backbone.p3.1.conv2.conv.weight\", \"module.backbone.p3.1.conv2.norm.weight\", \"module.backbone.p3.1.conv2.norm.bias\", \"module.backbone.p3.1.conv2.norm.running_mean\", \"module.backbone.p3.1.conv2.norm.running_var\", \"module.backbone.p3.1.conv2.norm.num_batches_tracked\", \"module.backbone.p3.1.conv3.conv.weight\", \"module.backbone.p3.1.conv3.norm.weight\", \"module.backbone.p3.1.conv3.norm.bias\", \"module.backbone.p3.1.conv3.norm.running_mean\", \"module.backbone.p3.1.conv3.norm.running_var\", \"module.backbone.p3.1.conv3.norm.num_batches_tracked\", \"module.backbone.p3.1.res_m.0.res_m.0.conv.weight\", \"module.backbone.p3.1.res_m.0.res_m.0.norm.weight\", \"module.backbone.p3.1.res_m.0.res_m.0.norm.bias\", \"module.backbone.p3.1.res_m.0.res_m.0.norm.running_mean\", \"module.backbone.p3.1.res_m.0.res_m.0.norm.running_var\", \"module.backbone.p3.1.res_m.0.res_m.0.norm.num_batches_tracked\", \"module.backbone.p3.1.res_m.0.res_m.1.conv.weight\", \"module.backbone.p3.1.res_m.0.res_m.1.norm.weight\", \"module.backbone.p3.1.res_m.0.res_m.1.norm.bias\", \"module.backbone.p3.1.res_m.0.res_m.1.norm.running_mean\", \"module.backbone.p3.1.res_m.0.res_m.1.norm.running_var\", \"module.backbone.p3.1.res_m.0.res_m.1.norm.num_batches_tracked\", \"module.backbone.p3.1.res_m.1.res_m.0.conv.weight\", \"module.backbone.p3.1.res_m.1.res_m.0.norm.weight\", \"module.backbone.p3.1.res_m.1.res_m.0.norm.bias\", \"module.backbone.p3.1.res_m.1.res_m.0.norm.running_mean\", \"module.backbone.p3.1.res_m.1.res_m.0.norm.running_var\", \"module.backbone.p3.1.res_m.1.res_m.0.norm.num_batches_tracked\", \"module.backbone.p3.1.res_m.1.res_m.1.conv.weight\", \"module.backbone.p3.1.res_m.1.res_m.1.norm.weight\", \"module.backbone.p3.1.res_m.1.res_m.1.norm.bias\", \"module.backbone.p3.1.res_m.1.res_m.1.norm.running_mean\", \"module.backbone.p3.1.res_m.1.res_m.1.norm.running_var\", \"module.backbone.p3.1.res_m.1.res_m.1.norm.num_batches_tracked\", \"module.backbone.p4.0.conv.weight\", \"module.backbone.p4.0.norm.weight\", \"module.backbone.p4.0.norm.bias\", \"module.backbone.p4.0.norm.running_mean\", \"module.backbone.p4.0.norm.running_var\", \"module.backbone.p4.0.norm.num_batches_tracked\", \"module.backbone.p4.1.conv1.conv.weight\", \"module.backbone.p4.1.conv1.norm.weight\", \"module.backbone.p4.1.conv1.norm.bias\", \"module.backbone.p4.1.conv1.norm.running_mean\", \"module.backbone.p4.1.conv1.norm.running_var\", \"module.backbone.p4.1.conv1.norm.num_batches_tracked\", \"module.backbone.p4.1.conv2.conv.weight\", \"module.backbone.p4.1.conv2.norm.weight\", \"module.backbone.p4.1.conv2.norm.bias\", \"module.backbone.p4.1.conv2.norm.running_mean\", \"module.backbone.p4.1.conv2.norm.running_var\", \"module.backbone.p4.1.conv2.norm.num_batches_tracked\", \"module.backbone.p4.1.conv3.conv.weight\", \"module.backbone.p4.1.conv3.norm.weight\", \"module.backbone.p4.1.conv3.norm.bias\", \"module.backbone.p4.1.conv3.norm.running_mean\", \"module.backbone.p4.1.conv3.norm.running_var\", \"module.backbone.p4.1.conv3.norm.num_batches_tracked\", \"module.backbone.p4.1.res_m.0.res_m.0.conv.weight\", \"module.backbone.p4.1.res_m.0.res_m.0.norm.weight\", \"module.backbone.p4.1.res_m.0.res_m.0.norm.bias\", \"module.backbone.p4.1.res_m.0.res_m.0.norm.running_mean\", \"module.backbone.p4.1.res_m.0.res_m.0.norm.running_var\", \"module.backbone.p4.1.res_m.0.res_m.0.norm.num_batches_tracked\", \"module.backbone.p4.1.res_m.0.res_m.1.conv.weight\", \"module.backbone.p4.1.res_m.0.res_m.1.norm.weight\", \"module.backbone.p4.1.res_m.0.res_m.1.norm.bias\", \"module.backbone.p4.1.res_m.0.res_m.1.norm.running_mean\", \"module.backbone.p4.1.res_m.0.res_m.1.norm.running_var\", \"module.backbone.p4.1.res_m.0.res_m.1.norm.num_batches_tracked\", \"module.backbone.p4.1.res_m.1.res_m.0.conv.weight\", \"module.backbone.p4.1.res_m.1.res_m.0.norm.weight\", \"module.backbone.p4.1.res_m.1.res_m.0.norm.bias\", \"module.backbone.p4.1.res_m.1.res_m.0.norm.running_mean\", \"module.backbone.p4.1.res_m.1.res_m.0.norm.running_var\", \"module.backbone.p4.1.res_m.1.res_m.0.norm.num_batches_tracked\", \"module.backbone.p4.1.res_m.1.res_m.1.conv.weight\", \"module.backbone.p4.1.res_m.1.res_m.1.norm.weight\", \"module.backbone.p4.1.res_m.1.res_m.1.norm.bias\", \"module.backbone.p4.1.res_m.1.res_m.1.norm.running_mean\", \"module.backbone.p4.1.res_m.1.res_m.1.norm.running_var\", \"module.backbone.p4.1.res_m.1.res_m.1.norm.num_batches_tracked\", \"module.backbone.p5.0.conv.weight\", \"module.backbone.p5.0.norm.weight\", \"module.backbone.p5.0.norm.bias\", \"module.backbone.p5.0.norm.running_mean\", \"module.backbone.p5.0.norm.running_var\", \"module.backbone.p5.0.norm.num_batches_tracked\", \"module.backbone.p5.1.conv1.conv.weight\", \"module.backbone.p5.1.conv1.norm.weight\", \"module.backbone.p5.1.conv1.norm.bias\", \"module.backbone.p5.1.conv1.norm.running_mean\", \"module.backbone.p5.1.conv1.norm.running_var\", \"module.backbone.p5.1.conv1.norm.num_batches_tracked\", \"module.backbone.p5.1.conv2.conv.weight\", \"module.backbone.p5.1.conv2.norm.weight\", \"module.backbone.p5.1.conv2.norm.bias\", \"module.backbone.p5.1.conv2.norm.running_mean\", \"module.backbone.p5.1.conv2.norm.running_var\", \"module.backbone.p5.1.conv2.norm.num_batches_tracked\", \"module.backbone.p5.1.conv3.conv.weight\", \"module.backbone.p5.1.conv3.norm.weight\", \"module.backbone.p5.1.conv3.norm.bias\", \"module.backbone.p5.1.conv3.norm.running_mean\", \"module.backbone.p5.1.conv3.norm.running_var\", \"module.backbone.p5.1.conv3.norm.num_batches_tracked\", \"module.backbone.p5.1.res_m.0.res_m.0.conv.weight\", \"module.backbone.p5.1.res_m.0.res_m.0.norm.weight\", \"module.backbone.p5.1.res_m.0.res_m.0.norm.bias\", \"module.backbone.p5.1.res_m.0.res_m.0.norm.running_mean\", \"module.backbone.p5.1.res_m.0.res_m.0.norm.running_var\", \"module.backbone.p5.1.res_m.0.res_m.0.norm.num_batches_tracked\", \"module.backbone.p5.1.res_m.0.res_m.1.conv.weight\", \"module.backbone.p5.1.res_m.0.res_m.1.norm.weight\", \"module.backbone.p5.1.res_m.0.res_m.1.norm.bias\", \"module.backbone.p5.1.res_m.0.res_m.1.norm.running_mean\", \"module.backbone.p5.1.res_m.0.res_m.1.norm.running_var\", \"module.backbone.p5.1.res_m.0.res_m.1.norm.num_batches_tracked\", \"module.backbone.p5.2.conv1.conv.weight\", \"module.backbone.p5.2.conv1.norm.weight\", \"module.backbone.p5.2.conv1.norm.bias\", \"module.backbone.p5.2.conv1.norm.running_mean\", \"module.backbone.p5.2.conv1.norm.running_var\", \"module.backbone.p5.2.conv1.norm.num_batches_tracked\", \"module.backbone.p5.2.conv2.conv.weight\", \"module.backbone.p5.2.conv2.norm.weight\", \"module.backbone.p5.2.conv2.norm.bias\", \"module.backbone.p5.2.conv2.norm.running_mean\", \"module.backbone.p5.2.conv2.norm.running_var\", \"module.backbone.p5.2.conv2.norm.num_batches_tracked\", \"module.neck.neck.h1.conv1.conv.weight\", \"module.neck.neck.h1.conv1.norm.weight\", \"module.neck.neck.h1.conv1.norm.bias\", \"module.neck.neck.h1.conv1.norm.running_mean\", \"module.neck.neck.h1.conv1.norm.running_var\", \"module.neck.neck.h1.conv1.norm.num_batches_tracked\", \"module.neck.neck.h1.conv2.conv.weight\", \"module.neck.neck.h1.conv2.norm.weight\", \"module.neck.neck.h1.conv2.norm.bias\", \"module.neck.neck.h1.conv2.norm.running_mean\", \"module.neck.neck.h1.conv2.norm.running_var\", \"module.neck.neck.h1.conv2.norm.num_batches_tracked\", \"module.neck.neck.h1.conv3.conv.weight\", \"module.neck.neck.h1.conv3.norm.weight\", \"module.neck.neck.h1.conv3.norm.bias\", \"module.neck.neck.h1.conv3.norm.running_mean\", \"module.neck.neck.h1.conv3.norm.running_var\", \"module.neck.neck.h1.conv3.norm.num_batches_tracked\", \"module.neck.neck.h1.res_m.0.res_m.0.conv.weight\", \"module.neck.neck.h1.res_m.0.res_m.0.norm.weight\", \"module.neck.neck.h1.res_m.0.res_m.0.norm.bias\", \"module.neck.neck.h1.res_m.0.res_m.0.norm.running_mean\", \"module.neck.neck.h1.res_m.0.res_m.0.norm.running_var\", \"module.neck.neck.h1.res_m.0.res_m.0.norm.num_batches_tracked\", \"module.neck.neck.h1.res_m.0.res_m.1.conv.weight\", \"module.neck.neck.h1.res_m.0.res_m.1.norm.weight\", \"module.neck.neck.h1.res_m.0.res_m.1.norm.bias\", \"module.neck.neck.h1.res_m.0.res_m.1.norm.running_mean\", \"module.neck.neck.h1.res_m.0.res_m.1.norm.running_var\", \"module.neck.neck.h1.res_m.0.res_m.1.norm.num_batches_tracked\", \"module.neck.neck.h2.conv1.conv.weight\", \"module.neck.neck.h2.conv1.norm.weight\", \"module.neck.neck.h2.conv1.norm.bias\", \"module.neck.neck.h2.conv1.norm.running_mean\", \"module.neck.neck.h2.conv1.norm.running_var\", \"module.neck.neck.h2.conv1.norm.num_batches_tracked\", \"module.neck.neck.h2.conv2.conv.weight\", \"module.neck.neck.h2.conv2.norm.weight\", \"module.neck.neck.h2.conv2.norm.bias\", \"module.neck.neck.h2.conv2.norm.running_mean\", \"module.neck.neck.h2.conv2.norm.running_var\", \"module.neck.neck.h2.conv2.norm.num_batches_tracked\", \"module.neck.neck.h2.conv3.conv.weight\", \"module.neck.neck.h2.conv3.norm.weight\", \"module.neck.neck.h2.conv3.norm.bias\", \"module.neck.neck.h2.conv3.norm.running_mean\", \"module.neck.neck.h2.conv3.norm.running_var\", \"module.neck.neck.h2.conv3.norm.num_batches_tracked\", \"module.neck.neck.h2.res_m.0.res_m.0.conv.weight\", \"module.neck.neck.h2.res_m.0.res_m.0.norm.weight\", \"module.neck.neck.h2.res_m.0.res_m.0.norm.bias\", \"module.neck.neck.h2.res_m.0.res_m.0.norm.running_mean\", \"module.neck.neck.h2.res_m.0.res_m.0.norm.running_var\", \"module.neck.neck.h2.res_m.0.res_m.0.norm.num_batches_tracked\", \"module.neck.neck.h2.res_m.0.res_m.1.conv.weight\", \"module.neck.neck.h2.res_m.0.res_m.1.norm.weight\", \"module.neck.neck.h2.res_m.0.res_m.1.norm.bias\", \"module.neck.neck.h2.res_m.0.res_m.1.norm.running_mean\", \"module.neck.neck.h2.res_m.0.res_m.1.norm.running_var\", \"module.neck.neck.h2.res_m.0.res_m.1.norm.num_batches_tracked\", \"module.neck.neck.h3.conv.weight\", \"module.neck.neck.h3.norm.weight\", \"module.neck.neck.h3.norm.bias\", \"module.neck.neck.h3.norm.running_mean\", \"module.neck.neck.h3.norm.running_var\", \"module.neck.neck.h3.norm.num_batches_tracked\", \"module.neck.neck.h4.conv1.conv.weight\", \"module.neck.neck.h4.conv1.norm.weight\", \"module.neck.neck.h4.conv1.norm.bias\", \"module.neck.neck.h4.conv1.norm.running_mean\", \"module.neck.neck.h4.conv1.norm.running_var\", \"module.neck.neck.h4.conv1.norm.num_batches_tracked\", \"module.neck.neck.h4.conv2.conv.weight\", \"module.neck.neck.h4.conv2.norm.weight\", \"module.neck.neck.h4.conv2.norm.bias\", \"module.neck.neck.h4.conv2.norm.running_mean\", \"module.neck.neck.h4.conv2.norm.running_var\", \"module.neck.neck.h4.conv2.norm.num_batches_tracked\", \"module.neck.neck.h4.conv3.conv.weight\", \"module.neck.neck.h4.conv3.norm.weight\", \"module.neck.neck.h4.conv3.norm.bias\", \"module.neck.neck.h4.conv3.norm.running_mean\", \"module.neck.neck.h4.conv3.norm.running_var\", \"module.neck.neck.h4.conv3.norm.num_batches_tracked\", \"module.neck.neck.h4.res_m.0.res_m.0.conv.weight\", \"module.neck.neck.h4.res_m.0.res_m.0.norm.weight\", \"module.neck.neck.h4.res_m.0.res_m.0.norm.bias\", \"module.neck.neck.h4.res_m.0.res_m.0.norm.running_mean\", \"module.neck.neck.h4.res_m.0.res_m.0.norm.running_var\", \"module.neck.neck.h4.res_m.0.res_m.0.norm.num_batches_tracked\", \"module.neck.neck.h4.res_m.0.res_m.1.conv.weight\", \"module.neck.neck.h4.res_m.0.res_m.1.norm.weight\", \"module.neck.neck.h4.res_m.0.res_m.1.norm.bias\", \"module.neck.neck.h4.res_m.0.res_m.1.norm.running_mean\", \"module.neck.neck.h4.res_m.0.res_m.1.norm.running_var\", \"module.neck.neck.h4.res_m.0.res_m.1.norm.num_batches_tracked\", \"module.neck.neck.h5.conv.weight\", \"module.neck.neck.h5.norm.weight\", \"module.neck.neck.h5.norm.bias\", \"module.neck.neck.h5.norm.running_mean\", \"module.neck.neck.h5.norm.running_var\", \"module.neck.neck.h5.norm.num_batches_tracked\", \"module.neck.neck.h6.conv1.conv.weight\", \"module.neck.neck.h6.conv1.norm.weight\", \"module.neck.neck.h6.conv1.norm.bias\", \"module.neck.neck.h6.conv1.norm.running_mean\", \"module.neck.neck.h6.conv1.norm.running_var\", \"module.neck.neck.h6.conv1.norm.num_batches_tracked\", \"module.neck.neck.h6.conv2.conv.weight\", \"module.neck.neck.h6.conv2.norm.weight\", \"module.neck.neck.h6.conv2.norm.bias\", \"module.neck.neck.h6.conv2.norm.running_mean\", \"module.neck.neck.h6.conv2.norm.running_var\", \"module.neck.neck.h6.conv2.norm.num_batches_tracked\", \"module.neck.neck.h6.conv3.conv.weight\", \"module.neck.neck.h6.conv3.norm.weight\", \"module.neck.neck.h6.conv3.norm.bias\", \"module.neck.neck.h6.conv3.norm.running_mean\", \"module.neck.neck.h6.conv3.norm.running_var\", \"module.neck.neck.h6.conv3.norm.num_batches_tracked\", \"module.neck.neck.h6.res_m.0.res_m.0.conv.weight\", \"module.neck.neck.h6.res_m.0.res_m.0.norm.weight\", \"module.neck.neck.h6.res_m.0.res_m.0.norm.bias\", \"module.neck.neck.h6.res_m.0.res_m.0.norm.running_mean\", \"module.neck.neck.h6.res_m.0.res_m.0.norm.running_var\", \"module.neck.neck.h6.res_m.0.res_m.0.norm.num_batches_tracked\", \"module.neck.neck.h6.res_m.0.res_m.1.conv.weight\", \"module.neck.neck.h6.res_m.0.res_m.1.norm.weight\", \"module.neck.neck.h6.res_m.0.res_m.1.norm.bias\", \"module.neck.neck.h6.res_m.0.res_m.1.norm.running_mean\", \"module.neck.neck.h6.res_m.0.res_m.1.norm.running_var\", \"module.neck.neck.h6.res_m.0.res_m.1.norm.num_batches_tracked\", \"module.neck.offset_2.weight\", \"module.neck.offset_1.weight\", \"module.neck.offset_0.weight\", \"module.heads.sample_x_indexs\", \"module.heads.prior_feat_ys\", \"module.heads.prior_ys\", \"module.heads.priors\", \"module.heads.priors_on_featmap\", \"module.heads.prior_embeddings.weight\", \"module.heads.seg_decoder.conv.weight\", \"module.heads.seg_decoder.conv.bias\", \"module.heads.reg_modules.0.weight\", \"module.heads.reg_modules.0.bias\", \"module.heads.reg_modules.2.weight\", \"module.heads.reg_modules.2.bias\", \"module.heads.cls_modules.0.weight\", \"module.heads.cls_modules.0.bias\", \"module.heads.cls_modules.2.weight\", \"module.heads.cls_modules.2.bias\", \"module.heads.roi_gather.f_key.conv.weight\", \"module.heads.roi_gather.f_key.bn.weight\", \"module.heads.roi_gather.f_key.bn.bias\", \"module.heads.roi_gather.f_key.bn.running_mean\", \"module.heads.roi_gather.f_key.bn.running_var\", \"module.heads.roi_gather.f_key.bn.num_batches_tracked\", \"module.heads.roi_gather.f_query.0.weight\", \"module.heads.roi_gather.f_query.0.bias\", \"module.heads.roi_gather.f_value.weight\", \"module.heads.roi_gather.f_value.bias\", \"module.heads.roi_gather.W.weight\", \"module.heads.roi_gather.W.bias\", \"module.heads.roi_gather.convs.0.conv.weight\", \"module.heads.roi_gather.convs.0.bn.weight\", \"module.heads.roi_gather.convs.0.bn.bias\", \"module.heads.roi_gather.convs.0.bn.running_mean\", \"module.heads.roi_gather.convs.0.bn.running_var\", \"module.heads.roi_gather.convs.0.bn.num_batches_tracked\", \"module.heads.roi_gather.convs.1.conv.weight\", \"module.heads.roi_gather.convs.1.bn.weight\", \"module.heads.roi_gather.convs.1.bn.bias\", \"module.heads.roi_gather.convs.1.bn.running_mean\", \"module.heads.roi_gather.convs.1.bn.running_var\", \"module.heads.roi_gather.convs.1.bn.num_batches_tracked\", \"module.heads.roi_gather.convs.2.conv.weight\", \"module.heads.roi_gather.convs.2.bn.weight\", \"module.heads.roi_gather.convs.2.bn.bias\", \"module.heads.roi_gather.convs.2.bn.running_mean\", \"module.heads.roi_gather.convs.2.bn.running_var\", \"module.heads.roi_gather.convs.2.bn.num_batches_tracked\", \"module.heads.roi_gather.catconv.0.conv.weight\", \"module.heads.roi_gather.catconv.0.bn.weight\", \"module.heads.roi_gather.catconv.0.bn.bias\", \"module.heads.roi_gather.catconv.0.bn.running_mean\", \"module.heads.roi_gather.catconv.0.bn.running_var\", \"module.heads.roi_gather.catconv.0.bn.num_batches_tracked\", \"module.heads.roi_gather.catconv.1.conv.weight\", \"module.heads.roi_gather.catconv.1.bn.weight\", \"module.heads.roi_gather.catconv.1.bn.bias\", \"module.heads.roi_gather.catconv.1.bn.running_mean\", \"module.heads.roi_gather.catconv.1.bn.running_var\", \"module.heads.roi_gather.catconv.1.bn.num_batches_tracked\", \"module.heads.roi_gather.catconv.2.conv.weight\", \"module.heads.roi_gather.catconv.2.bn.weight\", \"module.heads.roi_gather.catconv.2.bn.bias\", \"module.heads.roi_gather.catconv.2.bn.running_mean\", \"module.heads.roi_gather.catconv.2.bn.running_var\", \"module.heads.roi_gather.catconv.2.bn.num_batches_tracked\", \"module.heads.roi_gather.fc.weight\", \"module.heads.roi_gather.fc.bias\", \"module.heads.roi_gather.fc_norm.weight\", \"module.heads.roi_gather.fc_norm.bias\", \"module.heads.reg_layers.weight\", \"module.heads.reg_layers.bias\", \"module.heads.cls_layers.weight\", \"module.heads.cls_layers.bias\", \"module.heads.criterion.weight\". "
     ]
    }
   ],
   "source": [
    "from multitask_s import YOLOL\n",
    "clrnet_yolo = YOLOL(darknet_backbone, darknet_neck, darknet_head, clrnet_head)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for YOLOL:\n\tMissing key(s) in state_dict: \"neck.h1.conv1.conv.weight\", \"neck.h1.conv1.norm.weight\", \"neck.h1.conv1.norm.bias\", \"neck.h1.conv1.norm.running_mean\", \"neck.h1.conv1.norm.running_var\", \"neck.h1.conv2.conv.weight\", \"neck.h1.conv2.norm.weight\", \"neck.h1.conv2.norm.bias\", \"neck.h1.conv2.norm.running_mean\", \"neck.h1.conv2.norm.running_var\", \"neck.h1.conv3.conv.weight\", \"neck.h1.conv3.norm.weight\", \"neck.h1.conv3.norm.bias\", \"neck.h1.conv3.norm.running_mean\", \"neck.h1.conv3.norm.running_var\", \"neck.h1.res_m.0.res_m.0.conv.weight\", \"neck.h1.res_m.0.res_m.0.norm.weight\", \"neck.h1.res_m.0.res_m.0.norm.bias\", \"neck.h1.res_m.0.res_m.0.norm.running_mean\", \"neck.h1.res_m.0.res_m.0.norm.running_var\", \"neck.h1.res_m.0.res_m.1.conv.weight\", \"neck.h1.res_m.0.res_m.1.norm.weight\", \"neck.h1.res_m.0.res_m.1.norm.bias\", \"neck.h1.res_m.0.res_m.1.norm.running_mean\", \"neck.h1.res_m.0.res_m.1.norm.running_var\", \"neck.h2.conv1.conv.weight\", \"neck.h2.conv1.norm.weight\", \"neck.h2.conv1.norm.bias\", \"neck.h2.conv1.norm.running_mean\", \"neck.h2.conv1.norm.running_var\", \"neck.h2.conv2.conv.weight\", \"neck.h2.conv2.norm.weight\", \"neck.h2.conv2.norm.bias\", \"neck.h2.conv2.norm.running_mean\", \"neck.h2.conv2.norm.running_var\", \"neck.h2.conv3.conv.weight\", \"neck.h2.conv3.norm.weight\", \"neck.h2.conv3.norm.bias\", \"neck.h2.conv3.norm.running_mean\", \"neck.h2.conv3.norm.running_var\", \"neck.h2.res_m.0.res_m.0.conv.weight\", \"neck.h2.res_m.0.res_m.0.norm.weight\", \"neck.h2.res_m.0.res_m.0.norm.bias\", \"neck.h2.res_m.0.res_m.0.norm.running_mean\", \"neck.h2.res_m.0.res_m.0.norm.running_var\", \"neck.h2.res_m.0.res_m.1.conv.weight\", \"neck.h2.res_m.0.res_m.1.norm.weight\", \"neck.h2.res_m.0.res_m.1.norm.bias\", \"neck.h2.res_m.0.res_m.1.norm.running_mean\", \"neck.h2.res_m.0.res_m.1.norm.running_var\", \"neck.h3.conv.weight\", \"neck.h3.norm.weight\", \"neck.h3.norm.bias\", \"neck.h3.norm.running_mean\", \"neck.h3.norm.running_var\", \"neck.h4.conv1.conv.weight\", \"neck.h4.conv1.norm.weight\", \"neck.h4.conv1.norm.bias\", \"neck.h4.conv1.norm.running_mean\", \"neck.h4.conv1.norm.running_var\", \"neck.h4.conv2.conv.weight\", \"neck.h4.conv2.norm.weight\", \"neck.h4.conv2.norm.bias\", \"neck.h4.conv2.norm.running_mean\", \"neck.h4.conv2.norm.running_var\", \"neck.h4.conv3.conv.weight\", \"neck.h4.conv3.norm.weight\", \"neck.h4.conv3.norm.bias\", \"neck.h4.conv3.norm.running_mean\", \"neck.h4.conv3.norm.running_var\", \"neck.h4.res_m.0.res_m.0.conv.weight\", \"neck.h4.res_m.0.res_m.0.norm.weight\", \"neck.h4.res_m.0.res_m.0.norm.bias\", \"neck.h4.res_m.0.res_m.0.norm.running_mean\", \"neck.h4.res_m.0.res_m.0.norm.running_var\", \"neck.h4.res_m.0.res_m.1.conv.weight\", \"neck.h4.res_m.0.res_m.1.norm.weight\", \"neck.h4.res_m.0.res_m.1.norm.bias\", \"neck.h4.res_m.0.res_m.1.norm.running_mean\", \"neck.h4.res_m.0.res_m.1.norm.running_var\", \"neck.h5.conv.weight\", \"neck.h5.norm.weight\", \"neck.h5.norm.bias\", \"neck.h5.norm.running_mean\", \"neck.h5.norm.running_var\", \"neck.h6.conv1.conv.weight\", \"neck.h6.conv1.norm.weight\", \"neck.h6.conv1.norm.bias\", \"neck.h6.conv1.norm.running_mean\", \"neck.h6.conv1.norm.running_var\", \"neck.h6.conv2.conv.weight\", \"neck.h6.conv2.norm.weight\", \"neck.h6.conv2.norm.bias\", \"neck.h6.conv2.norm.running_mean\", \"neck.h6.conv2.norm.running_var\", \"neck.h6.conv3.conv.weight\", \"neck.h6.conv3.norm.weight\", \"neck.h6.conv3.norm.bias\", \"neck.h6.conv3.norm.running_mean\", \"neck.h6.conv3.norm.running_var\", \"neck.h6.res_m.0.res_m.0.conv.weight\", \"neck.h6.res_m.0.res_m.0.norm.weight\", \"neck.h6.res_m.0.res_m.0.norm.bias\", \"neck.h6.res_m.0.res_m.0.norm.running_mean\", \"neck.h6.res_m.0.res_m.0.norm.running_var\", \"neck.h6.res_m.0.res_m.1.conv.weight\", \"neck.h6.res_m.0.res_m.1.norm.weight\", \"neck.h6.res_m.0.res_m.1.norm.bias\", \"neck.h6.res_m.0.res_m.1.norm.running_mean\", \"neck.h6.res_m.0.res_m.1.norm.running_var\", \"yolo_head.dfl.conv.weight\", \"yolo_head.cls.0.0.conv.weight\", \"yolo_head.cls.0.0.norm.weight\", \"yolo_head.cls.0.0.norm.bias\", \"yolo_head.cls.0.0.norm.running_mean\", \"yolo_head.cls.0.0.norm.running_var\", \"yolo_head.cls.0.1.conv.weight\", \"yolo_head.cls.0.1.norm.weight\", \"yolo_head.cls.0.1.norm.bias\", \"yolo_head.cls.0.1.norm.running_mean\", \"yolo_head.cls.0.1.norm.running_var\", \"yolo_head.cls.0.2.weight\", \"yolo_head.cls.0.2.bias\", \"yolo_head.cls.1.0.conv.weight\", \"yolo_head.cls.1.0.norm.weight\", \"yolo_head.cls.1.0.norm.bias\", \"yolo_head.cls.1.0.norm.running_mean\", \"yolo_head.cls.1.0.norm.running_var\", \"yolo_head.cls.1.1.conv.weight\", \"yolo_head.cls.1.1.norm.weight\", \"yolo_head.cls.1.1.norm.bias\", \"yolo_head.cls.1.1.norm.running_mean\", \"yolo_head.cls.1.1.norm.running_var\", \"yolo_head.cls.1.2.weight\", \"yolo_head.cls.1.2.bias\", \"yolo_head.cls.2.0.conv.weight\", \"yolo_head.cls.2.0.norm.weight\", \"yolo_head.cls.2.0.norm.bias\", \"yolo_head.cls.2.0.norm.running_mean\", \"yolo_head.cls.2.0.norm.running_var\", \"yolo_head.cls.2.1.conv.weight\", \"yolo_head.cls.2.1.norm.weight\", \"yolo_head.cls.2.1.norm.bias\", \"yolo_head.cls.2.1.norm.running_mean\", \"yolo_head.cls.2.1.norm.running_var\", \"yolo_head.cls.2.2.weight\", \"yolo_head.cls.2.2.bias\", \"yolo_head.box.0.0.conv.weight\", \"yolo_head.box.0.0.norm.weight\", \"yolo_head.box.0.0.norm.bias\", \"yolo_head.box.0.0.norm.running_mean\", \"yolo_head.box.0.0.norm.running_var\", \"yolo_head.box.0.1.conv.weight\", \"yolo_head.box.0.1.norm.weight\", \"yolo_head.box.0.1.norm.bias\", \"yolo_head.box.0.1.norm.running_mean\", \"yolo_head.box.0.1.norm.running_var\", \"yolo_head.box.0.2.weight\", \"yolo_head.box.0.2.bias\", \"yolo_head.box.1.0.conv.weight\", \"yolo_head.box.1.0.norm.weight\", \"yolo_head.box.1.0.norm.bias\", \"yolo_head.box.1.0.norm.running_mean\", \"yolo_head.box.1.0.norm.running_var\", \"yolo_head.box.1.1.conv.weight\", \"yolo_head.box.1.1.norm.weight\", \"yolo_head.box.1.1.norm.bias\", \"yolo_head.box.1.1.norm.running_mean\", \"yolo_head.box.1.1.norm.running_var\", \"yolo_head.box.1.2.weight\", \"yolo_head.box.1.2.bias\", \"yolo_head.box.2.0.conv.weight\", \"yolo_head.box.2.0.norm.weight\", \"yolo_head.box.2.0.norm.bias\", \"yolo_head.box.2.0.norm.running_mean\", \"yolo_head.box.2.0.norm.running_var\", \"yolo_head.box.2.1.conv.weight\", \"yolo_head.box.2.1.norm.weight\", \"yolo_head.box.2.1.norm.bias\", \"yolo_head.box.2.1.norm.running_mean\", \"yolo_head.box.2.1.norm.running_var\", \"yolo_head.box.2.2.weight\", \"yolo_head.box.2.2.bias\", \"clrhead.sample_x_indexs\", \"clrhead.prior_feat_ys\", \"clrhead.prior_ys\", \"clrhead.priors\", \"clrhead.priors_on_featmap\", \"clrhead.prior_embeddings.weight\", \"clrhead.seg_decoder.conv.weight\", \"clrhead.seg_decoder.conv.bias\", \"clrhead.reg_modules.0.weight\", \"clrhead.reg_modules.0.bias\", \"clrhead.reg_modules.2.weight\", \"clrhead.reg_modules.2.bias\", \"clrhead.cls_modules.0.weight\", \"clrhead.cls_modules.0.bias\", \"clrhead.cls_modules.2.weight\", \"clrhead.cls_modules.2.bias\", \"clrhead.roi_gather.f_key.conv.weight\", \"clrhead.roi_gather.f_key.bn.weight\", \"clrhead.roi_gather.f_key.bn.bias\", \"clrhead.roi_gather.f_key.bn.running_mean\", \"clrhead.roi_gather.f_key.bn.running_var\", \"clrhead.roi_gather.f_query.0.weight\", \"clrhead.roi_gather.f_query.0.bias\", \"clrhead.roi_gather.f_value.weight\", \"clrhead.roi_gather.f_value.bias\", \"clrhead.roi_gather.W.weight\", \"clrhead.roi_gather.W.bias\", \"clrhead.roi_gather.convs.0.conv.weight\", \"clrhead.roi_gather.convs.0.bn.weight\", \"clrhead.roi_gather.convs.0.bn.bias\", \"clrhead.roi_gather.convs.0.bn.running_mean\", \"clrhead.roi_gather.convs.0.bn.running_var\", \"clrhead.roi_gather.convs.1.conv.weight\", \"clrhead.roi_gather.convs.1.bn.weight\", \"clrhead.roi_gather.convs.1.bn.bias\", \"clrhead.roi_gather.convs.1.bn.running_mean\", \"clrhead.roi_gather.convs.1.bn.running_var\", \"clrhead.roi_gather.convs.2.conv.weight\", \"clrhead.roi_gather.convs.2.bn.weight\", \"clrhead.roi_gather.convs.2.bn.bias\", \"clrhead.roi_gather.convs.2.bn.running_mean\", \"clrhead.roi_gather.convs.2.bn.running_var\", \"clrhead.roi_gather.catconv.0.conv.weight\", \"clrhead.roi_gather.catconv.0.bn.weight\", \"clrhead.roi_gather.catconv.0.bn.bias\", \"clrhead.roi_gather.catconv.0.bn.running_mean\", \"clrhead.roi_gather.catconv.0.bn.running_var\", \"clrhead.roi_gather.catconv.1.conv.weight\", \"clrhead.roi_gather.catconv.1.bn.weight\", \"clrhead.roi_gather.catconv.1.bn.bias\", \"clrhead.roi_gather.catconv.1.bn.running_mean\", \"clrhead.roi_gather.catconv.1.bn.running_var\", \"clrhead.roi_gather.catconv.2.conv.weight\", \"clrhead.roi_gather.catconv.2.bn.weight\", \"clrhead.roi_gather.catconv.2.bn.bias\", \"clrhead.roi_gather.catconv.2.bn.running_mean\", \"clrhead.roi_gather.catconv.2.bn.running_var\", \"clrhead.roi_gather.fc.weight\", \"clrhead.roi_gather.fc.bias\", \"clrhead.roi_gather.fc_norm.weight\", \"clrhead.roi_gather.fc_norm.bias\", \"clrhead.reg_layers.weight\", \"clrhead.reg_layers.bias\", \"clrhead.cls_layers.weight\", \"clrhead.cls_layers.bias\", \"clrhead.criterion.weight\", \"offset_2.weight\", \"offset_1.weight\", \"offset_0.weight\". \n\tUnexpected key(s) in state_dict: \"heads.sample_x_indexs\", \"heads.prior_feat_ys\", \"heads.prior_ys\", \"heads.priors\", \"heads.priors_on_featmap\", \"heads.prior_embeddings.weight\", \"heads.seg_decoder.conv.weight\", \"heads.seg_decoder.conv.bias\", \"heads.reg_modules.0.weight\", \"heads.reg_modules.0.bias\", \"heads.reg_modules.2.weight\", \"heads.reg_modules.2.bias\", \"heads.cls_modules.0.weight\", \"heads.cls_modules.0.bias\", \"heads.cls_modules.2.weight\", \"heads.cls_modules.2.bias\", \"heads.roi_gather.f_key.conv.weight\", \"heads.roi_gather.f_key.bn.weight\", \"heads.roi_gather.f_key.bn.bias\", \"heads.roi_gather.f_key.bn.running_mean\", \"heads.roi_gather.f_key.bn.running_var\", \"heads.roi_gather.f_key.bn.num_batches_tracked\", \"heads.roi_gather.f_query.0.weight\", \"heads.roi_gather.f_query.0.bias\", \"heads.roi_gather.f_value.weight\", \"heads.roi_gather.f_value.bias\", \"heads.roi_gather.W.weight\", \"heads.roi_gather.W.bias\", \"heads.roi_gather.convs.0.conv.weight\", \"heads.roi_gather.convs.0.bn.weight\", \"heads.roi_gather.convs.0.bn.bias\", \"heads.roi_gather.convs.0.bn.running_mean\", \"heads.roi_gather.convs.0.bn.running_var\", \"heads.roi_gather.convs.0.bn.num_batches_tracked\", \"heads.roi_gather.convs.1.conv.weight\", \"heads.roi_gather.convs.1.bn.weight\", \"heads.roi_gather.convs.1.bn.bias\", \"heads.roi_gather.convs.1.bn.running_mean\", \"heads.roi_gather.convs.1.bn.running_var\", \"heads.roi_gather.convs.1.bn.num_batches_tracked\", \"heads.roi_gather.convs.2.conv.weight\", \"heads.roi_gather.convs.2.bn.weight\", \"heads.roi_gather.convs.2.bn.bias\", \"heads.roi_gather.convs.2.bn.running_mean\", \"heads.roi_gather.convs.2.bn.running_var\", \"heads.roi_gather.convs.2.bn.num_batches_tracked\", \"heads.roi_gather.catconv.0.conv.weight\", \"heads.roi_gather.catconv.0.bn.weight\", \"heads.roi_gather.catconv.0.bn.bias\", \"heads.roi_gather.catconv.0.bn.running_mean\", \"heads.roi_gather.catconv.0.bn.running_var\", \"heads.roi_gather.catconv.0.bn.num_batches_tracked\", \"heads.roi_gather.catconv.1.conv.weight\", \"heads.roi_gather.catconv.1.bn.weight\", \"heads.roi_gather.catconv.1.bn.bias\", \"heads.roi_gather.catconv.1.bn.running_mean\", \"heads.roi_gather.catconv.1.bn.running_var\", \"heads.roi_gather.catconv.1.bn.num_batches_tracked\", \"heads.roi_gather.catconv.2.conv.weight\", \"heads.roi_gather.catconv.2.bn.weight\", \"heads.roi_gather.catconv.2.bn.bias\", \"heads.roi_gather.catconv.2.bn.running_mean\", \"heads.roi_gather.catconv.2.bn.running_var\", \"heads.roi_gather.catconv.2.bn.num_batches_tracked\", \"heads.roi_gather.fc.weight\", \"heads.roi_gather.fc.bias\", \"heads.roi_gather.fc_norm.weight\", \"heads.roi_gather.fc_norm.bias\", \"heads.reg_layers.weight\", \"heads.reg_layers.bias\", \"heads.cls_layers.weight\", \"heads.cls_layers.bias\", \"heads.criterion.weight\", \"neck.neck.h1.conv1.conv.weight\", \"neck.neck.h1.conv1.norm.weight\", \"neck.neck.h1.conv1.norm.bias\", \"neck.neck.h1.conv1.norm.running_mean\", \"neck.neck.h1.conv1.norm.running_var\", \"neck.neck.h1.conv1.norm.num_batches_tracked\", \"neck.neck.h1.conv2.conv.weight\", \"neck.neck.h1.conv2.norm.weight\", \"neck.neck.h1.conv2.norm.bias\", \"neck.neck.h1.conv2.norm.running_mean\", \"neck.neck.h1.conv2.norm.running_var\", \"neck.neck.h1.conv2.norm.num_batches_tracked\", \"neck.neck.h1.conv3.conv.weight\", \"neck.neck.h1.conv3.norm.weight\", \"neck.neck.h1.conv3.norm.bias\", \"neck.neck.h1.conv3.norm.running_mean\", \"neck.neck.h1.conv3.norm.running_var\", \"neck.neck.h1.conv3.norm.num_batches_tracked\", \"neck.neck.h1.res_m.0.res_m.0.conv.weight\", \"neck.neck.h1.res_m.0.res_m.0.norm.weight\", \"neck.neck.h1.res_m.0.res_m.0.norm.bias\", \"neck.neck.h1.res_m.0.res_m.0.norm.running_mean\", \"neck.neck.h1.res_m.0.res_m.0.norm.running_var\", \"neck.neck.h1.res_m.0.res_m.0.norm.num_batches_tracked\", \"neck.neck.h1.res_m.0.res_m.1.conv.weight\", \"neck.neck.h1.res_m.0.res_m.1.norm.weight\", \"neck.neck.h1.res_m.0.res_m.1.norm.bias\", \"neck.neck.h1.res_m.0.res_m.1.norm.running_mean\", \"neck.neck.h1.res_m.0.res_m.1.norm.running_var\", \"neck.neck.h1.res_m.0.res_m.1.norm.num_batches_tracked\", \"neck.neck.h2.conv1.conv.weight\", \"neck.neck.h2.conv1.norm.weight\", \"neck.neck.h2.conv1.norm.bias\", \"neck.neck.h2.conv1.norm.running_mean\", \"neck.neck.h2.conv1.norm.running_var\", \"neck.neck.h2.conv1.norm.num_batches_tracked\", \"neck.neck.h2.conv2.conv.weight\", \"neck.neck.h2.conv2.norm.weight\", \"neck.neck.h2.conv2.norm.bias\", \"neck.neck.h2.conv2.norm.running_mean\", \"neck.neck.h2.conv2.norm.running_var\", \"neck.neck.h2.conv2.norm.num_batches_tracked\", \"neck.neck.h2.conv3.conv.weight\", \"neck.neck.h2.conv3.norm.weight\", \"neck.neck.h2.conv3.norm.bias\", \"neck.neck.h2.conv3.norm.running_mean\", \"neck.neck.h2.conv3.norm.running_var\", \"neck.neck.h2.conv3.norm.num_batches_tracked\", \"neck.neck.h2.res_m.0.res_m.0.conv.weight\", \"neck.neck.h2.res_m.0.res_m.0.norm.weight\", \"neck.neck.h2.res_m.0.res_m.0.norm.bias\", \"neck.neck.h2.res_m.0.res_m.0.norm.running_mean\", \"neck.neck.h2.res_m.0.res_m.0.norm.running_var\", \"neck.neck.h2.res_m.0.res_m.0.norm.num_batches_tracked\", \"neck.neck.h2.res_m.0.res_m.1.conv.weight\", \"neck.neck.h2.res_m.0.res_m.1.norm.weight\", \"neck.neck.h2.res_m.0.res_m.1.norm.bias\", \"neck.neck.h2.res_m.0.res_m.1.norm.running_mean\", \"neck.neck.h2.res_m.0.res_m.1.norm.running_var\", \"neck.neck.h2.res_m.0.res_m.1.norm.num_batches_tracked\", \"neck.neck.h3.conv.weight\", \"neck.neck.h3.norm.weight\", \"neck.neck.h3.norm.bias\", \"neck.neck.h3.norm.running_mean\", \"neck.neck.h3.norm.running_var\", \"neck.neck.h3.norm.num_batches_tracked\", \"neck.neck.h4.conv1.conv.weight\", \"neck.neck.h4.conv1.norm.weight\", \"neck.neck.h4.conv1.norm.bias\", \"neck.neck.h4.conv1.norm.running_mean\", \"neck.neck.h4.conv1.norm.running_var\", \"neck.neck.h4.conv1.norm.num_batches_tracked\", \"neck.neck.h4.conv2.conv.weight\", \"neck.neck.h4.conv2.norm.weight\", \"neck.neck.h4.conv2.norm.bias\", \"neck.neck.h4.conv2.norm.running_mean\", \"neck.neck.h4.conv2.norm.running_var\", \"neck.neck.h4.conv2.norm.num_batches_tracked\", \"neck.neck.h4.conv3.conv.weight\", \"neck.neck.h4.conv3.norm.weight\", \"neck.neck.h4.conv3.norm.bias\", \"neck.neck.h4.conv3.norm.running_mean\", \"neck.neck.h4.conv3.norm.running_var\", \"neck.neck.h4.conv3.norm.num_batches_tracked\", \"neck.neck.h4.res_m.0.res_m.0.conv.weight\", \"neck.neck.h4.res_m.0.res_m.0.norm.weight\", \"neck.neck.h4.res_m.0.res_m.0.norm.bias\", \"neck.neck.h4.res_m.0.res_m.0.norm.running_mean\", \"neck.neck.h4.res_m.0.res_m.0.norm.running_var\", \"neck.neck.h4.res_m.0.res_m.0.norm.num_batches_tracked\", \"neck.neck.h4.res_m.0.res_m.1.conv.weight\", \"neck.neck.h4.res_m.0.res_m.1.norm.weight\", \"neck.neck.h4.res_m.0.res_m.1.norm.bias\", \"neck.neck.h4.res_m.0.res_m.1.norm.running_mean\", \"neck.neck.h4.res_m.0.res_m.1.norm.running_var\", \"neck.neck.h4.res_m.0.res_m.1.norm.num_batches_tracked\", \"neck.neck.h5.conv.weight\", \"neck.neck.h5.norm.weight\", \"neck.neck.h5.norm.bias\", \"neck.neck.h5.norm.running_mean\", \"neck.neck.h5.norm.running_var\", \"neck.neck.h5.norm.num_batches_tracked\", \"neck.neck.h6.conv1.conv.weight\", \"neck.neck.h6.conv1.norm.weight\", \"neck.neck.h6.conv1.norm.bias\", \"neck.neck.h6.conv1.norm.running_mean\", \"neck.neck.h6.conv1.norm.running_var\", \"neck.neck.h6.conv1.norm.num_batches_tracked\", \"neck.neck.h6.conv2.conv.weight\", \"neck.neck.h6.conv2.norm.weight\", \"neck.neck.h6.conv2.norm.bias\", \"neck.neck.h6.conv2.norm.running_mean\", \"neck.neck.h6.conv2.norm.running_var\", \"neck.neck.h6.conv2.norm.num_batches_tracked\", \"neck.neck.h6.conv3.conv.weight\", \"neck.neck.h6.conv3.norm.weight\", \"neck.neck.h6.conv3.norm.bias\", \"neck.neck.h6.conv3.norm.running_mean\", \"neck.neck.h6.conv3.norm.running_var\", \"neck.neck.h6.conv3.norm.num_batches_tracked\", \"neck.neck.h6.res_m.0.res_m.0.conv.weight\", \"neck.neck.h6.res_m.0.res_m.0.norm.weight\", \"neck.neck.h6.res_m.0.res_m.0.norm.bias\", \"neck.neck.h6.res_m.0.res_m.0.norm.running_mean\", \"neck.neck.h6.res_m.0.res_m.0.norm.running_var\", \"neck.neck.h6.res_m.0.res_m.0.norm.num_batches_tracked\", \"neck.neck.h6.res_m.0.res_m.1.conv.weight\", \"neck.neck.h6.res_m.0.res_m.1.norm.weight\", \"neck.neck.h6.res_m.0.res_m.1.norm.bias\", \"neck.neck.h6.res_m.0.res_m.1.norm.running_mean\", \"neck.neck.h6.res_m.0.res_m.1.norm.running_var\", \"neck.neck.h6.res_m.0.res_m.1.norm.num_batches_tracked\", \"neck.offset_2.weight\", \"neck.offset_1.weight\", \"neck.offset_0.weight\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m     new_key \u001b[38;5;241m=\u001b[39m k\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodule.\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# remove 'module.'\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     new_state_dict[new_key] \u001b[38;5;241m=\u001b[39m v\n\u001b[0;32m----> 8\u001b[0m \u001b[43mclrnet_yolo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_state_dict\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/clrnet/lib/python3.8/site-packages/torch/nn/modules/module.py:1223\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   1218\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   1219\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   1220\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(k) \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[1;32m   1222\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 1223\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   1224\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   1225\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for YOLOL:\n\tMissing key(s) in state_dict: \"neck.h1.conv1.conv.weight\", \"neck.h1.conv1.norm.weight\", \"neck.h1.conv1.norm.bias\", \"neck.h1.conv1.norm.running_mean\", \"neck.h1.conv1.norm.running_var\", \"neck.h1.conv2.conv.weight\", \"neck.h1.conv2.norm.weight\", \"neck.h1.conv2.norm.bias\", \"neck.h1.conv2.norm.running_mean\", \"neck.h1.conv2.norm.running_var\", \"neck.h1.conv3.conv.weight\", \"neck.h1.conv3.norm.weight\", \"neck.h1.conv3.norm.bias\", \"neck.h1.conv3.norm.running_mean\", \"neck.h1.conv3.norm.running_var\", \"neck.h1.res_m.0.res_m.0.conv.weight\", \"neck.h1.res_m.0.res_m.0.norm.weight\", \"neck.h1.res_m.0.res_m.0.norm.bias\", \"neck.h1.res_m.0.res_m.0.norm.running_mean\", \"neck.h1.res_m.0.res_m.0.norm.running_var\", \"neck.h1.res_m.0.res_m.1.conv.weight\", \"neck.h1.res_m.0.res_m.1.norm.weight\", \"neck.h1.res_m.0.res_m.1.norm.bias\", \"neck.h1.res_m.0.res_m.1.norm.running_mean\", \"neck.h1.res_m.0.res_m.1.norm.running_var\", \"neck.h2.conv1.conv.weight\", \"neck.h2.conv1.norm.weight\", \"neck.h2.conv1.norm.bias\", \"neck.h2.conv1.norm.running_mean\", \"neck.h2.conv1.norm.running_var\", \"neck.h2.conv2.conv.weight\", \"neck.h2.conv2.norm.weight\", \"neck.h2.conv2.norm.bias\", \"neck.h2.conv2.norm.running_mean\", \"neck.h2.conv2.norm.running_var\", \"neck.h2.conv3.conv.weight\", \"neck.h2.conv3.norm.weight\", \"neck.h2.conv3.norm.bias\", \"neck.h2.conv3.norm.running_mean\", \"neck.h2.conv3.norm.running_var\", \"neck.h2.res_m.0.res_m.0.conv.weight\", \"neck.h2.res_m.0.res_m.0.norm.weight\", \"neck.h2.res_m.0.res_m.0.norm.bias\", \"neck.h2.res_m.0.res_m.0.norm.running_mean\", \"neck.h2.res_m.0.res_m.0.norm.running_var\", \"neck.h2.res_m.0.res_m.1.conv.weight\", \"neck.h2.res_m.0.res_m.1.norm.weight\", \"neck.h2.res_m.0.res_m.1.norm.bias\", \"neck.h2.res_m.0.res_m.1.norm.running_mean\", \"neck.h2.res_m.0.res_m.1.norm.running_var\", \"neck.h3.conv.weight\", \"neck.h3.norm.weight\", \"neck.h3.norm.bias\", \"neck.h3.norm.running_mean\", \"neck.h3.norm.running_var\", \"neck.h4.conv1.conv.weight\", \"neck.h4.conv1.norm.weight\", \"neck.h4.conv1.norm.bias\", \"neck.h4.conv1.norm.running_mean\", \"neck.h4.conv1.norm.running_var\", \"neck.h4.conv2.conv.weight\", \"neck.h4.conv2.norm.weight\", \"neck.h4.conv2.norm.bias\", \"neck.h4.conv2.norm.running_mean\", \"neck.h4.conv2.norm.running_var\", \"neck.h4.conv3.conv.weight\", \"neck.h4.conv3.norm.weight\", \"neck.h4.conv3.norm.bias\", \"neck.h4.conv3.norm.running_mean\", \"neck.h4.conv3.norm.running_var\", \"neck.h4.res_m.0.res_m.0.conv.weight\", \"neck.h4.res_m.0.res_m.0.norm.weight\", \"neck.h4.res_m.0.res_m.0.norm.bias\", \"neck.h4.res_m.0.res_m.0.norm.running_mean\", \"neck.h4.res_m.0.res_m.0.norm.running_var\", \"neck.h4.res_m.0.res_m.1.conv.weight\", \"neck.h4.res_m.0.res_m.1.norm.weight\", \"neck.h4.res_m.0.res_m.1.norm.bias\", \"neck.h4.res_m.0.res_m.1.norm.running_mean\", \"neck.h4.res_m.0.res_m.1.norm.running_var\", \"neck.h5.conv.weight\", \"neck.h5.norm.weight\", \"neck.h5.norm.bias\", \"neck.h5.norm.running_mean\", \"neck.h5.norm.running_var\", \"neck.h6.conv1.conv.weight\", \"neck.h6.conv1.norm.weight\", \"neck.h6.conv1.norm.bias\", \"neck.h6.conv1.norm.running_mean\", \"neck.h6.conv1.norm.running_var\", \"neck.h6.conv2.conv.weight\", \"neck.h6.conv2.norm.weight\", \"neck.h6.conv2.norm.bias\", \"neck.h6.conv2.norm.running_mean\", \"neck.h6.conv2.norm.running_var\", \"neck.h6.conv3.conv.weight\", \"neck.h6.conv3.norm.weight\", \"neck.h6.conv3.norm.bias\", \"neck.h6.conv3.norm.running_mean\", \"neck.h6.conv3.norm.running_var\", \"neck.h6.res_m.0.res_m.0.conv.weight\", \"neck.h6.res_m.0.res_m.0.norm.weight\", \"neck.h6.res_m.0.res_m.0.norm.bias\", \"neck.h6.res_m.0.res_m.0.norm.running_mean\", \"neck.h6.res_m.0.res_m.0.norm.running_var\", \"neck.h6.res_m.0.res_m.1.conv.weight\", \"neck.h6.res_m.0.res_m.1.norm.weight\", \"neck.h6.res_m.0.res_m.1.norm.bias\", \"neck.h6.res_m.0.res_m.1.norm.running_mean\", \"neck.h6.res_m.0.res_m.1.norm.running_var\", \"yolo_head.dfl.conv.weight\", \"yolo_head.cls.0.0.conv.weight\", \"yolo_head.cls.0.0.norm.weight\", \"yolo_head.cls.0.0.norm.bias\", \"yolo_head.cls.0.0.norm.running_mean\", \"yolo_head.cls.0.0.norm.running_var\", \"yolo_head.cls.0.1.conv.weight\", \"yolo_head.cls.0.1.norm.weight\", \"yolo_head.cls.0.1.norm.bias\", \"yolo_head.cls.0.1.norm.running_mean\", \"yolo_head.cls.0.1.norm.running_var\", \"yolo_head.cls.0.2.weight\", \"yolo_head.cls.0.2.bias\", \"yolo_head.cls.1.0.conv.weight\", \"yolo_head.cls.1.0.norm.weight\", \"yolo_head.cls.1.0.norm.bias\", \"yolo_head.cls.1.0.norm.running_mean\", \"yolo_head.cls.1.0.norm.running_var\", \"yolo_head.cls.1.1.conv.weight\", \"yolo_head.cls.1.1.norm.weight\", \"yolo_head.cls.1.1.norm.bias\", \"yolo_head.cls.1.1.norm.running_mean\", \"yolo_head.cls.1.1.norm.running_var\", \"yolo_head.cls.1.2.weight\", \"yolo_head.cls.1.2.bias\", \"yolo_head.cls.2.0.conv.weight\", \"yolo_head.cls.2.0.norm.weight\", \"yolo_head.cls.2.0.norm.bias\", \"yolo_head.cls.2.0.norm.running_mean\", \"yolo_head.cls.2.0.norm.running_var\", \"yolo_head.cls.2.1.conv.weight\", \"yolo_head.cls.2.1.norm.weight\", \"yolo_head.cls.2.1.norm.bias\", \"yolo_head.cls.2.1.norm.running_mean\", \"yolo_head.cls.2.1.norm.running_var\", \"yolo_head.cls.2.2.weight\", \"yolo_head.cls.2.2.bias\", \"yolo_head.box.0.0.conv.weight\", \"yolo_head.box.0.0.norm.weight\", \"yolo_head.box.0.0.norm.bias\", \"yolo_head.box.0.0.norm.running_mean\", \"yolo_head.box.0.0.norm.running_var\", \"yolo_head.box.0.1.conv.weight\", \"yolo_head.box.0.1.norm.weight\", \"yolo_head.box.0.1.norm.bias\", \"yolo_head.box.0.1.norm.running_mean\", \"yolo_head.box.0.1.norm.running_var\", \"yolo_head.box.0.2.weight\", \"yolo_head.box.0.2.bias\", \"yolo_head.box.1.0.conv.weight\", \"yolo_head.box.1.0.norm.weight\", \"yolo_head.box.1.0.norm.bias\", \"yolo_head.box.1.0.norm.running_mean\", \"yolo_head.box.1.0.norm.running_var\", \"yolo_head.box.1.1.conv.weight\", \"yolo_head.box.1.1.norm.weight\", \"yolo_head.box.1.1.norm.bias\", \"yolo_head.box.1.1.norm.running_mean\", \"yolo_head.box.1.1.norm.running_var\", \"yolo_head.box.1.2.weight\", \"yolo_head.box.1.2.bias\", \"yolo_head.box.2.0.conv.weight\", \"yolo_head.box.2.0.norm.weight\", \"yolo_head.box.2.0.norm.bias\", \"yolo_head.box.2.0.norm.running_mean\", \"yolo_head.box.2.0.norm.running_var\", \"yolo_head.box.2.1.conv.weight\", \"yolo_head.box.2.1.norm.weight\", \"yolo_head.box.2.1.norm.bias\", \"yolo_head.box.2.1.norm.running_mean\", \"yolo_head.box.2.1.norm.running_var\", \"yolo_head.box.2.2.weight\", \"yolo_head.box.2.2.bias\", \"clrhead.sample_x_indexs\", \"clrhead.prior_feat_ys\", \"clrhead.prior_ys\", \"clrhead.priors\", \"clrhead.priors_on_featmap\", \"clrhead.prior_embeddings.weight\", \"clrhead.seg_decoder.conv.weight\", \"clrhead.seg_decoder.conv.bias\", \"clrhead.reg_modules.0.weight\", \"clrhead.reg_modules.0.bias\", \"clrhead.reg_modules.2.weight\", \"clrhead.reg_modules.2.bias\", \"clrhead.cls_modules.0.weight\", \"clrhead.cls_modules.0.bias\", \"clrhead.cls_modules.2.weight\", \"clrhead.cls_modules.2.bias\", \"clrhead.roi_gather.f_key.conv.weight\", \"clrhead.roi_gather.f_key.bn.weight\", \"clrhead.roi_gather.f_key.bn.bias\", \"clrhead.roi_gather.f_key.bn.running_mean\", \"clrhead.roi_gather.f_key.bn.running_var\", \"clrhead.roi_gather.f_query.0.weight\", \"clrhead.roi_gather.f_query.0.bias\", \"clrhead.roi_gather.f_value.weight\", \"clrhead.roi_gather.f_value.bias\", \"clrhead.roi_gather.W.weight\", \"clrhead.roi_gather.W.bias\", \"clrhead.roi_gather.convs.0.conv.weight\", \"clrhead.roi_gather.convs.0.bn.weight\", \"clrhead.roi_gather.convs.0.bn.bias\", \"clrhead.roi_gather.convs.0.bn.running_mean\", \"clrhead.roi_gather.convs.0.bn.running_var\", \"clrhead.roi_gather.convs.1.conv.weight\", \"clrhead.roi_gather.convs.1.bn.weight\", \"clrhead.roi_gather.convs.1.bn.bias\", \"clrhead.roi_gather.convs.1.bn.running_mean\", \"clrhead.roi_gather.convs.1.bn.running_var\", \"clrhead.roi_gather.convs.2.conv.weight\", \"clrhead.roi_gather.convs.2.bn.weight\", \"clrhead.roi_gather.convs.2.bn.bias\", \"clrhead.roi_gather.convs.2.bn.running_mean\", \"clrhead.roi_gather.convs.2.bn.running_var\", \"clrhead.roi_gather.catconv.0.conv.weight\", \"clrhead.roi_gather.catconv.0.bn.weight\", \"clrhead.roi_gather.catconv.0.bn.bias\", \"clrhead.roi_gather.catconv.0.bn.running_mean\", \"clrhead.roi_gather.catconv.0.bn.running_var\", \"clrhead.roi_gather.catconv.1.conv.weight\", \"clrhead.roi_gather.catconv.1.bn.weight\", \"clrhead.roi_gather.catconv.1.bn.bias\", \"clrhead.roi_gather.catconv.1.bn.running_mean\", \"clrhead.roi_gather.catconv.1.bn.running_var\", \"clrhead.roi_gather.catconv.2.conv.weight\", \"clrhead.roi_gather.catconv.2.bn.weight\", \"clrhead.roi_gather.catconv.2.bn.bias\", \"clrhead.roi_gather.catconv.2.bn.running_mean\", \"clrhead.roi_gather.catconv.2.bn.running_var\", \"clrhead.roi_gather.fc.weight\", \"clrhead.roi_gather.fc.bias\", \"clrhead.roi_gather.fc_norm.weight\", \"clrhead.roi_gather.fc_norm.bias\", \"clrhead.reg_layers.weight\", \"clrhead.reg_layers.bias\", \"clrhead.cls_layers.weight\", \"clrhead.cls_layers.bias\", \"clrhead.criterion.weight\", \"offset_2.weight\", \"offset_1.weight\", \"offset_0.weight\". \n\tUnexpected key(s) in state_dict: \"heads.sample_x_indexs\", \"heads.prior_feat_ys\", \"heads.prior_ys\", \"heads.priors\", \"heads.priors_on_featmap\", \"heads.prior_embeddings.weight\", \"heads.seg_decoder.conv.weight\", \"heads.seg_decoder.conv.bias\", \"heads.reg_modules.0.weight\", \"heads.reg_modules.0.bias\", \"heads.reg_modules.2.weight\", \"heads.reg_modules.2.bias\", \"heads.cls_modules.0.weight\", \"heads.cls_modules.0.bias\", \"heads.cls_modules.2.weight\", \"heads.cls_modules.2.bias\", \"heads.roi_gather.f_key.conv.weight\", \"heads.roi_gather.f_key.bn.weight\", \"heads.roi_gather.f_key.bn.bias\", \"heads.roi_gather.f_key.bn.running_mean\", \"heads.roi_gather.f_key.bn.running_var\", \"heads.roi_gather.f_key.bn.num_batches_tracked\", \"heads.roi_gather.f_query.0.weight\", \"heads.roi_gather.f_query.0.bias\", \"heads.roi_gather.f_value.weight\", \"heads.roi_gather.f_value.bias\", \"heads.roi_gather.W.weight\", \"heads.roi_gather.W.bias\", \"heads.roi_gather.convs.0.conv.weight\", \"heads.roi_gather.convs.0.bn.weight\", \"heads.roi_gather.convs.0.bn.bias\", \"heads.roi_gather.convs.0.bn.running_mean\", \"heads.roi_gather.convs.0.bn.running_var\", \"heads.roi_gather.convs.0.bn.num_batches_tracked\", \"heads.roi_gather.convs.1.conv.weight\", \"heads.roi_gather.convs.1.bn.weight\", \"heads.roi_gather.convs.1.bn.bias\", \"heads.roi_gather.convs.1.bn.running_mean\", \"heads.roi_gather.convs.1.bn.running_var\", \"heads.roi_gather.convs.1.bn.num_batches_tracked\", \"heads.roi_gather.convs.2.conv.weight\", \"heads.roi_gather.convs.2.bn.weight\", \"heads.roi_gather.convs.2.bn.bias\", \"heads.roi_gather.convs.2.bn.running_mean\", \"heads.roi_gather.convs.2.bn.running_var\", \"heads.roi_gather.convs.2.bn.num_batches_tracked\", \"heads.roi_gather.catconv.0.conv.weight\", \"heads.roi_gather.catconv.0.bn.weight\", \"heads.roi_gather.catconv.0.bn.bias\", \"heads.roi_gather.catconv.0.bn.running_mean\", \"heads.roi_gather.catconv.0.bn.running_var\", \"heads.roi_gather.catconv.0.bn.num_batches_tracked\", \"heads.roi_gather.catconv.1.conv.weight\", \"heads.roi_gather.catconv.1.bn.weight\", \"heads.roi_gather.catconv.1.bn.bias\", \"heads.roi_gather.catconv.1.bn.running_mean\", \"heads.roi_gather.catconv.1.bn.running_var\", \"heads.roi_gather.catconv.1.bn.num_batches_tracked\", \"heads.roi_gather.catconv.2.conv.weight\", \"heads.roi_gather.catconv.2.bn.weight\", \"heads.roi_gather.catconv.2.bn.bias\", \"heads.roi_gather.catconv.2.bn.running_mean\", \"heads.roi_gather.catconv.2.bn.running_var\", \"heads.roi_gather.catconv.2.bn.num_batches_tracked\", \"heads.roi_gather.fc.weight\", \"heads.roi_gather.fc.bias\", \"heads.roi_gather.fc_norm.weight\", \"heads.roi_gather.fc_norm.bias\", \"heads.reg_layers.weight\", \"heads.reg_layers.bias\", \"heads.cls_layers.weight\", \"heads.cls_layers.bias\", \"heads.criterion.weight\", \"neck.neck.h1.conv1.conv.weight\", \"neck.neck.h1.conv1.norm.weight\", \"neck.neck.h1.conv1.norm.bias\", \"neck.neck.h1.conv1.norm.running_mean\", \"neck.neck.h1.conv1.norm.running_var\", \"neck.neck.h1.conv1.norm.num_batches_tracked\", \"neck.neck.h1.conv2.conv.weight\", \"neck.neck.h1.conv2.norm.weight\", \"neck.neck.h1.conv2.norm.bias\", \"neck.neck.h1.conv2.norm.running_mean\", \"neck.neck.h1.conv2.norm.running_var\", \"neck.neck.h1.conv2.norm.num_batches_tracked\", \"neck.neck.h1.conv3.conv.weight\", \"neck.neck.h1.conv3.norm.weight\", \"neck.neck.h1.conv3.norm.bias\", \"neck.neck.h1.conv3.norm.running_mean\", \"neck.neck.h1.conv3.norm.running_var\", \"neck.neck.h1.conv3.norm.num_batches_tracked\", \"neck.neck.h1.res_m.0.res_m.0.conv.weight\", \"neck.neck.h1.res_m.0.res_m.0.norm.weight\", \"neck.neck.h1.res_m.0.res_m.0.norm.bias\", \"neck.neck.h1.res_m.0.res_m.0.norm.running_mean\", \"neck.neck.h1.res_m.0.res_m.0.norm.running_var\", \"neck.neck.h1.res_m.0.res_m.0.norm.num_batches_tracked\", \"neck.neck.h1.res_m.0.res_m.1.conv.weight\", \"neck.neck.h1.res_m.0.res_m.1.norm.weight\", \"neck.neck.h1.res_m.0.res_m.1.norm.bias\", \"neck.neck.h1.res_m.0.res_m.1.norm.running_mean\", \"neck.neck.h1.res_m.0.res_m.1.norm.running_var\", \"neck.neck.h1.res_m.0.res_m.1.norm.num_batches_tracked\", \"neck.neck.h2.conv1.conv.weight\", \"neck.neck.h2.conv1.norm.weight\", \"neck.neck.h2.conv1.norm.bias\", \"neck.neck.h2.conv1.norm.running_mean\", \"neck.neck.h2.conv1.norm.running_var\", \"neck.neck.h2.conv1.norm.num_batches_tracked\", \"neck.neck.h2.conv2.conv.weight\", \"neck.neck.h2.conv2.norm.weight\", \"neck.neck.h2.conv2.norm.bias\", \"neck.neck.h2.conv2.norm.running_mean\", \"neck.neck.h2.conv2.norm.running_var\", \"neck.neck.h2.conv2.norm.num_batches_tracked\", \"neck.neck.h2.conv3.conv.weight\", \"neck.neck.h2.conv3.norm.weight\", \"neck.neck.h2.conv3.norm.bias\", \"neck.neck.h2.conv3.norm.running_mean\", \"neck.neck.h2.conv3.norm.running_var\", \"neck.neck.h2.conv3.norm.num_batches_tracked\", \"neck.neck.h2.res_m.0.res_m.0.conv.weight\", \"neck.neck.h2.res_m.0.res_m.0.norm.weight\", \"neck.neck.h2.res_m.0.res_m.0.norm.bias\", \"neck.neck.h2.res_m.0.res_m.0.norm.running_mean\", \"neck.neck.h2.res_m.0.res_m.0.norm.running_var\", \"neck.neck.h2.res_m.0.res_m.0.norm.num_batches_tracked\", \"neck.neck.h2.res_m.0.res_m.1.conv.weight\", \"neck.neck.h2.res_m.0.res_m.1.norm.weight\", \"neck.neck.h2.res_m.0.res_m.1.norm.bias\", \"neck.neck.h2.res_m.0.res_m.1.norm.running_mean\", \"neck.neck.h2.res_m.0.res_m.1.norm.running_var\", \"neck.neck.h2.res_m.0.res_m.1.norm.num_batches_tracked\", \"neck.neck.h3.conv.weight\", \"neck.neck.h3.norm.weight\", \"neck.neck.h3.norm.bias\", \"neck.neck.h3.norm.running_mean\", \"neck.neck.h3.norm.running_var\", \"neck.neck.h3.norm.num_batches_tracked\", \"neck.neck.h4.conv1.conv.weight\", \"neck.neck.h4.conv1.norm.weight\", \"neck.neck.h4.conv1.norm.bias\", \"neck.neck.h4.conv1.norm.running_mean\", \"neck.neck.h4.conv1.norm.running_var\", \"neck.neck.h4.conv1.norm.num_batches_tracked\", \"neck.neck.h4.conv2.conv.weight\", \"neck.neck.h4.conv2.norm.weight\", \"neck.neck.h4.conv2.norm.bias\", \"neck.neck.h4.conv2.norm.running_mean\", \"neck.neck.h4.conv2.norm.running_var\", \"neck.neck.h4.conv2.norm.num_batches_tracked\", \"neck.neck.h4.conv3.conv.weight\", \"neck.neck.h4.conv3.norm.weight\", \"neck.neck.h4.conv3.norm.bias\", \"neck.neck.h4.conv3.norm.running_mean\", \"neck.neck.h4.conv3.norm.running_var\", \"neck.neck.h4.conv3.norm.num_batches_tracked\", \"neck.neck.h4.res_m.0.res_m.0.conv.weight\", \"neck.neck.h4.res_m.0.res_m.0.norm.weight\", \"neck.neck.h4.res_m.0.res_m.0.norm.bias\", \"neck.neck.h4.res_m.0.res_m.0.norm.running_mean\", \"neck.neck.h4.res_m.0.res_m.0.norm.running_var\", \"neck.neck.h4.res_m.0.res_m.0.norm.num_batches_tracked\", \"neck.neck.h4.res_m.0.res_m.1.conv.weight\", \"neck.neck.h4.res_m.0.res_m.1.norm.weight\", \"neck.neck.h4.res_m.0.res_m.1.norm.bias\", \"neck.neck.h4.res_m.0.res_m.1.norm.running_mean\", \"neck.neck.h4.res_m.0.res_m.1.norm.running_var\", \"neck.neck.h4.res_m.0.res_m.1.norm.num_batches_tracked\", \"neck.neck.h5.conv.weight\", \"neck.neck.h5.norm.weight\", \"neck.neck.h5.norm.bias\", \"neck.neck.h5.norm.running_mean\", \"neck.neck.h5.norm.running_var\", \"neck.neck.h5.norm.num_batches_tracked\", \"neck.neck.h6.conv1.conv.weight\", \"neck.neck.h6.conv1.norm.weight\", \"neck.neck.h6.conv1.norm.bias\", \"neck.neck.h6.conv1.norm.running_mean\", \"neck.neck.h6.conv1.norm.running_var\", \"neck.neck.h6.conv1.norm.num_batches_tracked\", \"neck.neck.h6.conv2.conv.weight\", \"neck.neck.h6.conv2.norm.weight\", \"neck.neck.h6.conv2.norm.bias\", \"neck.neck.h6.conv2.norm.running_mean\", \"neck.neck.h6.conv2.norm.running_var\", \"neck.neck.h6.conv2.norm.num_batches_tracked\", \"neck.neck.h6.conv3.conv.weight\", \"neck.neck.h6.conv3.norm.weight\", \"neck.neck.h6.conv3.norm.bias\", \"neck.neck.h6.conv3.norm.running_mean\", \"neck.neck.h6.conv3.norm.running_var\", \"neck.neck.h6.conv3.norm.num_batches_tracked\", \"neck.neck.h6.res_m.0.res_m.0.conv.weight\", \"neck.neck.h6.res_m.0.res_m.0.norm.weight\", \"neck.neck.h6.res_m.0.res_m.0.norm.bias\", \"neck.neck.h6.res_m.0.res_m.0.norm.running_mean\", \"neck.neck.h6.res_m.0.res_m.0.norm.running_var\", \"neck.neck.h6.res_m.0.res_m.0.norm.num_batches_tracked\", \"neck.neck.h6.res_m.0.res_m.1.conv.weight\", \"neck.neck.h6.res_m.0.res_m.1.norm.weight\", \"neck.neck.h6.res_m.0.res_m.1.norm.bias\", \"neck.neck.h6.res_m.0.res_m.1.norm.running_mean\", \"neck.neck.h6.res_m.0.res_m.1.norm.running_var\", \"neck.neck.h6.res_m.0.res_m.1.norm.num_batches_tracked\", \"neck.offset_2.weight\", \"neck.offset_1.weight\", \"neck.offset_0.weight\". "
     ]
    }
   ],
   "source": [
    "state_dict = torch.load('/home/mmm9886/Desktop/Capstone_Implementation/clrnet/work_dirs/clr/r18_culane/20250111_141413_lr_6e-04_b_24_________/ckpt/9.pth')['net']\n",
    "from collections import OrderedDict\n",
    "new_state_dict = OrderedDict()\n",
    "for k, v in state_dict.items():\n",
    "    new_key = k.replace(\"module.\", \"\")  # remove 'module.'\n",
    "    new_state_dict[new_key] = v\n",
    "    \n",
    "clrnet_yolo.load_state_dict(new_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "YOLOL(\n",
       "  (backbone): DarkNet(\n",
       "    (p1): Sequential(\n",
       "      (0): Conv(\n",
       "        (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (norm): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (relu): SiLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (p2): Sequential(\n",
       "      (0): Conv(\n",
       "        (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (norm): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (relu): SiLU(inplace=True)\n",
       "      )\n",
       "      (1): CSP(\n",
       "        (conv1): Conv(\n",
       "          (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (relu): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv2): Conv(\n",
       "          (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (relu): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv3): Conv(\n",
       "          (conv): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (relu): SiLU(inplace=True)\n",
       "        )\n",
       "        (res_m): ModuleList(\n",
       "          (0): Residual(\n",
       "            (res_m): Sequential(\n",
       "              (0): Conv(\n",
       "                (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (norm): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (relu): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv(\n",
       "                (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (norm): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (relu): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (p3): Sequential(\n",
       "      (0): Conv(\n",
       "        (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (norm): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (relu): SiLU(inplace=True)\n",
       "      )\n",
       "      (1): CSP(\n",
       "        (conv1): Conv(\n",
       "          (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (relu): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv2): Conv(\n",
       "          (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (relu): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv3): Conv(\n",
       "          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (relu): SiLU(inplace=True)\n",
       "        )\n",
       "        (res_m): ModuleList(\n",
       "          (0): Residual(\n",
       "            (res_m): Sequential(\n",
       "              (0): Conv(\n",
       "                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (norm): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (relu): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv(\n",
       "                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (norm): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (relu): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (1): Residual(\n",
       "            (res_m): Sequential(\n",
       "              (0): Conv(\n",
       "                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (norm): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (relu): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv(\n",
       "                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (norm): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (relu): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (p4): Sequential(\n",
       "      (0): Conv(\n",
       "        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (norm): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (relu): SiLU(inplace=True)\n",
       "      )\n",
       "      (1): CSP(\n",
       "        (conv1): Conv(\n",
       "          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (relu): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv2): Conv(\n",
       "          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (relu): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv3): Conv(\n",
       "          (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (relu): SiLU(inplace=True)\n",
       "        )\n",
       "        (res_m): ModuleList(\n",
       "          (0): Residual(\n",
       "            (res_m): Sequential(\n",
       "              (0): Conv(\n",
       "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (norm): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (relu): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv(\n",
       "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (norm): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (relu): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (1): Residual(\n",
       "            (res_m): Sequential(\n",
       "              (0): Conv(\n",
       "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (norm): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (relu): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv(\n",
       "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (norm): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (relu): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (p5): Sequential(\n",
       "      (0): Conv(\n",
       "        (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (norm): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (relu): SiLU(inplace=True)\n",
       "      )\n",
       "      (1): CSP(\n",
       "        (conv1): Conv(\n",
       "          (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (relu): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv2): Conv(\n",
       "          (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (relu): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv3): Conv(\n",
       "          (conv): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (relu): SiLU(inplace=True)\n",
       "        )\n",
       "        (res_m): ModuleList(\n",
       "          (0): Residual(\n",
       "            (res_m): Sequential(\n",
       "              (0): Conv(\n",
       "                (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (norm): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (relu): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv(\n",
       "                (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (norm): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (relu): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): SPP(\n",
       "        (conv1): Conv(\n",
       "          (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (relu): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv2): Conv(\n",
       "          (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (relu): SiLU(inplace=True)\n",
       "        )\n",
       "        (res_m): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (neck): DarkFPN(\n",
       "    (up): Upsample(scale_factor=2.0, mode=nearest)\n",
       "    (h1): CSP(\n",
       "      (conv1): Conv(\n",
       "        (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (relu): SiLU(inplace=True)\n",
       "      )\n",
       "      (conv2): Conv(\n",
       "        (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (relu): SiLU(inplace=True)\n",
       "      )\n",
       "      (conv3): Conv(\n",
       "        (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (relu): SiLU(inplace=True)\n",
       "      )\n",
       "      (res_m): ModuleList(\n",
       "        (0): Residual(\n",
       "          (res_m): Sequential(\n",
       "            (0): Conv(\n",
       "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (norm): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (relu): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv(\n",
       "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (norm): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (relu): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (h2): CSP(\n",
       "      (conv1): Conv(\n",
       "        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (relu): SiLU(inplace=True)\n",
       "      )\n",
       "      (conv2): Conv(\n",
       "        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (relu): SiLU(inplace=True)\n",
       "      )\n",
       "      (conv3): Conv(\n",
       "        (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (relu): SiLU(inplace=True)\n",
       "      )\n",
       "      (res_m): ModuleList(\n",
       "        (0): Residual(\n",
       "          (res_m): Sequential(\n",
       "            (0): Conv(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (norm): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (relu): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (norm): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (relu): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (h3): Conv(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (norm): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (relu): SiLU(inplace=True)\n",
       "    )\n",
       "    (h4): CSP(\n",
       "      (conv1): Conv(\n",
       "        (conv): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (relu): SiLU(inplace=True)\n",
       "      )\n",
       "      (conv2): Conv(\n",
       "        (conv): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (relu): SiLU(inplace=True)\n",
       "      )\n",
       "      (conv3): Conv(\n",
       "        (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (relu): SiLU(inplace=True)\n",
       "      )\n",
       "      (res_m): ModuleList(\n",
       "        (0): Residual(\n",
       "          (res_m): Sequential(\n",
       "            (0): Conv(\n",
       "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (norm): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (relu): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv(\n",
       "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (norm): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (relu): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (h5): Conv(\n",
       "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (norm): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (relu): SiLU(inplace=True)\n",
       "    )\n",
       "    (h6): CSP(\n",
       "      (conv1): Conv(\n",
       "        (conv): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (relu): SiLU(inplace=True)\n",
       "      )\n",
       "      (conv2): Conv(\n",
       "        (conv): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (relu): SiLU(inplace=True)\n",
       "      )\n",
       "      (conv3): Conv(\n",
       "        (conv): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (relu): SiLU(inplace=True)\n",
       "      )\n",
       "      (res_m): ModuleList(\n",
       "        (0): Residual(\n",
       "          (res_m): Sequential(\n",
       "            (0): Conv(\n",
       "              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (norm): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (relu): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv(\n",
       "              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (norm): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (relu): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (yolo_head): Head(\n",
       "    (dfl): DFL(\n",
       "      (conv): Conv2d(16, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    )\n",
       "    (cls): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): Conv(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (norm): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (relu): SiLU(inplace=True)\n",
       "        )\n",
       "        (1): Conv(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (norm): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (relu): SiLU(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(128, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): Conv(\n",
       "          (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (norm): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (relu): SiLU(inplace=True)\n",
       "        )\n",
       "        (1): Conv(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (norm): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (relu): SiLU(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(128, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): Conv(\n",
       "          (conv): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (norm): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (relu): SiLU(inplace=True)\n",
       "        )\n",
       "        (1): Conv(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (norm): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (relu): SiLU(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(128, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (box): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): Conv(\n",
       "          (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (norm): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (relu): SiLU(inplace=True)\n",
       "        )\n",
       "        (1): Conv(\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (norm): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (relu): SiLU(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): Conv(\n",
       "          (conv): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (norm): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (relu): SiLU(inplace=True)\n",
       "        )\n",
       "        (1): Conv(\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (norm): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (relu): SiLU(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): Conv(\n",
       "          (conv): Conv2d(512, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (norm): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (relu): SiLU(inplace=True)\n",
       "        )\n",
       "        (1): Conv(\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (norm): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (relu): SiLU(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (clrhead): CLRHead(\n",
       "    (prior_embeddings): Embedding(192, 3)\n",
       "    (seg_decoder): SegDecoder(\n",
       "      (dropout): Dropout2d(p=0.1, inplace=False)\n",
       "      (conv): Conv2d(192, 5, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (reg_modules): ModuleList(\n",
       "      (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "    (cls_modules): ModuleList(\n",
       "      (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "    (roi_gather): ROIGather(\n",
       "      (f_key): ConvModule(\n",
       "        (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activate): ReLU(inplace=True)\n",
       "      )\n",
       "      (f_query): Sequential(\n",
       "        (0): Conv1d(192, 192, kernel_size=(1,), stride=(1,), groups=192)\n",
       "        (1): ReLU()\n",
       "      )\n",
       "      (f_value): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (W): Conv1d(192, 192, kernel_size=(1,), stride=(1,), groups=192)\n",
       "      (resize): FeatureResize()\n",
       "      (convs): ModuleList(\n",
       "        (0): ConvModule(\n",
       "          (conv): Conv2d(64, 48, kernel_size=(9, 1), stride=(1, 1), padding=(4, 0), bias=False)\n",
       "          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activate): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): ConvModule(\n",
       "          (conv): Conv2d(64, 48, kernel_size=(9, 1), stride=(1, 1), padding=(4, 0), bias=False)\n",
       "          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activate): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): ConvModule(\n",
       "          (conv): Conv2d(64, 48, kernel_size=(9, 1), stride=(1, 1), padding=(4, 0), bias=False)\n",
       "          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activate): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (catconv): ModuleList(\n",
       "        (0): ConvModule(\n",
       "          (conv): Conv2d(48, 64, kernel_size=(9, 1), stride=(1, 1), padding=(4, 0), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activate): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): ConvModule(\n",
       "          (conv): Conv2d(96, 64, kernel_size=(9, 1), stride=(1, 1), padding=(4, 0), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activate): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): ConvModule(\n",
       "          (conv): Conv2d(144, 64, kernel_size=(9, 1), stride=(1, 1), padding=(4, 0), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activate): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (fc): Linear(in_features=2304, out_features=64, bias=True)\n",
       "      (fc_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (reg_layers): Linear(in_features=64, out_features=76, bias=True)\n",
       "    (cls_layers): Linear(in_features=64, out_features=2, bias=True)\n",
       "    (criterion): NLLLoss()\n",
       "  )\n",
       "  (offset_2): Conv2d(512, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (offset_1): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (offset_0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clrnet_yolo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "YOLOL(\n",
       "  (backbone): DarkNet(\n",
       "    (p1): Sequential(\n",
       "      (0): Conv(\n",
       "        (conv): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (norm): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (relu): SiLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (p2): Sequential(\n",
       "      (0): Conv(\n",
       "        (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (norm): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (relu): SiLU(inplace=True)\n",
       "      )\n",
       "      (1): CSP(\n",
       "        (conv1): Conv(\n",
       "          (conv): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (relu): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv2): Conv(\n",
       "          (conv): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (relu): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv3): Conv(\n",
       "          (conv): Conv2d(48, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (relu): SiLU(inplace=True)\n",
       "        )\n",
       "        (res_m): ModuleList(\n",
       "          (0): Residual(\n",
       "            (res_m): Sequential(\n",
       "              (0): Conv(\n",
       "                (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (norm): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (relu): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv(\n",
       "                (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (norm): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (relu): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (p3): Sequential(\n",
       "      (0): Conv(\n",
       "        (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (norm): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (relu): SiLU(inplace=True)\n",
       "      )\n",
       "      (1): CSP(\n",
       "        (conv1): Conv(\n",
       "          (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (relu): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv2): Conv(\n",
       "          (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (relu): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv3): Conv(\n",
       "          (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (relu): SiLU(inplace=True)\n",
       "        )\n",
       "        (res_m): ModuleList(\n",
       "          (0): Residual(\n",
       "            (res_m): Sequential(\n",
       "              (0): Conv(\n",
       "                (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (norm): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (relu): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv(\n",
       "                (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (norm): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (relu): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (1): Residual(\n",
       "            (res_m): Sequential(\n",
       "              (0): Conv(\n",
       "                (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (norm): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (relu): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv(\n",
       "                (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (norm): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (relu): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (p4): Sequential(\n",
       "      (0): Conv(\n",
       "        (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (norm): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (relu): SiLU(inplace=True)\n",
       "      )\n",
       "      (1): CSP(\n",
       "        (conv1): Conv(\n",
       "          (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (relu): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv2): Conv(\n",
       "          (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (relu): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv3): Conv(\n",
       "          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (relu): SiLU(inplace=True)\n",
       "        )\n",
       "        (res_m): ModuleList(\n",
       "          (0): Residual(\n",
       "            (res_m): Sequential(\n",
       "              (0): Conv(\n",
       "                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (norm): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (relu): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv(\n",
       "                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (norm): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (relu): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (1): Residual(\n",
       "            (res_m): Sequential(\n",
       "              (0): Conv(\n",
       "                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (norm): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (relu): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv(\n",
       "                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (norm): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (relu): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (p5): Sequential(\n",
       "      (0): Conv(\n",
       "        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (norm): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (relu): SiLU(inplace=True)\n",
       "      )\n",
       "      (1): CSP(\n",
       "        (conv1): Conv(\n",
       "          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (relu): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv2): Conv(\n",
       "          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (relu): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv3): Conv(\n",
       "          (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (relu): SiLU(inplace=True)\n",
       "        )\n",
       "        (res_m): ModuleList(\n",
       "          (0): Residual(\n",
       "            (res_m): Sequential(\n",
       "              (0): Conv(\n",
       "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (norm): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (relu): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv(\n",
       "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (norm): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (relu): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): SPP(\n",
       "        (conv1): Conv(\n",
       "          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (relu): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv2): Conv(\n",
       "          (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (relu): SiLU(inplace=True)\n",
       "        )\n",
       "        (res_m): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (neck): CrossStitchDarkFPN(\n",
       "    (up): Upsample(scale_factor=2.0, mode=nearest)\n",
       "    (h1): CSP(\n",
       "      (conv1): Conv(\n",
       "        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (relu): SiLU(inplace=True)\n",
       "      )\n",
       "      (conv2): Conv(\n",
       "        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (relu): SiLU(inplace=True)\n",
       "      )\n",
       "      (conv3): Conv(\n",
       "        (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (relu): SiLU(inplace=True)\n",
       "      )\n",
       "      (res_m): ModuleList(\n",
       "        (0): Residual(\n",
       "          (res_m): Sequential(\n",
       "            (0): Conv(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (norm): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (relu): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (norm): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (relu): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (h2): CSP(\n",
       "      (conv1): Conv(\n",
       "        (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (relu): SiLU(inplace=True)\n",
       "      )\n",
       "      (conv2): Conv(\n",
       "        (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (relu): SiLU(inplace=True)\n",
       "      )\n",
       "      (conv3): Conv(\n",
       "        (conv): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (relu): SiLU(inplace=True)\n",
       "      )\n",
       "      (res_m): ModuleList(\n",
       "        (0): Residual(\n",
       "          (res_m): Sequential(\n",
       "            (0): Conv(\n",
       "              (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (norm): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (relu): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv(\n",
       "              (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (norm): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (relu): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (h3): Conv(\n",
       "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (norm): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (relu): SiLU(inplace=True)\n",
       "    )\n",
       "    (h4_yolo): CSP(\n",
       "      (conv1): Conv(\n",
       "        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (relu): SiLU(inplace=True)\n",
       "      )\n",
       "      (conv2): Conv(\n",
       "        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (relu): SiLU(inplace=True)\n",
       "      )\n",
       "      (conv3): Conv(\n",
       "        (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (relu): SiLU(inplace=True)\n",
       "      )\n",
       "      (res_m): ModuleList(\n",
       "        (0): Residual(\n",
       "          (res_m): Sequential(\n",
       "            (0): Conv(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (norm): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (relu): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (norm): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (relu): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (h4_clr): CSP(\n",
       "      (conv1): Conv(\n",
       "        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (relu): SiLU(inplace=True)\n",
       "      )\n",
       "      (conv2): Conv(\n",
       "        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (relu): SiLU(inplace=True)\n",
       "      )\n",
       "      (conv3): Conv(\n",
       "        (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (relu): SiLU(inplace=True)\n",
       "      )\n",
       "      (res_m): ModuleList(\n",
       "        (0): Residual(\n",
       "          (res_m): Sequential(\n",
       "            (0): Conv(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (norm): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (relu): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (norm): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (relu): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (cross_stitch_h4): CrossStitchUnit()\n",
       "    (h5_yolo): Conv(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (norm): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (relu): SiLU(inplace=True)\n",
       "    )\n",
       "    (h5_clr): Conv(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (norm): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (relu): SiLU(inplace=True)\n",
       "    )\n",
       "    (h6_yolo): CSP(\n",
       "      (conv1): Conv(\n",
       "        (conv): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (relu): SiLU(inplace=True)\n",
       "      )\n",
       "      (conv2): Conv(\n",
       "        (conv): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (relu): SiLU(inplace=True)\n",
       "      )\n",
       "      (conv3): Conv(\n",
       "        (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (relu): SiLU(inplace=True)\n",
       "      )\n",
       "      (res_m): ModuleList(\n",
       "        (0): Residual(\n",
       "          (res_m): Sequential(\n",
       "            (0): Conv(\n",
       "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (norm): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (relu): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv(\n",
       "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (norm): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (relu): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (h6_clr): CSP(\n",
       "      (conv1): Conv(\n",
       "        (conv): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (relu): SiLU(inplace=True)\n",
       "      )\n",
       "      (conv2): Conv(\n",
       "        (conv): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (relu): SiLU(inplace=True)\n",
       "      )\n",
       "      (conv3): Conv(\n",
       "        (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (relu): SiLU(inplace=True)\n",
       "      )\n",
       "      (res_m): ModuleList(\n",
       "        (0): Residual(\n",
       "          (res_m): Sequential(\n",
       "            (0): Conv(\n",
       "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (norm): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (relu): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv(\n",
       "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (norm): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (relu): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (yolo_head): Head(\n",
       "    (dfl): DFL(\n",
       "      (conv): Conv2d(16, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    )\n",
       "    (cls): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): Conv(\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (norm): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (relu): SiLU(inplace=True)\n",
       "        )\n",
       "        (1): Conv(\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (norm): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (relu): SiLU(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(64, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): Conv(\n",
       "          (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (norm): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (relu): SiLU(inplace=True)\n",
       "        )\n",
       "        (1): Conv(\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (norm): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (relu): SiLU(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(64, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): Conv(\n",
       "          (conv): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (norm): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (relu): SiLU(inplace=True)\n",
       "        )\n",
       "        (1): Conv(\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (norm): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (relu): SiLU(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(64, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (box): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): Conv(\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (norm): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (relu): SiLU(inplace=True)\n",
       "        )\n",
       "        (1): Conv(\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (norm): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (relu): SiLU(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): Conv(\n",
       "          (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (norm): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (relu): SiLU(inplace=True)\n",
       "        )\n",
       "        (1): Conv(\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (norm): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (relu): SiLU(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): Conv(\n",
       "          (conv): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (norm): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (relu): SiLU(inplace=True)\n",
       "        )\n",
       "        (1): Conv(\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (norm): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (relu): SiLU(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (clrhead): CLRHead(\n",
       "    (prior_embeddings): Embedding(192, 3)\n",
       "    (seg_decoder): SegDecoder(\n",
       "      (dropout): Dropout2d(p=0.1, inplace=False)\n",
       "      (conv): Conv2d(192, 5, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (reg_modules): ModuleList(\n",
       "      (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "    (cls_modules): ModuleList(\n",
       "      (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "    (roi_gather): ROIGather(\n",
       "      (f_key): ConvModule(\n",
       "        (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activate): ReLU(inplace=True)\n",
       "      )\n",
       "      (f_query): Sequential(\n",
       "        (0): Conv1d(192, 192, kernel_size=(1,), stride=(1,), groups=192)\n",
       "        (1): ReLU()\n",
       "      )\n",
       "      (f_value): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (W): Conv1d(192, 192, kernel_size=(1,), stride=(1,), groups=192)\n",
       "      (resize): FeatureResize()\n",
       "      (convs): ModuleList(\n",
       "        (0): ConvModule(\n",
       "          (conv): Conv2d(64, 48, kernel_size=(9, 1), stride=(1, 1), padding=(4, 0), bias=False)\n",
       "          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activate): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): ConvModule(\n",
       "          (conv): Conv2d(64, 48, kernel_size=(9, 1), stride=(1, 1), padding=(4, 0), bias=False)\n",
       "          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activate): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): ConvModule(\n",
       "          (conv): Conv2d(64, 48, kernel_size=(9, 1), stride=(1, 1), padding=(4, 0), bias=False)\n",
       "          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activate): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (catconv): ModuleList(\n",
       "        (0): ConvModule(\n",
       "          (conv): Conv2d(48, 64, kernel_size=(9, 1), stride=(1, 1), padding=(4, 0), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activate): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): ConvModule(\n",
       "          (conv): Conv2d(96, 64, kernel_size=(9, 1), stride=(1, 1), padding=(4, 0), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activate): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): ConvModule(\n",
       "          (conv): Conv2d(144, 64, kernel_size=(9, 1), stride=(1, 1), padding=(4, 0), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activate): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (fc): Linear(in_features=2304, out_features=64, bias=True)\n",
       "      (fc_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (reg_layers): Linear(in_features=64, out_features=76, bias=True)\n",
       "    (cls_layers): Linear(in_features=64, out_features=2, bias=True)\n",
       "    (criterion): NLLLoss()\n",
       "  )\n",
       "  (offset_2): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (offset_1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "model_cross_stitch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = [], [], []\n",
    "for v in net.modules():\n",
    "    if hasattr(v, 'bias') and isinstance(v.bias, torch.nn.Parameter):\n",
    "        p[2].append(v.bias)\n",
    "    if isinstance(v, torch.nn.BatchNorm2d):\n",
    "        p[1].append(v.weight)\n",
    "    elif hasattr(v, 'weight') and isinstance(v.weight, torch.nn.Parameter):\n",
    "        p[0].append(v.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = YOLOL(darknet_backbone, darknet_neck, darknet_head, clrnet_head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = torch.load('weights/vehicle_pcgrad_model_best.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for YOLOL:\n\tsize mismatch for backbone.p1.0.conv.weight: copying a param with shape torch.Size([32, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([16, 3, 3, 3]).\n\tsize mismatch for backbone.p1.0.norm.weight: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for backbone.p1.0.norm.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for backbone.p1.0.norm.running_mean: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for backbone.p1.0.norm.running_var: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for backbone.p2.0.conv.weight: copying a param with shape torch.Size([64, 32, 3, 3]) from checkpoint, the shape in current model is torch.Size([32, 16, 3, 3]).\n\tsize mismatch for backbone.p2.0.norm.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for backbone.p2.0.norm.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for backbone.p2.0.norm.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for backbone.p2.0.norm.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for backbone.p2.1.conv1.conv.weight: copying a param with shape torch.Size([32, 64, 1, 1]) from checkpoint, the shape in current model is torch.Size([16, 32, 1, 1]).\n\tsize mismatch for backbone.p2.1.conv1.norm.weight: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for backbone.p2.1.conv1.norm.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for backbone.p2.1.conv1.norm.running_mean: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for backbone.p2.1.conv1.norm.running_var: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for backbone.p2.1.conv2.conv.weight: copying a param with shape torch.Size([32, 64, 1, 1]) from checkpoint, the shape in current model is torch.Size([16, 32, 1, 1]).\n\tsize mismatch for backbone.p2.1.conv2.norm.weight: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for backbone.p2.1.conv2.norm.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for backbone.p2.1.conv2.norm.running_mean: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for backbone.p2.1.conv2.norm.running_var: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for backbone.p2.1.conv3.conv.weight: copying a param with shape torch.Size([64, 96, 1, 1]) from checkpoint, the shape in current model is torch.Size([32, 48, 1, 1]).\n\tsize mismatch for backbone.p2.1.conv3.norm.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for backbone.p2.1.conv3.norm.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for backbone.p2.1.conv3.norm.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for backbone.p2.1.conv3.norm.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for backbone.p2.1.res_m.0.res_m.0.conv.weight: copying a param with shape torch.Size([32, 32, 3, 3]) from checkpoint, the shape in current model is torch.Size([16, 16, 3, 3]).\n\tsize mismatch for backbone.p2.1.res_m.0.res_m.0.norm.weight: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for backbone.p2.1.res_m.0.res_m.0.norm.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for backbone.p2.1.res_m.0.res_m.0.norm.running_mean: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for backbone.p2.1.res_m.0.res_m.0.norm.running_var: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for backbone.p2.1.res_m.0.res_m.1.conv.weight: copying a param with shape torch.Size([32, 32, 3, 3]) from checkpoint, the shape in current model is torch.Size([16, 16, 3, 3]).\n\tsize mismatch for backbone.p2.1.res_m.0.res_m.1.norm.weight: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for backbone.p2.1.res_m.0.res_m.1.norm.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for backbone.p2.1.res_m.0.res_m.1.norm.running_mean: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for backbone.p2.1.res_m.0.res_m.1.norm.running_var: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for backbone.p3.0.conv.weight: copying a param with shape torch.Size([128, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 32, 3, 3]).\n\tsize mismatch for backbone.p3.0.norm.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for backbone.p3.0.norm.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for backbone.p3.0.norm.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for backbone.p3.0.norm.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for backbone.p3.1.conv1.conv.weight: copying a param with shape torch.Size([64, 128, 1, 1]) from checkpoint, the shape in current model is torch.Size([32, 64, 1, 1]).\n\tsize mismatch for backbone.p3.1.conv1.norm.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for backbone.p3.1.conv1.norm.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for backbone.p3.1.conv1.norm.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for backbone.p3.1.conv1.norm.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for backbone.p3.1.conv2.conv.weight: copying a param with shape torch.Size([64, 128, 1, 1]) from checkpoint, the shape in current model is torch.Size([32, 64, 1, 1]).\n\tsize mismatch for backbone.p3.1.conv2.norm.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for backbone.p3.1.conv2.norm.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for backbone.p3.1.conv2.norm.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for backbone.p3.1.conv2.norm.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for backbone.p3.1.conv3.conv.weight: copying a param with shape torch.Size([128, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([64, 128, 1, 1]).\n\tsize mismatch for backbone.p3.1.conv3.norm.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for backbone.p3.1.conv3.norm.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for backbone.p3.1.conv3.norm.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for backbone.p3.1.conv3.norm.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for backbone.p3.1.res_m.0.res_m.0.conv.weight: copying a param with shape torch.Size([64, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([32, 32, 3, 3]).\n\tsize mismatch for backbone.p3.1.res_m.0.res_m.0.norm.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for backbone.p3.1.res_m.0.res_m.0.norm.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for backbone.p3.1.res_m.0.res_m.0.norm.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for backbone.p3.1.res_m.0.res_m.0.norm.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for backbone.p3.1.res_m.0.res_m.1.conv.weight: copying a param with shape torch.Size([64, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([32, 32, 3, 3]).\n\tsize mismatch for backbone.p3.1.res_m.0.res_m.1.norm.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for backbone.p3.1.res_m.0.res_m.1.norm.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for backbone.p3.1.res_m.0.res_m.1.norm.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for backbone.p3.1.res_m.0.res_m.1.norm.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for backbone.p3.1.res_m.1.res_m.0.conv.weight: copying a param with shape torch.Size([64, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([32, 32, 3, 3]).\n\tsize mismatch for backbone.p3.1.res_m.1.res_m.0.norm.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for backbone.p3.1.res_m.1.res_m.0.norm.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for backbone.p3.1.res_m.1.res_m.0.norm.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for backbone.p3.1.res_m.1.res_m.0.norm.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for backbone.p3.1.res_m.1.res_m.1.conv.weight: copying a param with shape torch.Size([64, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([32, 32, 3, 3]).\n\tsize mismatch for backbone.p3.1.res_m.1.res_m.1.norm.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for backbone.p3.1.res_m.1.res_m.1.norm.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for backbone.p3.1.res_m.1.res_m.1.norm.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for backbone.p3.1.res_m.1.res_m.1.norm.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for backbone.p4.0.conv.weight: copying a param with shape torch.Size([256, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 64, 3, 3]).\n\tsize mismatch for backbone.p4.0.norm.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for backbone.p4.0.norm.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for backbone.p4.0.norm.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for backbone.p4.0.norm.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for backbone.p4.1.conv1.conv.weight: copying a param with shape torch.Size([128, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([64, 128, 1, 1]).\n\tsize mismatch for backbone.p4.1.conv1.norm.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for backbone.p4.1.conv1.norm.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for backbone.p4.1.conv1.norm.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for backbone.p4.1.conv1.norm.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for backbone.p4.1.conv2.conv.weight: copying a param with shape torch.Size([128, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([64, 128, 1, 1]).\n\tsize mismatch for backbone.p4.1.conv2.norm.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for backbone.p4.1.conv2.norm.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for backbone.p4.1.conv2.norm.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for backbone.p4.1.conv2.norm.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for backbone.p4.1.conv3.conv.weight: copying a param with shape torch.Size([256, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 256, 1, 1]).\n\tsize mismatch for backbone.p4.1.conv3.norm.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for backbone.p4.1.conv3.norm.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for backbone.p4.1.conv3.norm.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for backbone.p4.1.conv3.norm.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for backbone.p4.1.res_m.0.res_m.0.conv.weight: copying a param with shape torch.Size([128, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 3, 3]).\n\tsize mismatch for backbone.p4.1.res_m.0.res_m.0.norm.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for backbone.p4.1.res_m.0.res_m.0.norm.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for backbone.p4.1.res_m.0.res_m.0.norm.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for backbone.p4.1.res_m.0.res_m.0.norm.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for backbone.p4.1.res_m.0.res_m.1.conv.weight: copying a param with shape torch.Size([128, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 3, 3]).\n\tsize mismatch for backbone.p4.1.res_m.0.res_m.1.norm.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for backbone.p4.1.res_m.0.res_m.1.norm.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for backbone.p4.1.res_m.0.res_m.1.norm.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for backbone.p4.1.res_m.0.res_m.1.norm.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for backbone.p4.1.res_m.1.res_m.0.conv.weight: copying a param with shape torch.Size([128, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 3, 3]).\n\tsize mismatch for backbone.p4.1.res_m.1.res_m.0.norm.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for backbone.p4.1.res_m.1.res_m.0.norm.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for backbone.p4.1.res_m.1.res_m.0.norm.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for backbone.p4.1.res_m.1.res_m.0.norm.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for backbone.p4.1.res_m.1.res_m.1.conv.weight: copying a param with shape torch.Size([128, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 3, 3]).\n\tsize mismatch for backbone.p4.1.res_m.1.res_m.1.norm.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for backbone.p4.1.res_m.1.res_m.1.norm.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for backbone.p4.1.res_m.1.res_m.1.norm.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for backbone.p4.1.res_m.1.res_m.1.norm.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for backbone.p5.0.conv.weight: copying a param with shape torch.Size([512, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 128, 3, 3]).\n\tsize mismatch for backbone.p5.0.norm.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for backbone.p5.0.norm.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for backbone.p5.0.norm.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for backbone.p5.0.norm.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for backbone.p5.1.conv1.conv.weight: copying a param with shape torch.Size([256, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 256, 1, 1]).\n\tsize mismatch for backbone.p5.1.conv1.norm.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for backbone.p5.1.conv1.norm.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for backbone.p5.1.conv1.norm.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for backbone.p5.1.conv1.norm.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for backbone.p5.1.conv2.conv.weight: copying a param with shape torch.Size([256, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 256, 1, 1]).\n\tsize mismatch for backbone.p5.1.conv2.norm.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for backbone.p5.1.conv2.norm.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for backbone.p5.1.conv2.norm.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for backbone.p5.1.conv2.norm.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for backbone.p5.1.conv3.conv.weight: copying a param with shape torch.Size([512, 768, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 384, 1, 1]).\n\tsize mismatch for backbone.p5.1.conv3.norm.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for backbone.p5.1.conv3.norm.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for backbone.p5.1.conv3.norm.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for backbone.p5.1.conv3.norm.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for backbone.p5.1.res_m.0.res_m.0.conv.weight: copying a param with shape torch.Size([256, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 128, 3, 3]).\n\tsize mismatch for backbone.p5.1.res_m.0.res_m.0.norm.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for backbone.p5.1.res_m.0.res_m.0.norm.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for backbone.p5.1.res_m.0.res_m.0.norm.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for backbone.p5.1.res_m.0.res_m.0.norm.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for backbone.p5.1.res_m.0.res_m.1.conv.weight: copying a param with shape torch.Size([256, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 128, 3, 3]).\n\tsize mismatch for backbone.p5.1.res_m.0.res_m.1.norm.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for backbone.p5.1.res_m.0.res_m.1.norm.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for backbone.p5.1.res_m.0.res_m.1.norm.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for backbone.p5.1.res_m.0.res_m.1.norm.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for backbone.p5.2.conv1.conv.weight: copying a param with shape torch.Size([256, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 256, 1, 1]).\n\tsize mismatch for backbone.p5.2.conv1.norm.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for backbone.p5.2.conv1.norm.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for backbone.p5.2.conv1.norm.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for backbone.p5.2.conv1.norm.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for backbone.p5.2.conv2.conv.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 512, 1, 1]).\n\tsize mismatch for backbone.p5.2.conv2.norm.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for backbone.p5.2.conv2.norm.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for backbone.p5.2.conv2.norm.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for backbone.p5.2.conv2.norm.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for neck.h1.conv1.conv.weight: copying a param with shape torch.Size([128, 768, 1, 1]) from checkpoint, the shape in current model is torch.Size([64, 384, 1, 1]).\n\tsize mismatch for neck.h1.conv1.norm.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for neck.h1.conv1.norm.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for neck.h1.conv1.norm.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for neck.h1.conv1.norm.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for neck.h1.conv2.conv.weight: copying a param with shape torch.Size([128, 768, 1, 1]) from checkpoint, the shape in current model is torch.Size([64, 384, 1, 1]).\n\tsize mismatch for neck.h1.conv2.norm.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for neck.h1.conv2.norm.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for neck.h1.conv2.norm.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for neck.h1.conv2.norm.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for neck.h1.conv3.conv.weight: copying a param with shape torch.Size([256, 384, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 192, 1, 1]).\n\tsize mismatch for neck.h1.conv3.norm.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for neck.h1.conv3.norm.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for neck.h1.conv3.norm.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for neck.h1.conv3.norm.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for neck.h1.res_m.0.res_m.0.conv.weight: copying a param with shape torch.Size([128, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 3, 3]).\n\tsize mismatch for neck.h1.res_m.0.res_m.0.norm.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for neck.h1.res_m.0.res_m.0.norm.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for neck.h1.res_m.0.res_m.0.norm.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for neck.h1.res_m.0.res_m.0.norm.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for neck.h1.res_m.0.res_m.1.conv.weight: copying a param with shape torch.Size([128, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 3, 3]).\n\tsize mismatch for neck.h1.res_m.0.res_m.1.norm.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for neck.h1.res_m.0.res_m.1.norm.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for neck.h1.res_m.0.res_m.1.norm.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for neck.h1.res_m.0.res_m.1.norm.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for neck.h2.conv1.conv.weight: copying a param with shape torch.Size([64, 384, 1, 1]) from checkpoint, the shape in current model is torch.Size([32, 192, 1, 1]).\n\tsize mismatch for neck.h2.conv1.norm.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for neck.h2.conv1.norm.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for neck.h2.conv1.norm.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for neck.h2.conv1.norm.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for neck.h2.conv2.conv.weight: copying a param with shape torch.Size([64, 384, 1, 1]) from checkpoint, the shape in current model is torch.Size([32, 192, 1, 1]).\n\tsize mismatch for neck.h2.conv2.norm.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for neck.h2.conv2.norm.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for neck.h2.conv2.norm.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for neck.h2.conv2.norm.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for neck.h2.conv3.conv.weight: copying a param with shape torch.Size([128, 192, 1, 1]) from checkpoint, the shape in current model is torch.Size([64, 96, 1, 1]).\n\tsize mismatch for neck.h2.conv3.norm.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for neck.h2.conv3.norm.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for neck.h2.conv3.norm.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for neck.h2.conv3.norm.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for neck.h2.res_m.0.res_m.0.conv.weight: copying a param with shape torch.Size([64, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([32, 32, 3, 3]).\n\tsize mismatch for neck.h2.res_m.0.res_m.0.norm.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for neck.h2.res_m.0.res_m.0.norm.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for neck.h2.res_m.0.res_m.0.norm.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for neck.h2.res_m.0.res_m.0.norm.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for neck.h2.res_m.0.res_m.1.conv.weight: copying a param with shape torch.Size([64, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([32, 32, 3, 3]).\n\tsize mismatch for neck.h2.res_m.0.res_m.1.norm.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for neck.h2.res_m.0.res_m.1.norm.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for neck.h2.res_m.0.res_m.1.norm.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for neck.h2.res_m.0.res_m.1.norm.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for neck.h3.conv.weight: copying a param with shape torch.Size([128, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 3, 3]).\n\tsize mismatch for neck.h3.norm.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for neck.h3.norm.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for neck.h3.norm.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for neck.h3.norm.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for neck.h4.conv1.conv.weight: copying a param with shape torch.Size([128, 384, 1, 1]) from checkpoint, the shape in current model is torch.Size([64, 192, 1, 1]).\n\tsize mismatch for neck.h4.conv1.norm.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for neck.h4.conv1.norm.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for neck.h4.conv1.norm.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for neck.h4.conv1.norm.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for neck.h4.conv2.conv.weight: copying a param with shape torch.Size([128, 384, 1, 1]) from checkpoint, the shape in current model is torch.Size([64, 192, 1, 1]).\n\tsize mismatch for neck.h4.conv2.norm.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for neck.h4.conv2.norm.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for neck.h4.conv2.norm.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for neck.h4.conv2.norm.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for neck.h4.conv3.conv.weight: copying a param with shape torch.Size([256, 384, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 192, 1, 1]).\n\tsize mismatch for neck.h4.conv3.norm.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for neck.h4.conv3.norm.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for neck.h4.conv3.norm.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for neck.h4.conv3.norm.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for neck.h4.res_m.0.res_m.0.conv.weight: copying a param with shape torch.Size([128, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 3, 3]).\n\tsize mismatch for neck.h4.res_m.0.res_m.0.norm.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for neck.h4.res_m.0.res_m.0.norm.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for neck.h4.res_m.0.res_m.0.norm.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for neck.h4.res_m.0.res_m.0.norm.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for neck.h4.res_m.0.res_m.1.conv.weight: copying a param with shape torch.Size([128, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 3, 3]).\n\tsize mismatch for neck.h4.res_m.0.res_m.1.norm.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for neck.h4.res_m.0.res_m.1.norm.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for neck.h4.res_m.0.res_m.1.norm.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for neck.h4.res_m.0.res_m.1.norm.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for neck.h5.conv.weight: copying a param with shape torch.Size([256, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 128, 3, 3]).\n\tsize mismatch for neck.h5.norm.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for neck.h5.norm.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for neck.h5.norm.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for neck.h5.norm.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for neck.h6.conv1.conv.weight: copying a param with shape torch.Size([256, 768, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 384, 1, 1]).\n\tsize mismatch for neck.h6.conv1.norm.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for neck.h6.conv1.norm.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for neck.h6.conv1.norm.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for neck.h6.conv1.norm.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for neck.h6.conv2.conv.weight: copying a param with shape torch.Size([256, 768, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 384, 1, 1]).\n\tsize mismatch for neck.h6.conv2.norm.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for neck.h6.conv2.norm.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for neck.h6.conv2.norm.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for neck.h6.conv2.norm.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for neck.h6.conv3.conv.weight: copying a param with shape torch.Size([512, 768, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 384, 1, 1]).\n\tsize mismatch for neck.h6.conv3.norm.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for neck.h6.conv3.norm.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for neck.h6.conv3.norm.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for neck.h6.conv3.norm.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for neck.h6.res_m.0.res_m.0.conv.weight: copying a param with shape torch.Size([256, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 128, 3, 3]).\n\tsize mismatch for neck.h6.res_m.0.res_m.0.norm.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for neck.h6.res_m.0.res_m.0.norm.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for neck.h6.res_m.0.res_m.0.norm.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for neck.h6.res_m.0.res_m.0.norm.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for neck.h6.res_m.0.res_m.1.conv.weight: copying a param with shape torch.Size([256, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 128, 3, 3]).\n\tsize mismatch for neck.h6.res_m.0.res_m.1.norm.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for neck.h6.res_m.0.res_m.1.norm.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for neck.h6.res_m.0.res_m.1.norm.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for neck.h6.res_m.0.res_m.1.norm.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for yolo_head.cls.0.0.conv.weight: copying a param with shape torch.Size([128, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 3, 3]).\n\tsize mismatch for yolo_head.cls.0.0.norm.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for yolo_head.cls.0.0.norm.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for yolo_head.cls.0.0.norm.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for yolo_head.cls.0.0.norm.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for yolo_head.cls.0.1.conv.weight: copying a param with shape torch.Size([128, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 3, 3]).\n\tsize mismatch for yolo_head.cls.0.1.norm.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for yolo_head.cls.0.1.norm.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for yolo_head.cls.0.1.norm.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for yolo_head.cls.0.1.norm.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for yolo_head.cls.0.2.weight: copying a param with shape torch.Size([10, 128, 1, 1]) from checkpoint, the shape in current model is torch.Size([1, 64, 1, 1]).\n\tsize mismatch for yolo_head.cls.0.2.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for yolo_head.cls.1.0.conv.weight: copying a param with shape torch.Size([128, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 128, 3, 3]).\n\tsize mismatch for yolo_head.cls.1.0.norm.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for yolo_head.cls.1.0.norm.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for yolo_head.cls.1.0.norm.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for yolo_head.cls.1.0.norm.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for yolo_head.cls.1.1.conv.weight: copying a param with shape torch.Size([128, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 3, 3]).\n\tsize mismatch for yolo_head.cls.1.1.norm.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for yolo_head.cls.1.1.norm.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for yolo_head.cls.1.1.norm.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for yolo_head.cls.1.1.norm.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for yolo_head.cls.1.2.weight: copying a param with shape torch.Size([10, 128, 1, 1]) from checkpoint, the shape in current model is torch.Size([1, 64, 1, 1]).\n\tsize mismatch for yolo_head.cls.1.2.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for yolo_head.cls.2.0.conv.weight: copying a param with shape torch.Size([128, 512, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 256, 3, 3]).\n\tsize mismatch for yolo_head.cls.2.0.norm.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for yolo_head.cls.2.0.norm.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for yolo_head.cls.2.0.norm.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for yolo_head.cls.2.0.norm.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for yolo_head.cls.2.1.conv.weight: copying a param with shape torch.Size([128, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 3, 3]).\n\tsize mismatch for yolo_head.cls.2.1.norm.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for yolo_head.cls.2.1.norm.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for yolo_head.cls.2.1.norm.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for yolo_head.cls.2.1.norm.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for yolo_head.cls.2.2.weight: copying a param with shape torch.Size([10, 128, 1, 1]) from checkpoint, the shape in current model is torch.Size([1, 64, 1, 1]).\n\tsize mismatch for yolo_head.cls.2.2.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for yolo_head.box.0.0.conv.weight: copying a param with shape torch.Size([64, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 3, 3]).\n\tsize mismatch for yolo_head.box.1.0.conv.weight: copying a param with shape torch.Size([64, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 128, 3, 3]).\n\tsize mismatch for yolo_head.box.2.0.conv.weight: copying a param with shape torch.Size([64, 512, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 256, 3, 3]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m YOLOL(darknet_backbone, darknet_neck, darknet_head, clrnet_head)  \u001b[38;5;66;03m# Replace with your model class\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweights/vehicle_only_model_best.pt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# model.eval()  # Set model to evaluation mode\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/clrnet/lib/python3.8/site-packages/torch/nn/modules/module.py:1223\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   1218\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   1219\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   1220\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(k) \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[1;32m   1222\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 1223\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   1224\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   1225\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for YOLOL:\n\tsize mismatch for backbone.p1.0.conv.weight: copying a param with shape torch.Size([32, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([16, 3, 3, 3]).\n\tsize mismatch for backbone.p1.0.norm.weight: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for backbone.p1.0.norm.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for backbone.p1.0.norm.running_mean: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for backbone.p1.0.norm.running_var: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for backbone.p2.0.conv.weight: copying a param with shape torch.Size([64, 32, 3, 3]) from checkpoint, the shape in current model is torch.Size([32, 16, 3, 3]).\n\tsize mismatch for backbone.p2.0.norm.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for backbone.p2.0.norm.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for backbone.p2.0.norm.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for backbone.p2.0.norm.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for backbone.p2.1.conv1.conv.weight: copying a param with shape torch.Size([32, 64, 1, 1]) from checkpoint, the shape in current model is torch.Size([16, 32, 1, 1]).\n\tsize mismatch for backbone.p2.1.conv1.norm.weight: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for backbone.p2.1.conv1.norm.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for backbone.p2.1.conv1.norm.running_mean: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for backbone.p2.1.conv1.norm.running_var: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for backbone.p2.1.conv2.conv.weight: copying a param with shape torch.Size([32, 64, 1, 1]) from checkpoint, the shape in current model is torch.Size([16, 32, 1, 1]).\n\tsize mismatch for backbone.p2.1.conv2.norm.weight: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for backbone.p2.1.conv2.norm.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for backbone.p2.1.conv2.norm.running_mean: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for backbone.p2.1.conv2.norm.running_var: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for backbone.p2.1.conv3.conv.weight: copying a param with shape torch.Size([64, 96, 1, 1]) from checkpoint, the shape in current model is torch.Size([32, 48, 1, 1]).\n\tsize mismatch for backbone.p2.1.conv3.norm.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for backbone.p2.1.conv3.norm.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for backbone.p2.1.conv3.norm.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for backbone.p2.1.conv3.norm.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for backbone.p2.1.res_m.0.res_m.0.conv.weight: copying a param with shape torch.Size([32, 32, 3, 3]) from checkpoint, the shape in current model is torch.Size([16, 16, 3, 3]).\n\tsize mismatch for backbone.p2.1.res_m.0.res_m.0.norm.weight: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for backbone.p2.1.res_m.0.res_m.0.norm.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for backbone.p2.1.res_m.0.res_m.0.norm.running_mean: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for backbone.p2.1.res_m.0.res_m.0.norm.running_var: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for backbone.p2.1.res_m.0.res_m.1.conv.weight: copying a param with shape torch.Size([32, 32, 3, 3]) from checkpoint, the shape in current model is torch.Size([16, 16, 3, 3]).\n\tsize mismatch for backbone.p2.1.res_m.0.res_m.1.norm.weight: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for backbone.p2.1.res_m.0.res_m.1.norm.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for backbone.p2.1.res_m.0.res_m.1.norm.running_mean: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for backbone.p2.1.res_m.0.res_m.1.norm.running_var: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for backbone.p3.0.conv.weight: copying a param with shape torch.Size([128, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 32, 3, 3]).\n\tsize mismatch for backbone.p3.0.norm.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for backbone.p3.0.norm.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for backbone.p3.0.norm.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for backbone.p3.0.norm.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for backbone.p3.1.conv1.conv.weight: copying a param with shape torch.Size([64, 128, 1, 1]) from checkpoint, the shape in current model is torch.Size([32, 64, 1, 1]).\n\tsize mismatch for backbone.p3.1.conv1.norm.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for backbone.p3.1.conv1.norm.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for backbone.p3.1.conv1.norm.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for backbone.p3.1.conv1.norm.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for backbone.p3.1.conv2.conv.weight: copying a param with shape torch.Size([64, 128, 1, 1]) from checkpoint, the shape in current model is torch.Size([32, 64, 1, 1]).\n\tsize mismatch for backbone.p3.1.conv2.norm.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for backbone.p3.1.conv2.norm.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for backbone.p3.1.conv2.norm.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for backbone.p3.1.conv2.norm.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for backbone.p3.1.conv3.conv.weight: copying a param with shape torch.Size([128, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([64, 128, 1, 1]).\n\tsize mismatch for backbone.p3.1.conv3.norm.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for backbone.p3.1.conv3.norm.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for backbone.p3.1.conv3.norm.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for backbone.p3.1.conv3.norm.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for backbone.p3.1.res_m.0.res_m.0.conv.weight: copying a param with shape torch.Size([64, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([32, 32, 3, 3]).\n\tsize mismatch for backbone.p3.1.res_m.0.res_m.0.norm.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for backbone.p3.1.res_m.0.res_m.0.norm.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for backbone.p3.1.res_m.0.res_m.0.norm.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for backbone.p3.1.res_m.0.res_m.0.norm.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for backbone.p3.1.res_m.0.res_m.1.conv.weight: copying a param with shape torch.Size([64, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([32, 32, 3, 3]).\n\tsize mismatch for backbone.p3.1.res_m.0.res_m.1.norm.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for backbone.p3.1.res_m.0.res_m.1.norm.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for backbone.p3.1.res_m.0.res_m.1.norm.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for backbone.p3.1.res_m.0.res_m.1.norm.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for backbone.p3.1.res_m.1.res_m.0.conv.weight: copying a param with shape torch.Size([64, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([32, 32, 3, 3]).\n\tsize mismatch for backbone.p3.1.res_m.1.res_m.0.norm.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for backbone.p3.1.res_m.1.res_m.0.norm.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for backbone.p3.1.res_m.1.res_m.0.norm.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for backbone.p3.1.res_m.1.res_m.0.norm.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for backbone.p3.1.res_m.1.res_m.1.conv.weight: copying a param with shape torch.Size([64, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([32, 32, 3, 3]).\n\tsize mismatch for backbone.p3.1.res_m.1.res_m.1.norm.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for backbone.p3.1.res_m.1.res_m.1.norm.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for backbone.p3.1.res_m.1.res_m.1.norm.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for backbone.p3.1.res_m.1.res_m.1.norm.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for backbone.p4.0.conv.weight: copying a param with shape torch.Size([256, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 64, 3, 3]).\n\tsize mismatch for backbone.p4.0.norm.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for backbone.p4.0.norm.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for backbone.p4.0.norm.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for backbone.p4.0.norm.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for backbone.p4.1.conv1.conv.weight: copying a param with shape torch.Size([128, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([64, 128, 1, 1]).\n\tsize mismatch for backbone.p4.1.conv1.norm.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for backbone.p4.1.conv1.norm.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for backbone.p4.1.conv1.norm.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for backbone.p4.1.conv1.norm.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for backbone.p4.1.conv2.conv.weight: copying a param with shape torch.Size([128, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([64, 128, 1, 1]).\n\tsize mismatch for backbone.p4.1.conv2.norm.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for backbone.p4.1.conv2.norm.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for backbone.p4.1.conv2.norm.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for backbone.p4.1.conv2.norm.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for backbone.p4.1.conv3.conv.weight: copying a param with shape torch.Size([256, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 256, 1, 1]).\n\tsize mismatch for backbone.p4.1.conv3.norm.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for backbone.p4.1.conv3.norm.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for backbone.p4.1.conv3.norm.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for backbone.p4.1.conv3.norm.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for backbone.p4.1.res_m.0.res_m.0.conv.weight: copying a param with shape torch.Size([128, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 3, 3]).\n\tsize mismatch for backbone.p4.1.res_m.0.res_m.0.norm.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for backbone.p4.1.res_m.0.res_m.0.norm.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for backbone.p4.1.res_m.0.res_m.0.norm.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for backbone.p4.1.res_m.0.res_m.0.norm.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for backbone.p4.1.res_m.0.res_m.1.conv.weight: copying a param with shape torch.Size([128, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 3, 3]).\n\tsize mismatch for backbone.p4.1.res_m.0.res_m.1.norm.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for backbone.p4.1.res_m.0.res_m.1.norm.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for backbone.p4.1.res_m.0.res_m.1.norm.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for backbone.p4.1.res_m.0.res_m.1.norm.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for backbone.p4.1.res_m.1.res_m.0.conv.weight: copying a param with shape torch.Size([128, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 3, 3]).\n\tsize mismatch for backbone.p4.1.res_m.1.res_m.0.norm.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for backbone.p4.1.res_m.1.res_m.0.norm.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for backbone.p4.1.res_m.1.res_m.0.norm.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for backbone.p4.1.res_m.1.res_m.0.norm.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for backbone.p4.1.res_m.1.res_m.1.conv.weight: copying a param with shape torch.Size([128, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 3, 3]).\n\tsize mismatch for backbone.p4.1.res_m.1.res_m.1.norm.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for backbone.p4.1.res_m.1.res_m.1.norm.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for backbone.p4.1.res_m.1.res_m.1.norm.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for backbone.p4.1.res_m.1.res_m.1.norm.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for backbone.p5.0.conv.weight: copying a param with shape torch.Size([512, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 128, 3, 3]).\n\tsize mismatch for backbone.p5.0.norm.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for backbone.p5.0.norm.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for backbone.p5.0.norm.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for backbone.p5.0.norm.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for backbone.p5.1.conv1.conv.weight: copying a param with shape torch.Size([256, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 256, 1, 1]).\n\tsize mismatch for backbone.p5.1.conv1.norm.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for backbone.p5.1.conv1.norm.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for backbone.p5.1.conv1.norm.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for backbone.p5.1.conv1.norm.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for backbone.p5.1.conv2.conv.weight: copying a param with shape torch.Size([256, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 256, 1, 1]).\n\tsize mismatch for backbone.p5.1.conv2.norm.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for backbone.p5.1.conv2.norm.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for backbone.p5.1.conv2.norm.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for backbone.p5.1.conv2.norm.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for backbone.p5.1.conv3.conv.weight: copying a param with shape torch.Size([512, 768, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 384, 1, 1]).\n\tsize mismatch for backbone.p5.1.conv3.norm.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for backbone.p5.1.conv3.norm.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for backbone.p5.1.conv3.norm.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for backbone.p5.1.conv3.norm.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for backbone.p5.1.res_m.0.res_m.0.conv.weight: copying a param with shape torch.Size([256, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 128, 3, 3]).\n\tsize mismatch for backbone.p5.1.res_m.0.res_m.0.norm.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for backbone.p5.1.res_m.0.res_m.0.norm.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for backbone.p5.1.res_m.0.res_m.0.norm.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for backbone.p5.1.res_m.0.res_m.0.norm.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for backbone.p5.1.res_m.0.res_m.1.conv.weight: copying a param with shape torch.Size([256, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 128, 3, 3]).\n\tsize mismatch for backbone.p5.1.res_m.0.res_m.1.norm.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for backbone.p5.1.res_m.0.res_m.1.norm.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for backbone.p5.1.res_m.0.res_m.1.norm.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for backbone.p5.1.res_m.0.res_m.1.norm.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for backbone.p5.2.conv1.conv.weight: copying a param with shape torch.Size([256, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 256, 1, 1]).\n\tsize mismatch for backbone.p5.2.conv1.norm.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for backbone.p5.2.conv1.norm.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for backbone.p5.2.conv1.norm.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for backbone.p5.2.conv1.norm.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for backbone.p5.2.conv2.conv.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 512, 1, 1]).\n\tsize mismatch for backbone.p5.2.conv2.norm.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for backbone.p5.2.conv2.norm.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for backbone.p5.2.conv2.norm.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for backbone.p5.2.conv2.norm.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for neck.h1.conv1.conv.weight: copying a param with shape torch.Size([128, 768, 1, 1]) from checkpoint, the shape in current model is torch.Size([64, 384, 1, 1]).\n\tsize mismatch for neck.h1.conv1.norm.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for neck.h1.conv1.norm.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for neck.h1.conv1.norm.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for neck.h1.conv1.norm.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for neck.h1.conv2.conv.weight: copying a param with shape torch.Size([128, 768, 1, 1]) from checkpoint, the shape in current model is torch.Size([64, 384, 1, 1]).\n\tsize mismatch for neck.h1.conv2.norm.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for neck.h1.conv2.norm.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for neck.h1.conv2.norm.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for neck.h1.conv2.norm.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for neck.h1.conv3.conv.weight: copying a param with shape torch.Size([256, 384, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 192, 1, 1]).\n\tsize mismatch for neck.h1.conv3.norm.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for neck.h1.conv3.norm.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for neck.h1.conv3.norm.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for neck.h1.conv3.norm.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for neck.h1.res_m.0.res_m.0.conv.weight: copying a param with shape torch.Size([128, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 3, 3]).\n\tsize mismatch for neck.h1.res_m.0.res_m.0.norm.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for neck.h1.res_m.0.res_m.0.norm.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for neck.h1.res_m.0.res_m.0.norm.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for neck.h1.res_m.0.res_m.0.norm.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for neck.h1.res_m.0.res_m.1.conv.weight: copying a param with shape torch.Size([128, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 3, 3]).\n\tsize mismatch for neck.h1.res_m.0.res_m.1.norm.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for neck.h1.res_m.0.res_m.1.norm.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for neck.h1.res_m.0.res_m.1.norm.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for neck.h1.res_m.0.res_m.1.norm.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for neck.h2.conv1.conv.weight: copying a param with shape torch.Size([64, 384, 1, 1]) from checkpoint, the shape in current model is torch.Size([32, 192, 1, 1]).\n\tsize mismatch for neck.h2.conv1.norm.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for neck.h2.conv1.norm.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for neck.h2.conv1.norm.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for neck.h2.conv1.norm.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for neck.h2.conv2.conv.weight: copying a param with shape torch.Size([64, 384, 1, 1]) from checkpoint, the shape in current model is torch.Size([32, 192, 1, 1]).\n\tsize mismatch for neck.h2.conv2.norm.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for neck.h2.conv2.norm.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for neck.h2.conv2.norm.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for neck.h2.conv2.norm.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for neck.h2.conv3.conv.weight: copying a param with shape torch.Size([128, 192, 1, 1]) from checkpoint, the shape in current model is torch.Size([64, 96, 1, 1]).\n\tsize mismatch for neck.h2.conv3.norm.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for neck.h2.conv3.norm.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for neck.h2.conv3.norm.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for neck.h2.conv3.norm.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for neck.h2.res_m.0.res_m.0.conv.weight: copying a param with shape torch.Size([64, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([32, 32, 3, 3]).\n\tsize mismatch for neck.h2.res_m.0.res_m.0.norm.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for neck.h2.res_m.0.res_m.0.norm.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for neck.h2.res_m.0.res_m.0.norm.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for neck.h2.res_m.0.res_m.0.norm.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for neck.h2.res_m.0.res_m.1.conv.weight: copying a param with shape torch.Size([64, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([32, 32, 3, 3]).\n\tsize mismatch for neck.h2.res_m.0.res_m.1.norm.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for neck.h2.res_m.0.res_m.1.norm.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for neck.h2.res_m.0.res_m.1.norm.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for neck.h2.res_m.0.res_m.1.norm.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for neck.h3.conv.weight: copying a param with shape torch.Size([128, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 3, 3]).\n\tsize mismatch for neck.h3.norm.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for neck.h3.norm.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for neck.h3.norm.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for neck.h3.norm.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for neck.h4.conv1.conv.weight: copying a param with shape torch.Size([128, 384, 1, 1]) from checkpoint, the shape in current model is torch.Size([64, 192, 1, 1]).\n\tsize mismatch for neck.h4.conv1.norm.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for neck.h4.conv1.norm.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for neck.h4.conv1.norm.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for neck.h4.conv1.norm.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for neck.h4.conv2.conv.weight: copying a param with shape torch.Size([128, 384, 1, 1]) from checkpoint, the shape in current model is torch.Size([64, 192, 1, 1]).\n\tsize mismatch for neck.h4.conv2.norm.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for neck.h4.conv2.norm.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for neck.h4.conv2.norm.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for neck.h4.conv2.norm.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for neck.h4.conv3.conv.weight: copying a param with shape torch.Size([256, 384, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 192, 1, 1]).\n\tsize mismatch for neck.h4.conv3.norm.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for neck.h4.conv3.norm.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for neck.h4.conv3.norm.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for neck.h4.conv3.norm.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for neck.h4.res_m.0.res_m.0.conv.weight: copying a param with shape torch.Size([128, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 3, 3]).\n\tsize mismatch for neck.h4.res_m.0.res_m.0.norm.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for neck.h4.res_m.0.res_m.0.norm.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for neck.h4.res_m.0.res_m.0.norm.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for neck.h4.res_m.0.res_m.0.norm.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for neck.h4.res_m.0.res_m.1.conv.weight: copying a param with shape torch.Size([128, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 3, 3]).\n\tsize mismatch for neck.h4.res_m.0.res_m.1.norm.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for neck.h4.res_m.0.res_m.1.norm.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for neck.h4.res_m.0.res_m.1.norm.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for neck.h4.res_m.0.res_m.1.norm.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for neck.h5.conv.weight: copying a param with shape torch.Size([256, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 128, 3, 3]).\n\tsize mismatch for neck.h5.norm.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for neck.h5.norm.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for neck.h5.norm.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for neck.h5.norm.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for neck.h6.conv1.conv.weight: copying a param with shape torch.Size([256, 768, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 384, 1, 1]).\n\tsize mismatch for neck.h6.conv1.norm.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for neck.h6.conv1.norm.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for neck.h6.conv1.norm.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for neck.h6.conv1.norm.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for neck.h6.conv2.conv.weight: copying a param with shape torch.Size([256, 768, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 384, 1, 1]).\n\tsize mismatch for neck.h6.conv2.norm.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for neck.h6.conv2.norm.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for neck.h6.conv2.norm.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for neck.h6.conv2.norm.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for neck.h6.conv3.conv.weight: copying a param with shape torch.Size([512, 768, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 384, 1, 1]).\n\tsize mismatch for neck.h6.conv3.norm.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for neck.h6.conv3.norm.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for neck.h6.conv3.norm.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for neck.h6.conv3.norm.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for neck.h6.res_m.0.res_m.0.conv.weight: copying a param with shape torch.Size([256, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 128, 3, 3]).\n\tsize mismatch for neck.h6.res_m.0.res_m.0.norm.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for neck.h6.res_m.0.res_m.0.norm.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for neck.h6.res_m.0.res_m.0.norm.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for neck.h6.res_m.0.res_m.0.norm.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for neck.h6.res_m.0.res_m.1.conv.weight: copying a param with shape torch.Size([256, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 128, 3, 3]).\n\tsize mismatch for neck.h6.res_m.0.res_m.1.norm.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for neck.h6.res_m.0.res_m.1.norm.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for neck.h6.res_m.0.res_m.1.norm.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for neck.h6.res_m.0.res_m.1.norm.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for yolo_head.cls.0.0.conv.weight: copying a param with shape torch.Size([128, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 3, 3]).\n\tsize mismatch for yolo_head.cls.0.0.norm.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for yolo_head.cls.0.0.norm.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for yolo_head.cls.0.0.norm.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for yolo_head.cls.0.0.norm.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for yolo_head.cls.0.1.conv.weight: copying a param with shape torch.Size([128, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 3, 3]).\n\tsize mismatch for yolo_head.cls.0.1.norm.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for yolo_head.cls.0.1.norm.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for yolo_head.cls.0.1.norm.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for yolo_head.cls.0.1.norm.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for yolo_head.cls.0.2.weight: copying a param with shape torch.Size([10, 128, 1, 1]) from checkpoint, the shape in current model is torch.Size([1, 64, 1, 1]).\n\tsize mismatch for yolo_head.cls.0.2.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for yolo_head.cls.1.0.conv.weight: copying a param with shape torch.Size([128, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 128, 3, 3]).\n\tsize mismatch for yolo_head.cls.1.0.norm.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for yolo_head.cls.1.0.norm.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for yolo_head.cls.1.0.norm.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for yolo_head.cls.1.0.norm.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for yolo_head.cls.1.1.conv.weight: copying a param with shape torch.Size([128, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 3, 3]).\n\tsize mismatch for yolo_head.cls.1.1.norm.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for yolo_head.cls.1.1.norm.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for yolo_head.cls.1.1.norm.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for yolo_head.cls.1.1.norm.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for yolo_head.cls.1.2.weight: copying a param with shape torch.Size([10, 128, 1, 1]) from checkpoint, the shape in current model is torch.Size([1, 64, 1, 1]).\n\tsize mismatch for yolo_head.cls.1.2.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for yolo_head.cls.2.0.conv.weight: copying a param with shape torch.Size([128, 512, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 256, 3, 3]).\n\tsize mismatch for yolo_head.cls.2.0.norm.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for yolo_head.cls.2.0.norm.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for yolo_head.cls.2.0.norm.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for yolo_head.cls.2.0.norm.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for yolo_head.cls.2.1.conv.weight: copying a param with shape torch.Size([128, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 3, 3]).\n\tsize mismatch for yolo_head.cls.2.1.norm.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for yolo_head.cls.2.1.norm.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for yolo_head.cls.2.1.norm.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for yolo_head.cls.2.1.norm.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for yolo_head.cls.2.2.weight: copying a param with shape torch.Size([10, 128, 1, 1]) from checkpoint, the shape in current model is torch.Size([1, 64, 1, 1]).\n\tsize mismatch for yolo_head.cls.2.2.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for yolo_head.box.0.0.conv.weight: copying a param with shape torch.Size([64, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 3, 3]).\n\tsize mismatch for yolo_head.box.1.0.conv.weight: copying a param with shape torch.Size([64, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 128, 3, 3]).\n\tsize mismatch for yolo_head.box.2.0.conv.weight: copying a param with shape torch.Size([64, 512, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 256, 3, 3])."
     ]
    }
   ],
   "source": [
    "model = YOLOL(darknet_backbone, darknet_neck, darknet_head, clrnet_head)  # Replace with your model class\n",
    "model.load_state_dict(torch.load('weights/vehicle_only_model_best.pt'))\n",
    "# model.eval()  # Set model to evaluation mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "# Example transform (adapt if your CLRNet expects specific normalization)\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((288, 800)),  # Resize like training\n",
    "    transforms.ToTensor(),          # Convert to [C, H, W] and scale [0,1]\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],  # Imagenet means\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"/data/bdd100k/images/val2017/b3d67c06-57b140bf.jpg\"  # Change path\n",
    "\n",
    "# Read using OpenCV (BGR)\n",
    "image_bgr = cv2.imread(img_path)\n",
    "\n",
    "# Convert BGR → RGB\n",
    "image = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Keep a copy for visualization later\n",
    "image_vis = image.copy()\n",
    "\n",
    "# Preprocess\n",
    "input_tensor = preprocess(image)\n",
    "input_tensor = input_tensor.unsqueeze(0).cuda()  # Add batch dim and send to GPU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(input_tensor.shape)\n",
    "print(next(model.parameters()).device)\n",
    "print(input_tensor.device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.cuda()\n",
    "model.eval()  # Set model to evaluation mode\n",
    "# with torch.no_grad():\n",
    "output_lane = model(input_tensor, 0)\n",
    "    # output_obj = model(input_tensor, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "softmax = nn.Softmax(dim=1)\n",
    "for pred in output_lane:\n",
    "    print(pred.shape)\n",
    "    print(softmax(pred[:, :2])[:, 1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.clrhead.get_lanes(output_lane)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_lane[\"seg\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(output_lane[\"predictions_lists\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_lane[\"predictions_lists\"][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_lane.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_obj.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-11 18:22:40,009 - clrnet.utils.recorder - INFO - Config: \n",
      "net = dict(type='Detector', )\n",
      "\n",
      "backbone = dict(\n",
      "    type='ResNetWrapper',\n",
      "    resnet='resnet18',\n",
      "    pretrained=True,\n",
      "    replace_stride_with_dilation=[False, False, False],\n",
      "    out_conv=False,\n",
      ")\n",
      "\n",
      "num_points = 72\n",
      "max_lanes = 4\n",
      "sample_y = range(589, 230, -20)\n",
      "\n",
      "heads = dict(type='CLRHead',\n",
      "             num_priors=192,\n",
      "             refine_layers=3,\n",
      "             fc_hidden_dim=64,\n",
      "             sample_points=36)\n",
      "\n",
      "iou_loss_weight = 2.\n",
      "cls_loss_weight = 2.\n",
      "xyt_loss_weight = 0.2\n",
      "seg_loss_weight = 1.0\n",
      "\n",
      "work_dirs = \"work_dirs/clr/r18_culane\"\n",
      "\n",
      "neck = dict(type='FPN',\n",
      "            in_channels=[128, 256, 512],\n",
      "            out_channels=64,\n",
      "            num_outs=3,\n",
      "            attention=False)\n",
      "\n",
      "test_parameters = dict(conf_threshold=0.4, nms_thres=50, nms_topk=max_lanes)\n",
      "\n",
      "epochs = 15\n",
      "batch_size = 24\n",
      "\n",
      "optimizer = dict(type='AdamW', lr=0.6e-3)  # 3e-4 for batchsize 8\n",
      "total_iter = (88880 // batch_size) * epochs\n",
      "scheduler = dict(type='CosineAnnealingLR', T_max=total_iter)\n",
      "\n",
      "eval_ep = 1\n",
      "save_ep = 10\n",
      "\n",
      "img_norm = dict(mean=[103.939, 116.779, 123.68], std=[1., 1., 1.])\n",
      "ori_img_w = 1640\n",
      "ori_img_h = 590\n",
      "img_w = 800\n",
      "img_h = 320\n",
      "cut_height = 270\n",
      "\n",
      "train_process = [\n",
      "    dict(\n",
      "        type='GenerateLaneLine',\n",
      "        transforms=[\n",
      "            dict(name='Resize',\n",
      "                 parameters=dict(size=dict(height=img_h, width=img_w)),\n",
      "                 p=1.0),\n",
      "            dict(name='HorizontalFlip', parameters=dict(p=1.0), p=0.5),\n",
      "            dict(name='ChannelShuffle', parameters=dict(p=1.0), p=0.1),\n",
      "            dict(name='MultiplyAndAddToBrightness',\n",
      "                 parameters=dict(mul=(0.85, 1.15), add=(-10, 10)),\n",
      "                 p=0.6),\n",
      "            dict(name='AddToHueAndSaturation',\n",
      "                 parameters=dict(value=(-10, 10)),\n",
      "                 p=0.7),\n",
      "            dict(name='OneOf',\n",
      "                 transforms=[\n",
      "                     dict(name='MotionBlur', parameters=dict(k=(3, 5))),\n",
      "                     dict(name='MedianBlur', parameters=dict(k=(3, 5)))\n",
      "                 ],\n",
      "                 p=0.2),\n",
      "            dict(name='Affine',\n",
      "                 parameters=dict(translate_percent=dict(x=(-0.1, 0.1),\n",
      "                                                        y=(-0.1, 0.1)),\n",
      "                                 rotate=(-10, 10),\n",
      "                                 scale=(0.8, 1.2)),\n",
      "                 p=0.7),\n",
      "            dict(name='Resize',\n",
      "                 parameters=dict(size=dict(height=img_h, width=img_w)),\n",
      "                 p=1.0),\n",
      "        ],\n",
      "    ),\n",
      "    dict(type='ToTensor', keys=['img', 'lane_line', 'seg']),\n",
      "]\n",
      "\n",
      "val_process = [\n",
      "    dict(type='GenerateLaneLine',\n",
      "         transforms=[\n",
      "             dict(name='Resize',\n",
      "                  parameters=dict(size=dict(height=img_h, width=img_w)),\n",
      "                  p=1.0),\n",
      "         ],\n",
      "         training=False),\n",
      "    dict(type='ToTensor', keys=['img']),\n",
      "]\n",
      "\n",
      "dataset_path = './data/CULane'\n",
      "dataset_type = 'CULane'\n",
      "dataset = dict(train=dict(\n",
      "    type=dataset_type,\n",
      "    data_root=dataset_path,\n",
      "    split='train',\n",
      "    processes=train_process,\n",
      "),\n",
      "val=dict(\n",
      "    type=dataset_type,\n",
      "    data_root=dataset_path,\n",
      "    split='test',\n",
      "    processes=val_process,\n",
      "),\n",
      "test=dict(\n",
      "    type=dataset_type,\n",
      "    data_root=dataset_path,\n",
      "    split='test',\n",
      "    processes=val_process,\n",
      "))\n",
      "\n",
      "workers = 10\n",
      "log_interval = 1000\n",
      "# seed = 0\n",
      "num_classes = 4 + 1\n",
      "ignore_label = 255\n",
      "bg_weight = 0.4\n",
      "lr_update_by_epoch = False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "recorder = build_recorder(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3889\n",
      "3704\n"
     ]
    }
   ],
   "source": [
    "print(len(train_loader_obj))\n",
    "print(len(train_loader_lane))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_cuda(batch, device = 'cpu'):\n",
    "    for k in batch:\n",
    "        if not isinstance(batch[k], torch.Tensor):\n",
    "            continue\n",
    "        batch[k] = batch[k].to(device)\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p_bar = enumerate(train_dataset_obj)\n",
    "# p_bar = tqdm(p_bar, total=len(train_loader_obj))  # progress bar\n",
    "# for i, (samples, targets, _) in p_bar:\n",
    "#     print(samples)\n",
    "#     print(targets)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, data in enumerate(train_loader_lane):\n",
    "#     print(data)\n",
    "#     data = to_cuda(data)\n",
    "#     print(data)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in net.backbone.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in net.neck.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in net.yolo_head.parameters():\n",
    "    param.requires_grad = True\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "image_path = '/data/bdd100k/images/val2017/c8054f9c-3ff3c2b1.jpg'\n",
    "\n",
    "# Load the image with PIL\n",
    "image = Image.open(image_path).convert('RGB')\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),   # adjust size as required by model\n",
    "    transforms.ToTensor(),           # converts PIL image to a PyTorch tensor, CxHxW\n",
    "    transforms.Normalize(            # normalize with mean & std used by model training\n",
    "        mean=[0.485, 0.456, 0.406], \n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n",
    "\n",
    "input_tensor = transform(image)\n",
    "input_batch = input_tensor.unsqueeze(0)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "input_batch = input_batch.to(device)\n",
    "input_batch = input_batch.half()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cross_stitch.half()\n",
    "model_cross_stitch.cuda()\n",
    "model_cross_stitch.eval()\n",
    "output = model_cross_stitch(input_batch, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchviz import make_dot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'model_arch.png'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_dot(output, params=dict(model_cross_stitch.named_parameters())).render(\"model_arch\", format=\"png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WrappedModel(torch.nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "\n",
    "    def forward(self, x):\n",
    "        # call original model with default or dummy extra args\n",
    "        return self.model(x, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WrappedModel(\n",
       "  (model): YOLOL(\n",
       "    (backbone): DarkNet(\n",
       "      (p1): Sequential(\n",
       "        (0): Conv(\n",
       "          (conv): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (norm): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (relu): SiLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (p2): Sequential(\n",
       "        (0): Conv(\n",
       "          (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (norm): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (relu): SiLU(inplace=True)\n",
       "        )\n",
       "        (1): CSP(\n",
       "          (conv1): Conv(\n",
       "            (conv): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (relu): SiLU(inplace=True)\n",
       "          )\n",
       "          (conv2): Conv(\n",
       "            (conv): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (relu): SiLU(inplace=True)\n",
       "          )\n",
       "          (conv3): Conv(\n",
       "            (conv): Conv2d(48, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (relu): SiLU(inplace=True)\n",
       "          )\n",
       "          (res_m): ModuleList(\n",
       "            (0): Residual(\n",
       "              (res_m): Sequential(\n",
       "                (0): Conv(\n",
       "                  (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (norm): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                  (relu): SiLU(inplace=True)\n",
       "                )\n",
       "                (1): Conv(\n",
       "                  (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (norm): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                  (relu): SiLU(inplace=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (p3): Sequential(\n",
       "        (0): Conv(\n",
       "          (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (norm): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (relu): SiLU(inplace=True)\n",
       "        )\n",
       "        (1): CSP(\n",
       "          (conv1): Conv(\n",
       "            (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (relu): SiLU(inplace=True)\n",
       "          )\n",
       "          (conv2): Conv(\n",
       "            (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (relu): SiLU(inplace=True)\n",
       "          )\n",
       "          (conv3): Conv(\n",
       "            (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (relu): SiLU(inplace=True)\n",
       "          )\n",
       "          (res_m): ModuleList(\n",
       "            (0): Residual(\n",
       "              (res_m): Sequential(\n",
       "                (0): Conv(\n",
       "                  (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (norm): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                  (relu): SiLU(inplace=True)\n",
       "                )\n",
       "                (1): Conv(\n",
       "                  (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (norm): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                  (relu): SiLU(inplace=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): Residual(\n",
       "              (res_m): Sequential(\n",
       "                (0): Conv(\n",
       "                  (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (norm): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                  (relu): SiLU(inplace=True)\n",
       "                )\n",
       "                (1): Conv(\n",
       "                  (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (norm): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                  (relu): SiLU(inplace=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (p4): Sequential(\n",
       "        (0): Conv(\n",
       "          (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (norm): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (relu): SiLU(inplace=True)\n",
       "        )\n",
       "        (1): CSP(\n",
       "          (conv1): Conv(\n",
       "            (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (relu): SiLU(inplace=True)\n",
       "          )\n",
       "          (conv2): Conv(\n",
       "            (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (relu): SiLU(inplace=True)\n",
       "          )\n",
       "          (conv3): Conv(\n",
       "            (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (relu): SiLU(inplace=True)\n",
       "          )\n",
       "          (res_m): ModuleList(\n",
       "            (0): Residual(\n",
       "              (res_m): Sequential(\n",
       "                (0): Conv(\n",
       "                  (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (norm): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                  (relu): SiLU(inplace=True)\n",
       "                )\n",
       "                (1): Conv(\n",
       "                  (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (norm): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                  (relu): SiLU(inplace=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): Residual(\n",
       "              (res_m): Sequential(\n",
       "                (0): Conv(\n",
       "                  (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (norm): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                  (relu): SiLU(inplace=True)\n",
       "                )\n",
       "                (1): Conv(\n",
       "                  (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (norm): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                  (relu): SiLU(inplace=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (p5): Sequential(\n",
       "        (0): Conv(\n",
       "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (norm): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (relu): SiLU(inplace=True)\n",
       "        )\n",
       "        (1): CSP(\n",
       "          (conv1): Conv(\n",
       "            (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (relu): SiLU(inplace=True)\n",
       "          )\n",
       "          (conv2): Conv(\n",
       "            (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (relu): SiLU(inplace=True)\n",
       "          )\n",
       "          (conv3): Conv(\n",
       "            (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (relu): SiLU(inplace=True)\n",
       "          )\n",
       "          (res_m): ModuleList(\n",
       "            (0): Residual(\n",
       "              (res_m): Sequential(\n",
       "                (0): Conv(\n",
       "                  (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (norm): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                  (relu): SiLU(inplace=True)\n",
       "                )\n",
       "                (1): Conv(\n",
       "                  (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (norm): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                  (relu): SiLU(inplace=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): SPP(\n",
       "          (conv1): Conv(\n",
       "            (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (relu): SiLU(inplace=True)\n",
       "          )\n",
       "          (conv2): Conv(\n",
       "            (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (relu): SiLU(inplace=True)\n",
       "          )\n",
       "          (res_m): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (neck): CrossStitchDarkFPN(\n",
       "      (up): Upsample(scale_factor=2.0, mode=nearest)\n",
       "      (h1): CSP(\n",
       "        (conv1): Conv(\n",
       "          (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (relu): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv2): Conv(\n",
       "          (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (relu): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv3): Conv(\n",
       "          (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (relu): SiLU(inplace=True)\n",
       "        )\n",
       "        (res_m): ModuleList(\n",
       "          (0): Residual(\n",
       "            (res_m): Sequential(\n",
       "              (0): Conv(\n",
       "                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (norm): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (relu): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv(\n",
       "                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (norm): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (relu): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (h2): CSP(\n",
       "        (conv1): Conv(\n",
       "          (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (relu): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv2): Conv(\n",
       "          (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (relu): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv3): Conv(\n",
       "          (conv): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (relu): SiLU(inplace=True)\n",
       "        )\n",
       "        (res_m): ModuleList(\n",
       "          (0): Residual(\n",
       "            (res_m): Sequential(\n",
       "              (0): Conv(\n",
       "                (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (norm): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (relu): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv(\n",
       "                (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (norm): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (relu): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (h3): Conv(\n",
       "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (norm): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (relu): SiLU(inplace=True)\n",
       "      )\n",
       "      (h4_yolo): CSP(\n",
       "        (conv1): Conv(\n",
       "          (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (relu): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv2): Conv(\n",
       "          (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (relu): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv3): Conv(\n",
       "          (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (relu): SiLU(inplace=True)\n",
       "        )\n",
       "        (res_m): ModuleList(\n",
       "          (0): Residual(\n",
       "            (res_m): Sequential(\n",
       "              (0): Conv(\n",
       "                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (norm): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (relu): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv(\n",
       "                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (norm): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (relu): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (h4_clr): CSP(\n",
       "        (conv1): Conv(\n",
       "          (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (relu): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv2): Conv(\n",
       "          (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (relu): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv3): Conv(\n",
       "          (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (relu): SiLU(inplace=True)\n",
       "        )\n",
       "        (res_m): ModuleList(\n",
       "          (0): Residual(\n",
       "            (res_m): Sequential(\n",
       "              (0): Conv(\n",
       "                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (norm): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (relu): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv(\n",
       "                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (norm): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (relu): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (cross_stitch_h4): CrossStitchUnit()\n",
       "      (h5_yolo): Conv(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (norm): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (relu): SiLU(inplace=True)\n",
       "      )\n",
       "      (h5_clr): Conv(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (norm): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (relu): SiLU(inplace=True)\n",
       "      )\n",
       "      (h6_yolo): CSP(\n",
       "        (conv1): Conv(\n",
       "          (conv): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (relu): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv2): Conv(\n",
       "          (conv): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (relu): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv3): Conv(\n",
       "          (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (relu): SiLU(inplace=True)\n",
       "        )\n",
       "        (res_m): ModuleList(\n",
       "          (0): Residual(\n",
       "            (res_m): Sequential(\n",
       "              (0): Conv(\n",
       "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (norm): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (relu): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv(\n",
       "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (norm): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (relu): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (h6_clr): CSP(\n",
       "        (conv1): Conv(\n",
       "          (conv): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (relu): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv2): Conv(\n",
       "          (conv): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (relu): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv3): Conv(\n",
       "          (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (relu): SiLU(inplace=True)\n",
       "        )\n",
       "        (res_m): ModuleList(\n",
       "          (0): Residual(\n",
       "            (res_m): Sequential(\n",
       "              (0): Conv(\n",
       "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (norm): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (relu): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv(\n",
       "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (norm): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (relu): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (yolo_head): Head(\n",
       "      (dfl): DFL(\n",
       "        (conv): Conv2d(16, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (cls): ModuleList(\n",
       "        (0): Sequential(\n",
       "          (0): Conv(\n",
       "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (norm): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (relu): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv(\n",
       "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (norm): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (relu): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(64, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1): Sequential(\n",
       "          (0): Conv(\n",
       "            (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (norm): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (relu): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv(\n",
       "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (norm): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (relu): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(64, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (2): Sequential(\n",
       "          (0): Conv(\n",
       "            (conv): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (norm): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (relu): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv(\n",
       "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (norm): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (relu): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(64, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (box): ModuleList(\n",
       "        (0): Sequential(\n",
       "          (0): Conv(\n",
       "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (norm): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (relu): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv(\n",
       "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (norm): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (relu): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1): Sequential(\n",
       "          (0): Conv(\n",
       "            (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (norm): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (relu): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv(\n",
       "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (norm): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (relu): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (2): Sequential(\n",
       "          (0): Conv(\n",
       "            (conv): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (norm): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (relu): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv(\n",
       "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (norm): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (relu): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (clrhead): CLRHead(\n",
       "      (prior_embeddings): Embedding(192, 3)\n",
       "      (seg_decoder): SegDecoder(\n",
       "        (dropout): Dropout2d(p=0.1, inplace=False)\n",
       "        (conv): Conv2d(192, 5, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (reg_modules): ModuleList(\n",
       "        (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (3): ReLU(inplace=True)\n",
       "      )\n",
       "      (cls_modules): ModuleList(\n",
       "        (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (3): ReLU(inplace=True)\n",
       "      )\n",
       "      (roi_gather): ROIGather(\n",
       "        (f_key): ConvModule(\n",
       "          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activate): ReLU(inplace=True)\n",
       "        )\n",
       "        (f_query): Sequential(\n",
       "          (0): Conv1d(192, 192, kernel_size=(1,), stride=(1,), groups=192)\n",
       "          (1): ReLU()\n",
       "        )\n",
       "        (f_value): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (W): Conv1d(192, 192, kernel_size=(1,), stride=(1,), groups=192)\n",
       "        (resize): FeatureResize()\n",
       "        (convs): ModuleList(\n",
       "          (0): ConvModule(\n",
       "            (conv): Conv2d(64, 48, kernel_size=(9, 1), stride=(1, 1), padding=(4, 0), bias=False)\n",
       "            (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activate): ReLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvModule(\n",
       "            (conv): Conv2d(64, 48, kernel_size=(9, 1), stride=(1, 1), padding=(4, 0), bias=False)\n",
       "            (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activate): ReLU(inplace=True)\n",
       "          )\n",
       "          (2): ConvModule(\n",
       "            (conv): Conv2d(64, 48, kernel_size=(9, 1), stride=(1, 1), padding=(4, 0), bias=False)\n",
       "            (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activate): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (catconv): ModuleList(\n",
       "          (0): ConvModule(\n",
       "            (conv): Conv2d(48, 64, kernel_size=(9, 1), stride=(1, 1), padding=(4, 0), bias=False)\n",
       "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activate): ReLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvModule(\n",
       "            (conv): Conv2d(96, 64, kernel_size=(9, 1), stride=(1, 1), padding=(4, 0), bias=False)\n",
       "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activate): ReLU(inplace=True)\n",
       "          )\n",
       "          (2): ConvModule(\n",
       "            (conv): Conv2d(144, 64, kernel_size=(9, 1), stride=(1, 1), padding=(4, 0), bias=False)\n",
       "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activate): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (fc): Linear(in_features=2304, out_features=64, bias=True)\n",
       "        (fc_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (reg_layers): Linear(in_features=64, out_features=76, bias=True)\n",
       "      (cls_layers): Linear(in_features=64, out_features=2, bias=True)\n",
       "      (criterion): NLLLoss()\n",
       "    )\n",
       "    (offset_2): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (offset_1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = WrappedModel(model_cross_stitch)\n",
    "model = model.cuda()\n",
    "model = model.half()\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mmm9886/miniconda3/envs/clrnet/lib/python3.8/site-packages/torch/tensor.py:587: RuntimeWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).\n",
      "  warnings.warn('Iterating over a tensor might cause the trace to be incorrect. '\n",
      "/home/mmm9886/miniconda3/envs/clrnet/lib/python3.8/site-packages/torch/onnx/symbolic_helper.py:677: UserWarning: ONNX export mode is set to inference mode, but operator batch_norm is set to inference mode. The model will be exported in inference, as specified by the export mode.\n",
      "  warnings.warn(\"ONNX export mode is set to \" + training_mode +\n",
      "/home/mmm9886/miniconda3/envs/clrnet/lib/python3.8/site-packages/torch/onnx/symbolic_helper.py:346: UserWarning: You are trying to export the model with onnx:Upsample for ONNX opset version 9. This operator might cause results to not match the expected results by PyTorch.\n",
      "ONNX's Upsample/Resize operator did not match Pytorch's Interpolation until opset 11. Attributes to determine how to transform the input were added in onnx:Resize in opset 11 to support Pytorch's behavior (like coordinate_transformation_mode and nearest_mode).\n",
      "We recommend using opset 11 and above for models using this operator. \n",
      "  warnings.warn(\"You are trying to export the model with \" + onnx_op + \" for ONNX opset version \"\n"
     ]
    }
   ],
   "source": [
    "import hiddenlayer as hl\n",
    "hl.build_graph(model, torch.randn(1, 3, 224, 224).cuda().half()).save(\"arch\", format=\"png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "net.apply(reset_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "\n",
    "@torch.no_grad()\n",
    "def test_obj(args, params, model=None):\n",
    "    \n",
    "    folder_path = \"/data/bdd100k/images/val2017/\"\n",
    "    filenames = glob.glob(os.path.join(folder_path, '*'))\n",
    "\n",
    "    val_dataset_obj = Dataset(filenames, args.input_size, params, False)\n",
    "\n",
    "    loader = data.DataLoader(val_dataset_obj, 8, False, num_workers=8,\n",
    "                             pin_memory=True, collate_fn=Dataset.collate_fn)\n",
    "\n",
    "    if model is None:\n",
    "        model = torch.load('./weights/best.pt', map_location='cuda')['model'].float()\n",
    "\n",
    "    model.half()\n",
    "    model.eval()\n",
    "\n",
    "    # Configure\n",
    "    iou_v = torch.linspace(0.5, 0.95, 10).to(device)  # iou vector for mAP@0.5:0.95\n",
    "    n_iou = iou_v.numel()\n",
    "\n",
    "    m_pre = 0.\n",
    "    m_rec = 0.\n",
    "    map50 = 0.\n",
    "    mean_ap = 0.\n",
    "    metrics = []\n",
    "    p_bar = tqdm(loader, desc=('%10s' * 3) % ('precision', 'recall', 'mAP'))\n",
    "    for samples, targets, shapes in p_bar:\n",
    "        samples = samples.to(device)\n",
    "        targets = targets.to(device)\n",
    "        samples = samples.half()  # uint8 to fp16/32\n",
    "        samples = samples / 255  # 0 - 255 to 0.0 - 1.0\n",
    "        _, _, height, width = samples.shape  # batch size, channels, height, width\n",
    "\n",
    "        # Inference\n",
    "        outputs = model(samples, 1)\n",
    "        # NMS\n",
    "        targets[:, 2:] *= torch.tensor((width, height, width, height)).to(device) # to pixels\n",
    "        outputs = util.non_max_suppression(outputs, 0.25, 0.45) # 0.001 originally\n",
    "        # Metrics\n",
    "        for i, output in enumerate(outputs):\n",
    "            labels = targets[targets[:, 0] == i, 1:]\n",
    "            correct = torch.zeros(output.shape[0], n_iou, dtype=torch.bool).to(device)\n",
    "\n",
    "            if output.shape[0] == 0:\n",
    "                if labels.shape[0]:\n",
    "                    metrics.append((correct, *torch.zeros((3, 0)).to(device)))\n",
    "                continue\n",
    "\n",
    "            detections = output.clone()\n",
    "            util.scale(detections[:, :4], samples[i].shape[1:], shapes[i][0], shapes[i][1])\n",
    "\n",
    "            # Evaluate\n",
    "            if labels.shape[0]:\n",
    "                tbox = labels[:, 1:5].clone()  # target boxes\n",
    "                tbox[:, 0] = labels[:, 1] - labels[:, 3] / 2  # top left x\n",
    "                tbox[:, 1] = labels[:, 2] - labels[:, 4] / 2  # top left y\n",
    "                tbox[:, 2] = labels[:, 1] + labels[:, 3] / 2  # bottom right x\n",
    "                tbox[:, 3] = labels[:, 2] + labels[:, 4] / 2  # bottom right y\n",
    "                util.scale(tbox, samples[i].shape[1:], shapes[i][0], shapes[i][1])\n",
    "\n",
    "                correct = numpy.zeros((detections.shape[0], iou_v.shape[0]))\n",
    "                correct = correct.astype(bool)\n",
    "\n",
    "                t_tensor = torch.cat((labels[:, 0:1], tbox), 1)\n",
    "                iou = util.box_iou(t_tensor[:, 1:], detections[:, :4])\n",
    "                correct_class = t_tensor[:, 0:1] == detections[:, 5]\n",
    "                for j in range(len(iou_v)):\n",
    "                    x = torch.where((iou >= iou_v[j]) & correct_class)\n",
    "                    if x[0].shape[0]:\n",
    "                        matches = torch.cat((torch.stack(x, 1), iou[x[0], x[1]][:, None]), 1)\n",
    "                        matches = matches.cpu().numpy()\n",
    "                        if x[0].shape[0] > 1:\n",
    "                            matches = matches[matches[:, 2].argsort()[::-1]]\n",
    "                            matches = matches[numpy.unique(matches[:, 1], return_index=True)[1]]\n",
    "                            matches = matches[numpy.unique(matches[:, 0], return_index=True)[1]]\n",
    "                        correct[matches[:, 1].astype(int), j] = True\n",
    "                correct = torch.tensor(correct, dtype=torch.bool, device=iou_v.device)\n",
    "            metrics.append((correct, output[:, 4], output[:, 5], labels[:, 0]))\n",
    "\n",
    "    # Compute metrics\n",
    "    metrics = [torch.cat(x, 0).cpu().numpy() for x in zip(*metrics)]  # to numpy\n",
    "    if len(metrics) and metrics[0].any():\n",
    "        tp, fp, m_pre, m_rec, map50, mean_ap = util.compute_ap(*metrics)\n",
    "\n",
    "    # Print results\n",
    "    print('%10.3g' * 3 % (m_pre, m_rec, mean_ap))\n",
    "\n",
    "    # Return results\n",
    "    model.float()  # for training\n",
    "    return tp, fp, m_pre, m_rec, map50, mean_ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def validate_lane(net, recorder, device):\n",
    "    \n",
    "    net.backbone = net.backbone.to(device)\n",
    "    net.neck = net.neck.to(device)\n",
    "    net.clrhead= net.clrhead.to(device)\n",
    "    net.yolo_head = net.yolo_head.to(device)\n",
    "    # net.offset_0 = net.offset_0.to(device)\n",
    "    net.offset_1 = net.offset_1.to(device)\n",
    "    net.offset_2 = net.offset_2.to(device)\n",
    "    \n",
    "    val_loader_lane = build_dataloader(cfg.dataset.val,\n",
    "                                            cfg,\n",
    "                                            is_train=False)\n",
    "    predictions = []\n",
    "    for i, data in enumerate(tqdm(val_loader_lane, desc=f'Validate')):\n",
    "        data = to_cuda(data, device)\n",
    "        with torch.no_grad():\n",
    "            output = net(data, 0)\n",
    "            output = net.clrhead.get_lanes(output)\n",
    "            predictions.extend(output)\n",
    "        if cfg.view:\n",
    "            val_loader_lane.dataset.view(output, data['meta'])\n",
    "\n",
    "    metric = val_loader_lane.dataset.evaluate(predictions,\n",
    "                                                cfg.work_dir)\n",
    "    # recorder.logger.info('metric: ' + str(metric))\n",
    "    return metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-04 00:37:29,067 - clrnet.datasets.base_dataset - INFO - Loading CULane annotations...\n"
     ]
    }
   ],
   "source": [
    "val_loader_lane = build_dataloader(cfg.dataset.val,\n",
    "                                            cfg,\n",
    "                                            is_train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<clrnet.datasets.culane.CULane at 0x7f6bd1fe58b0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_loader_lane.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-11 18:24:00,480 - clrnet.datasets.base_dataset - INFO - Loading CULane annotations...\n",
      "Validate: 100%|██████████| 1445/1445 [02:12<00:00, 10.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating prediction output...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-11 18:26:16,774 - clrnet.utils.culane_metric - INFO - Calculating metric for List: ./data/CULane/list/test_split/test0_normal.txt\n",
      "2025-05-11 18:26:54,130 - clrnet.utils.culane_metric - INFO - iou thr: 0.50, tp: 27, fp: 3526, fn: 32750,precision: 0.007599211933577259, recall: 0.0008237483601305793, f1: 0.001486374896779521\n",
      "2025-05-11 18:26:54,200 - clrnet.utils.culane_metric - INFO - Calculating metric for List: ./data/CULane/list/test_split/test1_crowd.txt\n",
      "2025-05-11 18:27:27,289 - clrnet.utils.culane_metric - INFO - iou thr: 0.50, tp: 2, fp: 1009, fn: 28001,precision: 0.0019782393669634025, recall: 7.142091918722994e-05, f1: 0.00013786447921692975\n",
      "2025-05-11 18:27:27,348 - clrnet.utils.culane_metric - INFO - Calculating metric for List: ./data/CULane/list/test_split/test2_hlight.txt\n",
      "2025-05-11 18:27:55,235 - clrnet.utils.culane_metric - INFO - iou thr: 0.50, tp: 1, fp: 145, fn: 1684,precision: 0.00684931506849315, recall: 0.0005934718100890207, f1: 0.0010922992900054614\n",
      "2025-05-11 18:27:55,241 - clrnet.utils.culane_metric - INFO - Calculating metric for List: ./data/CULane/list/test_split/test3_shadow.txt\n",
      "2025-05-11 18:28:23,227 - clrnet.utils.culane_metric - INFO - iou thr: 0.50, tp: 0, fp: 76, fn: 2876,precision: 0, recall: 0, f1: 0\n",
      "2025-05-11 18:28:23,235 - clrnet.utils.culane_metric - INFO - Calculating metric for List: ./data/CULane/list/test_split/test4_noline.txt\n",
      "2025-05-11 18:28:53,673 - clrnet.utils.culane_metric - INFO - iou thr: 0.50, tp: 2, fp: 1152, fn: 14019,precision: 0.0017331022530329288, recall: 0.00014264317809000785, f1: 0.0002635914332784185\n",
      "2025-05-11 18:28:53,707 - clrnet.utils.culane_metric - INFO - Calculating metric for List: ./data/CULane/list/test_split/test5_arrow.txt\n",
      "2025-05-11 18:29:21,699 - clrnet.utils.culane_metric - INFO - iou thr: 0.50, tp: 3, fp: 212, fn: 3179,precision: 0.013953488372093023, recall: 0.0009428032683846638, f1: 0.001766264350897851\n",
      "2025-05-11 18:29:21,710 - clrnet.utils.culane_metric - INFO - Calculating metric for List: ./data/CULane/list/test_split/test6_curve.txt\n",
      "2025-05-11 18:29:49,507 - clrnet.utils.culane_metric - INFO - iou thr: 0.50, tp: 0, fp: 66, fn: 1312,precision: 0, recall: 0, f1: 0\n",
      "2025-05-11 18:29:49,512 - clrnet.utils.culane_metric - INFO - Calculating metric for List: ./data/CULane/list/test_split/test7_cross.txt\n",
      "2025-05-11 18:30:17,185 - clrnet.utils.culane_metric - INFO - iou thr: 0.50, tp: 0, fp: 260, fn: 0,precision: 0, recall: 0, f1: 0\n",
      "2025-05-11 18:30:17,189 - clrnet.utils.culane_metric - INFO - Calculating metric for List: ./data/CULane/list/test_split/test8_night.txt\n",
      "2025-05-11 18:30:49,038 - clrnet.utils.culane_metric - INFO - iou thr: 0.50, tp: 10, fp: 439, fn: 21020,precision: 0.022271714922048998, recall: 0.00047551117451260106, f1: 0.0009311420457190745\n"
     ]
    }
   ],
   "source": [
    "model_pc.eval()\n",
    "metric = validate_lane(model_pc, recorder, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-11 18:30:49,404 - clrnet.datasets.base_dataset - INFO - Loading CULane annotations...\n",
      "Validate: 100%|██████████| 1445/1445 [03:16<00:00,  7.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating prediction output...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-11 18:34:15,738 - clrnet.utils.culane_metric - INFO - Calculating metric for List: ./data/CULane/list/test_split/test0_normal.txt\n",
      "2025-05-11 18:35:16,818 - clrnet.utils.culane_metric - INFO - iou thr: 0.50, tp: 28958, fp: 3203, fn: 3819,precision: 0.9004073256428594, recall: 0.883485370839308, f1: 0.8918660876528381\n",
      "2025-05-11 18:35:16,955 - clrnet.utils.culane_metric - INFO - Calculating metric for List: ./data/CULane/list/test_split/test1_crowd.txt\n",
      "2025-05-11 18:36:09,523 - clrnet.utils.culane_metric - INFO - iou thr: 0.50, tp: 18254, fp: 4531, fn: 9749,precision: 0.8011411016019311, recall: 0.6518587294218476, f1: 0.718831219973222\n",
      "2025-05-11 18:36:09,632 - clrnet.utils.culane_metric - INFO - Calculating metric for List: ./data/CULane/list/test_split/test2_hlight.txt\n",
      "2025-05-11 18:36:41,127 - clrnet.utils.culane_metric - INFO - iou thr: 0.50, tp: 936, fp: 293, fn: 749,precision: 0.7615947925142392, recall: 0.5554896142433234, f1: 0.6424159231297186\n",
      "2025-05-11 18:36:41,136 - clrnet.utils.culane_metric - INFO - Calculating metric for List: ./data/CULane/list/test_split/test3_shadow.txt\n",
      "2025-05-11 18:37:12,611 - clrnet.utils.culane_metric - INFO - iou thr: 0.50, tp: 1994, fp: 427, fn: 882,precision: 0.8236266005782734, recall: 0.6933240611961057, f1: 0.7528789881064754\n",
      "2025-05-11 18:37:12,627 - clrnet.utils.culane_metric - INFO - Calculating metric for List: ./data/CULane/list/test_split/test4_noline.txt\n",
      "2025-05-11 18:37:50,121 - clrnet.utils.culane_metric - INFO - iou thr: 0.50, tp: 5230, fp: 2463, fn: 8791,precision: 0.6798388145066944, recall: 0.37301191070537054, f1: 0.4817168646955881\n",
      "2025-05-11 18:37:50,171 - clrnet.utils.culane_metric - INFO - Calculating metric for List: ./data/CULane/list/test_split/test5_arrow.txt\n",
      "2025-05-11 18:38:22,358 - clrnet.utils.culane_metric - INFO - iou thr: 0.50, tp: 2581, fp: 406, fn: 601,precision: 0.8640776699029126, recall: 0.811125078566939, f1: 0.8367644674987843\n",
      "2025-05-11 18:38:22,376 - clrnet.utils.culane_metric - INFO - Calculating metric for List: ./data/CULane/list/test_split/test6_curve.txt\n",
      "2025-05-11 18:38:52,237 - clrnet.utils.culane_metric - INFO - iou thr: 0.50, tp: 779, fp: 213, fn: 533,precision: 0.7852822580645161, recall: 0.59375, f1: 0.6762152777777778\n",
      "2025-05-11 18:38:52,246 - clrnet.utils.culane_metric - INFO - Calculating metric for List: ./data/CULane/list/test_split/test7_cross.txt\n",
      "2025-05-11 18:39:21,419 - clrnet.utils.culane_metric - INFO - iou thr: 0.50, tp: 0, fp: 1575, fn: 0,precision: 0, recall: 0, f1: 0\n",
      "2025-05-11 18:39:21,426 - clrnet.utils.culane_metric - INFO - Calculating metric for List: ./data/CULane/list/test_split/test8_night.txt\n",
      "2025-05-11 18:40:06,968 - clrnet.utils.culane_metric - INFO - iou thr: 0.50, tp: 12567, fp: 3797, fn: 8463,precision: 0.7679662674162796, recall: 0.5975748930099858, f1: 0.6721399154944643\n"
     ]
    }
   ],
   "source": [
    "model_pc_cs.eval()\n",
    "metric_pc_cs = validate_lane(model_pc_cs, recorder, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-11 18:40:07,990 - clrnet.datasets.base_dataset - INFO - Loading CULane annotations...\n",
      "Validate: 100%|██████████| 1445/1445 [03:15<00:00,  7.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating prediction output...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-11 18:43:32,968 - clrnet.utils.culane_metric - INFO - Calculating metric for List: ./data/CULane/list/test_split/test0_normal.txt\n",
      "2025-05-11 18:44:34,617 - clrnet.utils.culane_metric - INFO - iou thr: 0.50, tp: 28679, fp: 2742, fn: 4098,precision: 0.9127335221667038, recall: 0.8749733044512921, f1: 0.8934546247546653\n",
      "2025-05-11 18:44:34,751 - clrnet.utils.culane_metric - INFO - Calculating metric for List: ./data/CULane/list/test_split/test1_crowd.txt\n",
      "2025-05-11 18:45:27,708 - clrnet.utils.culane_metric - INFO - iou thr: 0.50, tp: 17655, fp: 3937, fn: 10348,precision: 0.817663949610967, recall: 0.6304681641252723, f1: 0.7119669321504184\n",
      "2025-05-11 18:45:27,812 - clrnet.utils.culane_metric - INFO - Calculating metric for List: ./data/CULane/list/test_split/test2_hlight.txt\n",
      "2025-05-11 18:46:00,395 - clrnet.utils.culane_metric - INFO - iou thr: 0.50, tp: 855, fp: 205, fn: 830,precision: 0.8066037735849056, recall: 0.5074183976261127, f1: 0.6229508196721312\n",
      "2025-05-11 18:46:00,404 - clrnet.utils.culane_metric - INFO - Calculating metric for List: ./data/CULane/list/test_split/test3_shadow.txt\n",
      "2025-05-11 18:46:32,019 - clrnet.utils.culane_metric - INFO - iou thr: 0.50, tp: 1875, fp: 445, fn: 1001,precision: 0.8081896551724138, recall: 0.6519471488178025, f1: 0.7217090069284064\n",
      "2025-05-11 18:46:32,035 - clrnet.utils.culane_metric - INFO - Calculating metric for List: ./data/CULane/list/test_split/test4_noline.txt\n",
      "2025-05-11 18:47:09,265 - clrnet.utils.culane_metric - INFO - iou thr: 0.50, tp: 4728, fp: 1826, fn: 9293,precision: 0.721391516631065, recall: 0.3372084730047785, f1: 0.45958687727825026\n",
      "2025-05-11 18:47:09,309 - clrnet.utils.culane_metric - INFO - Calculating metric for List: ./data/CULane/list/test_split/test5_arrow.txt\n",
      "2025-05-11 18:47:41,628 - clrnet.utils.culane_metric - INFO - iou thr: 0.50, tp: 2512, fp: 332, fn: 670,precision: 0.8832630098452883, recall: 0.7894406033940917, f1: 0.8337205443079987\n",
      "2025-05-11 18:47:41,642 - clrnet.utils.culane_metric - INFO - Calculating metric for List: ./data/CULane/list/test_split/test6_curve.txt\n",
      "2025-05-11 18:48:11,858 - clrnet.utils.culane_metric - INFO - iou thr: 0.50, tp: 772, fp: 162, fn: 540,precision: 0.8265524625267666, recall: 0.5884146341463414, f1: 0.6874443455031166\n",
      "2025-05-11 18:48:11,866 - clrnet.utils.culane_metric - INFO - Calculating metric for List: ./data/CULane/list/test_split/test7_cross.txt\n",
      "2025-05-11 18:48:41,293 - clrnet.utils.culane_metric - INFO - iou thr: 0.50, tp: 0, fp: 1178, fn: 0,precision: 0, recall: 0, f1: 0\n",
      "2025-05-11 18:48:41,299 - clrnet.utils.culane_metric - INFO - Calculating metric for List: ./data/CULane/list/test_split/test8_night.txt\n",
      "2025-05-11 18:49:27,449 - clrnet.utils.culane_metric - INFO - iou thr: 0.50, tp: 11984, fp: 2597, fn: 9046,precision: 0.8218915026404224, recall: 0.5698525915359011, f1: 0.6730504619359187\n"
     ]
    }
   ],
   "source": [
    "model_pc_cs_scale.eval()\n",
    "metric_pc_cs_scale = validate_lane(model_pc_cs_scale, recorder, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-04 01:33:45,894 - clrnet.datasets.base_dataset - INFO - Loading CULane annotations...\n",
      "Validate: 100%|██████████| 1445/1445 [03:03<00:00,  7.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating prediction output...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-04 01:37:02,159 - clrnet.utils.culane_metric - INFO - Calculating metric for List: ./data/CULane/list/test_split/test0_normal.txt\n",
      "2025-05-04 01:38:00,812 - clrnet.utils.culane_metric - INFO - iou thr: 0.50, tp: 1468, fp: 33214, fn: 31309,precision: 0.042327432097341564, recall: 0.04478750343228483, f1: 0.043522732326301904\n",
      "2025-05-04 01:38:00,952 - clrnet.utils.culane_metric - INFO - Calculating metric for List: ./data/CULane/list/test_split/test1_crowd.txt\n",
      "2025-05-04 01:38:54,687 - clrnet.utils.culane_metric - INFO - iou thr: 0.50, tp: 1090, fp: 27733, fn: 26913,precision: 0.03781702112895951, recall: 0.03892440095704032, f1: 0.03836272128955056\n",
      "2025-05-04 01:38:54,813 - clrnet.utils.culane_metric - INFO - Calculating metric for List: ./data/CULane/list/test_split/test2_hlight.txt\n",
      "2025-05-04 01:39:21,732 - clrnet.utils.culane_metric - INFO - iou thr: 0.50, tp: 71, fp: 1511, fn: 1614,precision: 0.04487989886219975, recall: 0.042136498516320474, f1: 0.04346495255586165\n",
      "2025-05-04 01:39:21,745 - clrnet.utils.culane_metric - INFO - Calculating metric for List: ./data/CULane/list/test_split/test3_shadow.txt\n",
      "2025-05-04 01:39:49,790 - clrnet.utils.culane_metric - INFO - iou thr: 0.50, tp: 93, fp: 2946, fn: 2783,precision: 0.03060217176702863, recall: 0.032336578581363004, f1: 0.03144547759932376\n",
      "2025-05-04 01:39:49,807 - clrnet.utils.culane_metric - INFO - Calculating metric for List: ./data/CULane/list/test_split/test4_noline.txt\n",
      "2025-05-04 01:40:27,882 - clrnet.utils.culane_metric - INFO - iou thr: 0.50, tp: 611, fp: 12661, fn: 13410,precision: 0.046036769138034964, recall: 0.043577490906497394, f1: 0.04477338511706299\n",
      "2025-05-04 01:40:27,947 - clrnet.utils.culane_metric - INFO - Calculating metric for List: ./data/CULane/list/test_split/test5_arrow.txt\n",
      "2025-05-04 01:40:55,213 - clrnet.utils.culane_metric - INFO - iou thr: 0.50, tp: 153, fp: 2979, fn: 3029,precision: 0.04885057471264368, recall: 0.04808296668761785, f1: 0.04846373139056066\n",
      "2025-05-04 01:40:55,229 - clrnet.utils.culane_metric - INFO - Calculating metric for List: ./data/CULane/list/test_split/test6_curve.txt\n",
      "2025-05-04 01:41:20,083 - clrnet.utils.culane_metric - INFO - iou thr: 0.50, tp: 31, fp: 1122, fn: 1281,precision: 0.026886383347788378, recall: 0.023628048780487805, f1: 0.02515212981744422\n",
      "2025-05-04 01:41:20,091 - clrnet.utils.culane_metric - INFO - Calculating metric for List: ./data/CULane/list/test_split/test7_cross.txt\n",
      "2025-05-04 01:41:44,584 - clrnet.utils.culane_metric - INFO - iou thr: 0.50, tp: 0, fp: 3478, fn: 0,precision: 0, recall: 0, f1: 0\n",
      "2025-05-04 01:41:44,598 - clrnet.utils.culane_metric - INFO - Calculating metric for List: ./data/CULane/list/test_split/test8_night.txt\n",
      "2025-05-04 01:42:28,443 - clrnet.utils.culane_metric - INFO - iou thr: 0.50, tp: 870, fp: 21137, fn: 20160,precision: 0.03953287590312173, recall: 0.04136947218259629, f1: 0.0404303273927086\n"
     ]
    }
   ],
   "source": [
    "model_cross_stitch.eval()\n",
    "metric = validate_lane(model_cross_stitch, recorder, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'normal': {0.5: {'TP': 1468,\n",
       "   'FP': 33214,\n",
       "   'FN': 31309,\n",
       "   'Precision': 0.042327432097341564,\n",
       "   'Recall': 0.04478750343228483,\n",
       "   'F1': 0.043522732326301904}},\n",
       " 'crowd': {0.5: {'TP': 1090,\n",
       "   'FP': 27733,\n",
       "   'FN': 26913,\n",
       "   'Precision': 0.03781702112895951,\n",
       "   'Recall': 0.03892440095704032,\n",
       "   'F1': 0.03836272128955056}},\n",
       " 'hlight': {0.5: {'TP': 71,\n",
       "   'FP': 1511,\n",
       "   'FN': 1614,\n",
       "   'Precision': 0.04487989886219975,\n",
       "   'Recall': 0.042136498516320474,\n",
       "   'F1': 0.04346495255586165}},\n",
       " 'shadow': {0.5: {'TP': 93,\n",
       "   'FP': 2946,\n",
       "   'FN': 2783,\n",
       "   'Precision': 0.03060217176702863,\n",
       "   'Recall': 0.032336578581363004,\n",
       "   'F1': 0.03144547759932376}},\n",
       " 'noline': {0.5: {'TP': 611,\n",
       "   'FP': 12661,\n",
       "   'FN': 13410,\n",
       "   'Precision': 0.046036769138034964,\n",
       "   'Recall': 0.043577490906497394,\n",
       "   'F1': 0.04477338511706299}},\n",
       " 'arrow': {0.5: {'TP': 153,\n",
       "   'FP': 2979,\n",
       "   'FN': 3029,\n",
       "   'Precision': 0.04885057471264368,\n",
       "   'Recall': 0.04808296668761785,\n",
       "   'F1': 0.04846373139056066}},\n",
       " 'curve': {0.5: {'TP': 31,\n",
       "   'FP': 1122,\n",
       "   'FN': 1281,\n",
       "   'Precision': 0.026886383347788378,\n",
       "   'Recall': 0.023628048780487805,\n",
       "   'F1': 0.02515212981744422}},\n",
       " 'cross': {0.5: {'TP': 0,\n",
       "   'FP': 3478,\n",
       "   'FN': 0,\n",
       "   'Precision': 0,\n",
       "   'Recall': 0,\n",
       "   'F1': 0}},\n",
       " 'night': {0.5: {'TP': 870,\n",
       "   'FP': 21137,\n",
       "   'FN': 20160,\n",
       "   'Precision': 0.03953287590312173,\n",
       "   'Recall': 0.04136947218259629,\n",
       "   'F1': 0.0404303273927086}}}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-04 00:09:58,243 - clrnet.datasets.base_dataset - INFO - Loading CULane annotations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 1445/1445 [02:48<00:00,  8.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating prediction output...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-04 00:12:56,785 - clrnet.utils.culane_metric - INFO - Calculating metric for List: ./data/CULane/list/test_split/test0_normal.txt\n",
      "2025-05-04 00:13:47,595 - clrnet.utils.culane_metric - INFO - iou thr: 0.50, tp: 28679, fp: 2742, fn: 4098,precision: 0.9127335221667038, recall: 0.8749733044512921, f1: 0.8934546247546653\n",
      "2025-05-04 00:13:47,739 - clrnet.utils.culane_metric - INFO - Calculating metric for List: ./data/CULane/list/test_split/test1_crowd.txt\n",
      "2025-05-04 00:14:29,380 - clrnet.utils.culane_metric - INFO - iou thr: 0.50, tp: 17655, fp: 3937, fn: 10348,precision: 0.817663949610967, recall: 0.6304681641252723, f1: 0.7119669321504184\n",
      "2025-05-04 00:14:29,488 - clrnet.utils.culane_metric - INFO - Calculating metric for List: ./data/CULane/list/test_split/test2_hlight.txt\n",
      "2025-05-04 00:14:49,610 - clrnet.utils.culane_metric - INFO - iou thr: 0.50, tp: 855, fp: 205, fn: 830,precision: 0.8066037735849056, recall: 0.5074183976261127, f1: 0.6229508196721312\n",
      "2025-05-04 00:14:49,620 - clrnet.utils.culane_metric - INFO - Calculating metric for List: ./data/CULane/list/test_split/test3_shadow.txt\n",
      "2025-05-04 00:15:10,849 - clrnet.utils.culane_metric - INFO - iou thr: 0.50, tp: 1875, fp: 445, fn: 1001,precision: 0.8081896551724138, recall: 0.6519471488178025, f1: 0.7217090069284064\n",
      "2025-05-04 00:15:10,864 - clrnet.utils.culane_metric - INFO - Calculating metric for List: ./data/CULane/list/test_split/test4_noline.txt\n",
      "2025-05-04 00:15:37,447 - clrnet.utils.culane_metric - INFO - iou thr: 0.50, tp: 4728, fp: 1826, fn: 9293,precision: 0.721391516631065, recall: 0.3372084730047785, f1: 0.45958687727825026\n",
      "2025-05-04 00:15:37,491 - clrnet.utils.culane_metric - INFO - Calculating metric for List: ./data/CULane/list/test_split/test5_arrow.txt\n",
      "2025-05-04 00:15:59,283 - clrnet.utils.culane_metric - INFO - iou thr: 0.50, tp: 2512, fp: 332, fn: 670,precision: 0.8832630098452883, recall: 0.7894406033940917, f1: 0.8337205443079987\n",
      "2025-05-04 00:15:59,301 - clrnet.utils.culane_metric - INFO - Calculating metric for List: ./data/CULane/list/test_split/test6_curve.txt\n",
      "2025-05-04 00:16:19,014 - clrnet.utils.culane_metric - INFO - iou thr: 0.50, tp: 772, fp: 162, fn: 540,precision: 0.8265524625267666, recall: 0.5884146341463414, f1: 0.6874443455031166\n",
      "2025-05-04 00:16:19,022 - clrnet.utils.culane_metric - INFO - Calculating metric for List: ./data/CULane/list/test_split/test7_cross.txt\n",
      "2025-05-04 00:16:38,119 - clrnet.utils.culane_metric - INFO - iou thr: 0.50, tp: 0, fp: 1178, fn: 0,precision: 0, recall: 0, f1: 0\n",
      "2025-05-04 00:16:38,126 - clrnet.utils.culane_metric - INFO - Calculating metric for List: ./data/CULane/list/test_split/test8_night.txt\n",
      "2025-05-04 00:17:12,426 - clrnet.utils.culane_metric - INFO - iou thr: 0.50, tp: 11984, fp: 2597, fn: 9046,precision: 0.8218915026404224, recall: 0.5698525915359011, f1: 0.6730504619359187\n",
      "2025-05-04 00:17:12,502 - clrnet.utils.culane_metric - INFO - Calculating metric for List: ./data/CULane/list/test.txt\n",
      "2025-05-04 00:18:56,078 - clrnet.utils.culane_metric - INFO - iou thr: 0.50, tp: 69060, fp: 13424, fn: 35826,precision: 0.8372532854856699, recall: 0.6584291516503632, f1: 0.7371510914233868\n",
      "2025-05-04 00:18:56,111 - clrnet.utils.culane_metric - INFO - iou thr: 0.55, tp: 67233, fp: 15251, fn: 37653,precision: 0.8151035352310751, recall: 0.641010239688805, f1: 0.7176495703687891\n",
      "2025-05-04 00:18:56,143 - clrnet.utils.culane_metric - INFO - iou thr: 0.60, tp: 64995, fp: 17489, fn: 39891,precision: 0.7879710004364483, recall: 0.6196727875979635, f1: 0.6937610076319582\n",
      "2025-05-04 00:18:56,175 - clrnet.utils.culane_metric - INFO - iou thr: 0.65, tp: 62131, fp: 20353, fn: 42755,precision: 0.7532491149798749, recall: 0.5923669507846614, f1: 0.6631904787319208\n",
      "2025-05-04 00:18:56,207 - clrnet.utils.culane_metric - INFO - iou thr: 0.70, tp: 57920, fp: 24564, fn: 46966,precision: 0.7021967896804229, recall: 0.5522185992410807, f1: 0.6182419811069007\n",
      "2025-05-04 00:18:56,240 - clrnet.utils.culane_metric - INFO - iou thr: 0.75, tp: 51852, fp: 30632, fn: 53034,precision: 0.6286310072256438, recall: 0.4943653109089869, f1: 0.5534717404066819\n",
      "2025-05-04 00:18:56,273 - clrnet.utils.culane_metric - INFO - iou thr: 0.80, tp: 43177, fp: 39307, fn: 61709,precision: 0.523459095097231, recall: 0.41165646511450527, f1: 0.4608742061162406\n",
      "2025-05-04 00:18:56,306 - clrnet.utils.culane_metric - INFO - iou thr: 0.85, tp: 30265, fp: 52219, fn: 74621,precision: 0.36691964502206487, recall: 0.288551379593082, f1: 0.3230506484495917\n",
      "2025-05-04 00:18:56,337 - clrnet.utils.culane_metric - INFO - iou thr: 0.90, tp: 13961, fp: 68523, fn: 90925,precision: 0.16925706803743756, recall: 0.13310642030394904, f1: 0.14902065432032877\n",
      "2025-05-04 00:18:56,367 - clrnet.utils.culane_metric - INFO - iou thr: 0.95, tp: 1196, fp: 81288, fn: 103690,precision: 0.01449978177585956, recall: 0.01140285643460519, f1: 0.01276618455462454\n",
      "2025-05-04 00:18:56,368 - clrnet.utils.culane_metric - INFO - mean result, total_tp: 461790, total_fp: 363050, total_fn: 587070,precision: 0.5598540322971727, recall: 0.44027801613180023, f1: 0.4929177563110423\n",
      "2025-05-04 00:18:56,791 - clrnet.utils.recorder - INFO - metric: 0.7371510914233868\n"
     ]
    }
   ],
   "source": [
    "model_cross_stitch.eval()\n",
    "metric = validate_lane(model_cross_stitch, recorder, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7371510914233868"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-04 00:19:46,117 - clrnet.datasets.base_dataset - INFO - Loading CULane annotations...\n",
      "Validate: 100%|██████████| 1445/1445 [02:12<00:00, 10.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating prediction output...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-04 00:22:04,095 - clrnet.utils.culane_metric - INFO - Calculating metric for List: ./data/CULane/list/test_split/test0_normal.txt\n",
      "2025-05-04 00:22:35,029 - clrnet.utils.culane_metric - INFO - iou thr: 0.50, tp: 140, fp: 7218, fn: 32637,precision: 0.019026909486273443, recall: 0.004271287793269671, f1: 0.006976454466176654\n",
      "2025-05-04 00:22:35,112 - clrnet.utils.culane_metric - INFO - Calculating metric for List: ./data/CULane/list/test_split/test1_crowd.txt\n",
      "2025-05-04 00:23:02,167 - clrnet.utils.culane_metric - INFO - iou thr: 0.50, tp: 21, fp: 4059, fn: 27982,precision: 0.005147058823529412, recall: 0.0007499196514659144, f1: 0.0013091045101767292\n",
      "2025-05-04 00:23:02,232 - clrnet.utils.culane_metric - INFO - Calculating metric for List: ./data/CULane/list/test_split/test2_hlight.txt\n",
      "2025-05-04 00:23:21,591 - clrnet.utils.culane_metric - INFO - iou thr: 0.50, tp: 2, fp: 231, fn: 1683,precision: 0.008583690987124463, recall: 0.0011869436201780415, f1: 0.0020855057351407713\n",
      "2025-05-04 00:23:21,600 - clrnet.utils.culane_metric - INFO - Calculating metric for List: ./data/CULane/list/test_split/test3_shadow.txt\n",
      "2025-05-04 00:23:40,964 - clrnet.utils.culane_metric - INFO - iou thr: 0.50, tp: 0, fp: 351, fn: 2876,precision: 0, recall: 0, f1: 0\n",
      "2025-05-04 00:23:40,976 - clrnet.utils.culane_metric - INFO - Calculating metric for List: ./data/CULane/list/test_split/test4_noline.txt\n",
      "2025-05-04 00:24:02,844 - clrnet.utils.culane_metric - INFO - iou thr: 0.50, tp: 19, fp: 1531, fn: 14002,precision: 0.012258064516129033, recall: 0.0013551101918550744, f1: 0.002440434140389185\n",
      "2025-05-04 00:24:02,875 - clrnet.utils.culane_metric - INFO - Calculating metric for List: ./data/CULane/list/test_split/test5_arrow.txt\n",
      "2025-05-04 00:24:22,299 - clrnet.utils.culane_metric - INFO - iou thr: 0.50, tp: 6, fp: 672, fn: 3176,precision: 0.008849557522123894, recall: 0.0018856065367693275, f1: 0.0031088082901554403\n",
      "2025-05-04 00:24:22,311 - clrnet.utils.culane_metric - INFO - Calculating metric for List: ./data/CULane/list/test_split/test6_curve.txt\n",
      "2025-05-04 00:24:41,702 - clrnet.utils.culane_metric - INFO - iou thr: 0.50, tp: 1, fp: 160, fn: 1311,precision: 0.006211180124223602, recall: 0.0007621951219512195, f1: 0.0013577732518669384\n",
      "2025-05-04 00:24:41,709 - clrnet.utils.culane_metric - INFO - Calculating metric for List: ./data/CULane/list/test_split/test7_cross.txt\n",
      "2025-05-04 00:25:00,689 - clrnet.utils.culane_metric - INFO - iou thr: 0.50, tp: 0, fp: 221, fn: 0,precision: 0, recall: 0, f1: 0\n",
      "2025-05-04 00:25:00,694 - clrnet.utils.culane_metric - INFO - Calculating metric for List: ./data/CULane/list/test_split/test8_night.txt\n",
      "2025-05-04 00:25:25,521 - clrnet.utils.culane_metric - INFO - iou thr: 0.50, tp: 14, fp: 2382, fn: 21016,precision: 0.005843071786310518, recall: 0.0006657156443176414, f1: 0.001195253137539486\n",
      "2025-05-04 00:25:25,572 - clrnet.utils.culane_metric - INFO - Calculating metric for List: ./data/CULane/list/test.txt\n",
      "2025-05-04 00:26:14,454 - clrnet.utils.culane_metric - INFO - iou thr: 0.50, tp: 203, fp: 16825, fn: 104683,precision: 0.011921540991308432, recall: 0.0019354346623953625, f1: 0.0033302163820397982\n",
      "2025-05-04 00:26:14,485 - clrnet.utils.culane_metric - INFO - iou thr: 0.55, tp: 158, fp: 16870, fn: 104728,precision: 0.00927883486023021, recall: 0.001506397421962893, f1: 0.0025919910756762965\n",
      "2025-05-04 00:26:14,515 - clrnet.utils.culane_metric - INFO - iou thr: 0.60, tp: 114, fp: 16914, fn: 104772,precision: 0.0066948555320648345, recall: 0.0010868943424289228, f1: 0.001870170776120872\n",
      "2025-05-04 00:26:14,544 - clrnet.utils.culane_metric - INFO - iou thr: 0.65, tp: 84, fp: 16944, fn: 104802,precision: 0.004933051444679351, recall: 0.0008008695154739431, f1: 0.0013780205718785373\n",
      "2025-05-04 00:26:14,574 - clrnet.utils.culane_metric - INFO - iou thr: 0.70, tp: 61, fp: 16967, fn: 104825,precision: 0.003582334977683815, recall: 0.0005815838148084588, f1: 0.0010007054152927474\n",
      "2025-05-04 00:26:14,603 - clrnet.utils.culane_metric - INFO - iou thr: 0.75, tp: 41, fp: 16987, fn: 104845,precision: 0.0024077989194268264, recall: 0.00039090059683847227, f1: 0.0006726052791311909\n",
      "2025-05-04 00:26:14,632 - clrnet.utils.culane_metric - INFO - iou thr: 0.80, tp: 18, fp: 17010, fn: 104868,precision: 0.0010570824524312897, recall: 0.00017161489617298782, f1: 0.00029529012254540083\n",
      "2025-05-04 00:26:14,661 - clrnet.utils.culane_metric - INFO - iou thr: 0.85, tp: 9, fp: 17019, fn: 104877,precision: 0.0005285412262156448, recall: 8.580744808649391e-05, f1: 0.00014764506127270041\n",
      "2025-05-04 00:26:14,690 - clrnet.utils.culane_metric - INFO - iou thr: 0.90, tp: 3, fp: 17025, fn: 104883,precision: 0.00017618040873854828, recall: 2.860248269549797e-05, f1: 4.921502042423349e-05\n",
      "2025-05-04 00:26:14,719 - clrnet.utils.culane_metric - INFO - iou thr: 0.95, tp: 0, fp: 17028, fn: 104886,precision: 0, recall: 0, f1: 0\n",
      "2025-05-04 00:26:14,720 - clrnet.utils.culane_metric - INFO - mean result, total_tp: 691, total_fp: 169589, total_fn: 1048169,precision: 0.0040580220812778955, recall: 0.0006588105180863031, f1: 0.0011335859704381778\n",
      "2025-05-04 00:26:14,974 - clrnet.utils.recorder - INFO - metric: 0.0033302163820397982\n"
     ]
    }
   ],
   "source": [
    "model_cross_stitch.eval()\n",
    "metric2 = validate_lane(model_cross_stitch, recorder, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-03 15:57:40,013 - clrnet.datasets.base_dataset - INFO - Loading CULane annotations...\n",
      "Validate: 100%|██████████| 1445/1445 [02:46<00:00,  8.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating prediction output...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-03 16:00:37,162 - clrnet.utils.culane_metric - INFO - Calculating metric for List: ./data/CULane/list/test_split/test0_normal.txt\n",
      "2025-05-03 16:01:30,042 - clrnet.utils.culane_metric - INFO - iou thr: 0.50, tp: 28486, fp: 2522, fn: 4291,precision: 0.9186661506707946, recall: 0.8690850291362846, f1: 0.8931880536176218\n",
      "2025-05-03 16:01:30,172 - clrnet.utils.culane_metric - INFO - Calculating metric for List: ./data/CULane/list/test_split/test1_crowd.txt\n",
      "2025-05-03 16:02:14,223 - clrnet.utils.culane_metric - INFO - iou thr: 0.50, tp: 17385, fp: 3847, fn: 10618,precision: 0.8188112283345893, recall: 0.6208263400349963, f1: 0.7062049355133544\n",
      "2025-05-03 16:02:14,329 - clrnet.utils.culane_metric - INFO - Calculating metric for List: ./data/CULane/list/test_split/test2_hlight.txt\n",
      "2025-05-03 16:02:37,566 - clrnet.utils.culane_metric - INFO - iou thr: 0.50, tp: 888, fp: 238, fn: 797,precision: 0.7886323268206039, recall: 0.5270029673590505, f1: 0.6318036286019212\n",
      "2025-05-03 16:02:37,576 - clrnet.utils.culane_metric - INFO - Calculating metric for List: ./data/CULane/list/test_split/test3_shadow.txt\n",
      "2025-05-03 16:03:01,723 - clrnet.utils.culane_metric - INFO - iou thr: 0.50, tp: 1854, fp: 428, fn: 1022,precision: 0.8124452234881683, recall: 0.6446453407510431, f1: 0.7188832880961613\n",
      "2025-05-03 16:03:01,738 - clrnet.utils.culane_metric - INFO - Calculating metric for List: ./data/CULane/list/test_split/test4_noline.txt\n",
      "2025-05-03 16:03:31,205 - clrnet.utils.culane_metric - INFO - iou thr: 0.50, tp: 4683, fp: 1855, fn: 9338,precision: 0.7162740899357601, recall: 0.33399900149775336, f1: 0.45556690500510727\n",
      "2025-05-03 16:03:31,251 - clrnet.utils.culane_metric - INFO - Calculating metric for List: ./data/CULane/list/test_split/test5_arrow.txt\n",
      "2025-05-03 16:03:56,039 - clrnet.utils.culane_metric - INFO - iou thr: 0.50, tp: 2511, fp: 297, fn: 671,precision: 0.8942307692307693, recall: 0.7891263356379635, f1: 0.8383973288814691\n",
      "2025-05-03 16:03:56,053 - clrnet.utils.culane_metric - INFO - Calculating metric for List: ./data/CULane/list/test_split/test6_curve.txt\n",
      "2025-05-03 16:04:18,914 - clrnet.utils.culane_metric - INFO - iou thr: 0.50, tp: 765, fp: 166, fn: 547,precision: 0.8216970998925887, recall: 0.583079268292683, f1: 0.6821221578243424\n",
      "2025-05-03 16:04:18,922 - clrnet.utils.culane_metric - INFO - Calculating metric for List: ./data/CULane/list/test_split/test7_cross.txt\n",
      "2025-05-03 16:04:40,918 - clrnet.utils.culane_metric - INFO - iou thr: 0.50, tp: 0, fp: 1260, fn: 0,precision: 0, recall: 0, f1: 0\n",
      "2025-05-03 16:04:40,926 - clrnet.utils.culane_metric - INFO - Calculating metric for List: ./data/CULane/list/test_split/test8_night.txt\n",
      "2025-05-03 16:05:18,457 - clrnet.utils.culane_metric - INFO - iou thr: 0.50, tp: 11716, fp: 2546, fn: 9314,precision: 0.8214836628803814, recall: 0.5571088920589634, f1: 0.663946503456874\n",
      "2025-05-03 16:05:18,531 - clrnet.utils.culane_metric - INFO - Calculating metric for List: ./data/CULane/list/test.txt\n",
      "2025-05-03 16:07:02,649 - clrnet.utils.culane_metric - INFO - iou thr: 0.50, tp: 68288, fp: 13159, fn: 36598,precision: 0.8384348103674782, recall: 0.6510687794367218, f1: 0.7329673219451198\n",
      "2025-05-03 16:07:02,679 - clrnet.utils.culane_metric - INFO - iou thr: 0.55, tp: 66374, fp: 15073, fn: 38512,precision: 0.814934865618132, recall: 0.6328203954769941, f1: 0.7124234569292611\n",
      "2025-05-03 16:07:02,709 - clrnet.utils.culane_metric - INFO - iou thr: 0.60, tp: 63940, fp: 17507, fn: 40946,precision: 0.7850504008741881, recall: 0.6096142478500467, f1: 0.6862981865799401\n",
      "2025-05-03 16:07:02,738 - clrnet.utils.culane_metric - INFO - iou thr: 0.65, tp: 60747, fp: 20700, fn: 44139,precision: 0.7458469925227449, recall: 0.5791716721011384, f1: 0.6520262111381238\n",
      "2025-05-03 16:07:02,767 - clrnet.utils.culane_metric - INFO - iou thr: 0.70, tp: 56086, fp: 25361, fn: 48800,precision: 0.6886195931096296, recall: 0.534732948153233, f1: 0.6019974991010717\n",
      "2025-05-03 16:07:02,795 - clrnet.utils.culane_metric - INFO - iou thr: 0.75, tp: 49708, fp: 31739, fn: 55178,precision: 0.6103109997912753, recall: 0.47392406994260433, f1: 0.5335394159917997\n",
      "2025-05-03 16:07:02,823 - clrnet.utils.culane_metric - INFO - iou thr: 0.80, tp: 40174, fp: 41273, fn: 64712,precision: 0.4932532812749395, recall: 0.3830253799363118, f1: 0.4312064958971304\n",
      "2025-05-03 16:07:02,851 - clrnet.utils.culane_metric - INFO - iou thr: 0.85, tp: 26389, fp: 55058, fn: 78497,precision: 0.32400211180276745, recall: 0.2515969719504986, f1: 0.28324558720140824\n",
      "2025-05-03 16:07:02,879 - clrnet.utils.culane_metric - INFO - iou thr: 0.90, tp: 10998, fp: 70449, fn: 93888,precision: 0.13503259788574165, recall: 0.10485670156169556, f1: 0.11804672280272416\n",
      "2025-05-03 16:07:02,908 - clrnet.utils.culane_metric - INFO - iou thr: 0.95, tp: 988, fp: 80459, fn: 103898,precision: 0.012130587989735656, recall: 0.009419750967717331, f1: 0.010604670133578057\n",
      "2025-05-03 16:07:02,908 - clrnet.utils.culane_metric - INFO - mean result, total_tp: 443692, total_fp: 370778, total_fn: 605168,precision: 0.5447616241236632, recall: 0.4230230917376962, f1: 0.47623555677201573\n",
      "2025-05-03 16:07:03,292 - clrnet.utils.recorder - INFO - metric: 0.7329673219451198\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7329673219451198"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cross_stitch.eval()\n",
    "validate_lane(model_cross_stitch, recorder, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-03 14:36:20,647 - clrnet.datasets.base_dataset - INFO - Loading CULane annotations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate: 100%|██████████| 1445/1445 [02:48<00:00,  8.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating prediction output...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-03 14:39:19,506 - clrnet.utils.culane_metric - INFO - Calculating metric for List: ./data/CULane/list/test_split/test0_normal.txt\n",
      "2025-05-03 14:40:12,580 - clrnet.utils.culane_metric - INFO - iou thr: 0.50, tp: 28905, fp: 2736, fn: 3872,precision: 0.9135299137195411, recall: 0.8818683833175702, f1: 0.8974199757831661\n",
      "2025-05-03 14:40:12,719 - clrnet.utils.culane_metric - INFO - Calculating metric for List: ./data/CULane/list/test_split/test1_crowd.txt\n",
      "2025-05-03 14:40:56,588 - clrnet.utils.culane_metric - INFO - iou thr: 0.50, tp: 18007, fp: 4200, fn: 9996,precision: 0.8108704462556852, recall: 0.6430382459022248, f1: 0.7172674765982873\n",
      "2025-05-03 14:40:56,694 - clrnet.utils.culane_metric - INFO - Calculating metric for List: ./data/CULane/list/test_split/test2_hlight.txt\n",
      "2025-05-03 14:41:18,952 - clrnet.utils.culane_metric - INFO - iou thr: 0.50, tp: 912, fp: 240, fn: 773,precision: 0.7916666666666666, recall: 0.5412462908011869, f1: 0.6429326753612972\n",
      "2025-05-03 14:41:18,963 - clrnet.utils.culane_metric - INFO - Calculating metric for List: ./data/CULane/list/test_split/test3_shadow.txt\n",
      "2025-05-03 14:41:42,226 - clrnet.utils.culane_metric - INFO - iou thr: 0.50, tp: 1892, fp: 472, fn: 984,precision: 0.8003384094754653, recall: 0.6578581363004172, f1: 0.7221374045801526\n",
      "2025-05-03 14:41:42,241 - clrnet.utils.culane_metric - INFO - Calculating metric for List: ./data/CULane/list/test_split/test4_noline.txt\n",
      "2025-05-03 14:42:11,057 - clrnet.utils.culane_metric - INFO - iou thr: 0.50, tp: 4897, fp: 2069, fn: 9124,precision: 0.7029859316681022, recall: 0.3492618215533842, f1: 0.4666698432362891\n",
      "2025-05-03 14:42:11,103 - clrnet.utils.culane_metric - INFO - Calculating metric for List: ./data/CULane/list/test_split/test5_arrow.txt\n",
      "2025-05-03 14:42:34,967 - clrnet.utils.culane_metric - INFO - iou thr: 0.50, tp: 2552, fp: 336, fn: 630,precision: 0.8836565096952909, recall: 0.8020113136392206, f1: 0.8408566721581548\n",
      "2025-05-03 14:42:34,983 - clrnet.utils.culane_metric - INFO - Calculating metric for List: ./data/CULane/list/test_split/test6_curve.txt\n",
      "2025-05-03 14:42:56,725 - clrnet.utils.culane_metric - INFO - iou thr: 0.50, tp: 798, fp: 170, fn: 514,precision: 0.8243801652892562, recall: 0.6082317073170732, f1: 0.7000000000000001\n",
      "2025-05-03 14:42:56,734 - clrnet.utils.culane_metric - INFO - Calculating metric for List: ./data/CULane/list/test_split/test7_cross.txt\n",
      "2025-05-03 14:43:17,873 - clrnet.utils.culane_metric - INFO - iou thr: 0.50, tp: 0, fp: 1334, fn: 0,precision: 0, recall: 0, f1: 0\n",
      "2025-05-03 14:43:17,879 - clrnet.utils.culane_metric - INFO - Calculating metric for List: ./data/CULane/list/test_split/test8_night.txt\n",
      "2025-05-03 14:43:54,047 - clrnet.utils.culane_metric - INFO - iou thr: 0.50, tp: 12133, fp: 2838, fn: 8897,precision: 0.8104335047759, recall: 0.5769377080361389, f1: 0.6740368323102135\n",
      "2025-05-03 14:43:54,120 - clrnet.utils.culane_metric - INFO - Calculating metric for List: ./data/CULane/list/test.txt\n",
      "2025-05-03 14:45:41,324 - clrnet.utils.culane_metric - INFO - iou thr: 0.50, tp: 70096, fp: 14395, fn: 34790,precision: 0.8296268241587862, recall: 0.6683065423412086, f1: 0.7402799706405742\n",
      "2025-05-03 14:45:41,354 - clrnet.utils.culane_metric - INFO - iou thr: 0.55, tp: 68169, fp: 16322, fn: 36717,precision: 0.8068196612656969, recall: 0.6499342142898004, f1: 0.7199290304524836\n",
      "2025-05-03 14:45:41,384 - clrnet.utils.culane_metric - INFO - iou thr: 0.60, tp: 65797, fp: 18694, fn: 39089,precision: 0.7787456652187807, recall: 0.62731918463856, f1: 0.6948784699303506\n",
      "2025-05-03 14:45:41,414 - clrnet.utils.culane_metric - INFO - iou thr: 0.65, tp: 62688, fp: 21803, fn: 42198,precision: 0.7419488466227172, recall: 0.5976774784051255, f1: 0.6620444932594771\n",
      "2025-05-03 14:45:41,443 - clrnet.utils.culane_metric - INFO - iou thr: 0.70, tp: 58330, fp: 26161, fn: 46556,precision: 0.6903693884555752, recall: 0.5561276052094655, f1: 0.6160198968195716\n",
      "2025-05-03 14:45:41,472 - clrnet.utils.culane_metric - INFO - iou thr: 0.75, tp: 52065, fp: 32426, fn: 52821,precision: 0.6162194789977631, recall: 0.49639608718036726, f1: 0.5498555790829932\n",
      "2025-05-03 14:45:41,500 - clrnet.utils.culane_metric - INFO - iou thr: 0.80, tp: 43038, fp: 41453, fn: 61848,precision: 0.5093796972458605, recall: 0.41033121674961387, f1: 0.4545219324416375\n",
      "2025-05-03 14:45:41,529 - clrnet.utils.culane_metric - INFO - iou thr: 0.85, tp: 30079, fp: 54412, fn: 74807,precision: 0.3560024144583447, recall: 0.2867780256659611, f1: 0.3176626517475723\n",
      "2025-05-03 14:45:41,558 - clrnet.utils.culane_metric - INFO - iou thr: 0.90, tp: 13679, fp: 70812, fn: 91207,precision: 0.16189890047460676, recall: 0.13041778693057224, f1: 0.1444631607851006\n",
      "2025-05-03 14:45:41,588 - clrnet.utils.culane_metric - INFO - iou thr: 0.95, tp: 1167, fp: 83324, fn: 103719,precision: 0.013812122001159886, recall: 0.01112636576854871, f1: 0.012324622314219782\n",
      "2025-05-03 14:45:41,588 - clrnet.utils.culane_metric - INFO - mean result, total_tp: 465108, total_fp: 379802, total_fn: 583752,precision: 0.5504822998899291, recall: 0.44344145071792235, f1: 0.49119798074739807\n",
      "2025-05-03 14:45:41,987 - clrnet.utils.recorder - INFO - metric: 0.7402799706405742\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7402799706405742"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cross_stitch.eval()\n",
    "validate_lane(model_cross_stitch, recorder, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-03 15:11:01,567 - clrnet.datasets.base_dataset - INFO - Loading CULane annotations...\n",
      "Validate: 100%|██████████| 1445/1445 [02:47<00:00,  8.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating prediction output...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-03 15:13:58,916 - clrnet.utils.culane_metric - INFO - Calculating metric for List: ./data/CULane/list/test_split/test0_normal.txt\n",
      "2025-05-03 15:14:52,055 - clrnet.utils.culane_metric - INFO - iou thr: 0.50, tp: 28920, fp: 2706, fn: 3857,precision: 0.9144374881426675, recall: 0.8823260212954206, f1: 0.8980948092480163\n",
      "2025-05-03 15:14:52,186 - clrnet.utils.culane_metric - INFO - Calculating metric for List: ./data/CULane/list/test_split/test1_crowd.txt\n",
      "2025-05-03 15:15:37,395 - clrnet.utils.culane_metric - INFO - iou thr: 0.50, tp: 17856, fp: 4178, fn: 10147,precision: 0.8103839520740673, recall: 0.6376459665035888, f1: 0.7137118532286107\n",
      "2025-05-03 15:15:37,499 - clrnet.utils.culane_metric - INFO - Calculating metric for List: ./data/CULane/list/test_split/test2_hlight.txt\n",
      "2025-05-03 15:16:00,798 - clrnet.utils.culane_metric - INFO - iou thr: 0.50, tp: 924, fp: 245, fn: 761,precision: 0.7904191616766467, recall: 0.5483679525222552, f1: 0.6475122634898389\n",
      "2025-05-03 15:16:00,812 - clrnet.utils.culane_metric - INFO - Calculating metric for List: ./data/CULane/list/test_split/test3_shadow.txt\n",
      "2025-05-03 15:16:24,985 - clrnet.utils.culane_metric - INFO - iou thr: 0.50, tp: 1913, fp: 453, fn: 963,precision: 0.8085376162299239, recall: 0.6651599443671766, f1: 0.7298740938573064\n",
      "2025-05-03 15:16:25,001 - clrnet.utils.culane_metric - INFO - Calculating metric for List: ./data/CULane/list/test_split/test4_noline.txt\n",
      "2025-05-03 15:16:54,821 - clrnet.utils.culane_metric - INFO - iou thr: 0.50, tp: 4942, fp: 2018, fn: 9079,precision: 0.7100574712643678, recall: 0.35247129306040936, f1: 0.47109289357037315\n",
      "2025-05-03 15:16:54,864 - clrnet.utils.culane_metric - INFO - Calculating metric for List: ./data/CULane/list/test_split/test5_arrow.txt\n",
      "2025-05-03 15:17:19,741 - clrnet.utils.culane_metric - INFO - iou thr: 0.50, tp: 2555, fp: 334, fn: 627,precision: 0.8843890619591555, recall: 0.8029541169076053, f1: 0.8417064733981223\n",
      "2025-05-03 15:17:19,758 - clrnet.utils.culane_metric - INFO - Calculating metric for List: ./data/CULane/list/test_split/test6_curve.txt\n",
      "2025-05-03 15:17:42,535 - clrnet.utils.culane_metric - INFO - iou thr: 0.50, tp: 803, fp: 182, fn: 509,precision: 0.8152284263959391, recall: 0.6120426829268293, f1: 0.6991728341314759\n",
      "2025-05-03 15:17:42,543 - clrnet.utils.culane_metric - INFO - Calculating metric for List: ./data/CULane/list/test_split/test7_cross.txt\n",
      "2025-05-03 15:18:04,652 - clrnet.utils.culane_metric - INFO - iou thr: 0.50, tp: 0, fp: 1320, fn: 0,precision: 0, recall: 0, f1: 0\n",
      "2025-05-03 15:18:04,659 - clrnet.utils.culane_metric - INFO - Calculating metric for List: ./data/CULane/list/test_split/test8_night.txt\n",
      "2025-05-03 15:18:41,756 - clrnet.utils.culane_metric - INFO - iou thr: 0.50, tp: 12174, fp: 2775, fn: 8856,precision: 0.8143688541039534, recall: 0.5788873038516406, f1: 0.6767280913866422\n",
      "2025-05-03 15:18:41,833 - clrnet.utils.culane_metric - INFO - Calculating metric for List: ./data/CULane/list/test.txt\n",
      "2025-05-03 15:20:30,401 - clrnet.utils.culane_metric - INFO - iou thr: 0.50, tp: 70087, fp: 14211, fn: 34799,precision: 0.8314194880068329, recall: 0.6682207348931221, f1: 0.7409400372124493\n",
      "2025-05-03 15:20:30,431 - clrnet.utils.culane_metric - INFO - iou thr: 0.55, tp: 68140, fp: 16158, fn: 36746,precision: 0.8083228546347482, recall: 0.6496577236237439, f1: 0.720356901217862\n",
      "2025-05-03 15:20:30,461 - clrnet.utils.culane_metric - INFO - iou thr: 0.60, tp: 65724, fp: 18574, fn: 39162,precision: 0.7796626254478161, recall: 0.6266231908929695, f1: 0.6948156292286873\n",
      "2025-05-03 15:20:30,491 - clrnet.utils.culane_metric - INFO - iou thr: 0.65, tp: 62632, fp: 21666, fn: 42254,precision: 0.742983226173812, recall: 0.5971435653948096, f1: 0.6621278755074426\n",
      "2025-05-03 15:20:30,520 - clrnet.utils.culane_metric - INFO - iou thr: 0.70, tp: 58252, fp: 26046, fn: 46634,precision: 0.691024698094854, recall: 0.5553839406593826, f1: 0.615823748308525\n",
      "2025-05-03 15:20:30,548 - clrnet.utils.culane_metric - INFO - iou thr: 0.75, tp: 51986, fp: 32312, fn: 52900,precision: 0.6166931599800707, recall: 0.4956428884693858, f1: 0.5495813599458729\n",
      "2025-05-03 15:20:30,577 - clrnet.utils.culane_metric - INFO - iou thr: 0.80, tp: 42849, fp: 41449, fn: 62037,precision: 0.5083038743505184, recall: 0.4085292603397975, f1: 0.45298756765899867\n",
      "2025-05-03 15:20:30,606 - clrnet.utils.culane_metric - INFO - iou thr: 0.85, tp: 29663, fp: 54635, fn: 75223,precision: 0.35188260694203893, recall: 0.2828118147321854, f1: 0.3135888870094723\n",
      "2025-05-03 15:20:30,635 - clrnet.utils.culane_metric - INFO - iou thr: 0.90, tp: 13188, fp: 71110, fn: 91698,precision: 0.15644499276376664, recall: 0.12573651392940907, f1: 0.1394198240866035\n",
      "2025-05-03 15:20:30,664 - clrnet.utils.culane_metric - INFO - iou thr: 0.95, tp: 1119, fp: 83179, fn: 103767,precision: 0.01327433628318584, recall: 0.010668726045420742, f1: 0.01182975304465494\n",
      "2025-05-03 15:20:30,665 - clrnet.utils.culane_metric - INFO - mean result, total_tp: 463640, total_fp: 379340, total_fn: 585220,precision: 0.5500011862677644, recall: 0.44204183589802265, f1: 0.49014715832205674\n",
      "2025-05-03 15:20:31,069 - clrnet.utils.recorder - INFO - metric: 0.7409400372124493\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7409400372124493"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cross_stitch.eval()\n",
    "validate_lane(model_cross_stitch, recorder, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-01 12:25:18,866 - clrnet.datasets.base_dataset - INFO - Loading CULane annotations...\n",
      "Validate: 100%|██████████| 1445/1445 [02:28<00:00,  9.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating prediction output...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-01 12:27:56,313 - clrnet.utils.culane_metric - INFO - Calculating metric for List: ./data/CULane/list/test_split/test0_normal.txt\n",
      "2025-05-01 12:28:56,525 - clrnet.utils.culane_metric - INFO - iou thr: 0.50, tp: 28977, fp: 1771, fn: 3800,precision: 0.942402757902953, recall: 0.8840650456112518, f1: 0.9123022432113341\n",
      "2025-05-01 12:28:56,637 - clrnet.utils.culane_metric - INFO - Calculating metric for List: ./data/CULane/list/test_split/test1_crowd.txt\n",
      "2025-05-01 12:29:46,755 - clrnet.utils.culane_metric - INFO - iou thr: 0.50, tp: 17293, fp: 2207, fn: 10710,precision: 0.8868205128205128, recall: 0.6175409777523837, f1: 0.7280803317685199\n",
      "2025-05-01 12:29:46,843 - clrnet.utils.culane_metric - INFO - Calculating metric for List: ./data/CULane/list/test_split/test2_hlight.txt\n",
      "2025-05-01 12:30:18,317 - clrnet.utils.culane_metric - INFO - iou thr: 0.50, tp: 894, fp: 211, fn: 791,precision: 0.8090497737556561, recall: 0.5305637982195845, f1: 0.6408602150537633\n",
      "2025-05-01 12:30:18,325 - clrnet.utils.culane_metric - INFO - Calculating metric for List: ./data/CULane/list/test_split/test3_shadow.txt\n",
      "2025-05-01 12:30:50,453 - clrnet.utils.culane_metric - INFO - iou thr: 0.50, tp: 1684, fp: 189, fn: 1192,precision: 0.8990923651895355, recall: 0.5855354659248957, f1: 0.7092019372499474\n",
      "2025-05-01 12:30:50,466 - clrnet.utils.culane_metric - INFO - Calculating metric for List: ./data/CULane/list/test_split/test4_noline.txt\n",
      "2025-05-01 12:31:27,006 - clrnet.utils.culane_metric - INFO - iou thr: 0.50, tp: 4326, fp: 1012, fn: 9695,precision: 0.8104158860996628, recall: 0.30853719420868697, f1: 0.44692391135905785\n",
      "2025-05-01 12:31:27,046 - clrnet.utils.culane_metric - INFO - Calculating metric for List: ./data/CULane/list/test_split/test5_arrow.txt\n",
      "2025-05-01 12:31:59,895 - clrnet.utils.culane_metric - INFO - iou thr: 0.50, tp: 2537, fp: 236, fn: 645,precision: 0.9148936170212766, recall: 0.7972972972972973, f1: 0.8520570948782535\n",
      "2025-05-01 12:31:59,908 - clrnet.utils.culane_metric - INFO - Calculating metric for List: ./data/CULane/list/test_split/test6_curve.txt\n",
      "2025-05-01 12:32:31,105 - clrnet.utils.culane_metric - INFO - iou thr: 0.50, tp: 658, fp: 98, fn: 654,precision: 0.8703703703703703, recall: 0.5015243902439024, f1: 0.6363636363636364\n",
      "2025-05-01 12:32:31,114 - clrnet.utils.culane_metric - INFO - Calculating metric for List: ./data/CULane/list/test_split/test7_cross.txt\n",
      "2025-05-01 12:33:03,272 - clrnet.utils.culane_metric - INFO - iou thr: 0.50, tp: 0, fp: 673, fn: 0,precision: 0, recall: 0, f1: 0\n",
      "2025-05-01 12:33:03,277 - clrnet.utils.culane_metric - INFO - Calculating metric for List: ./data/CULane/list/test_split/test8_night.txt\n",
      "2025-05-01 12:33:47,428 - clrnet.utils.culane_metric - INFO - iou thr: 0.50, tp: 11344, fp: 1407, fn: 9686,precision: 0.88965571327739, recall: 0.5394198763670947, f1: 0.6716201414996595\n",
      "2025-05-01 12:33:47,490 - clrnet.utils.culane_metric - INFO - Calculating metric for List: ./data/CULane/list/test.txt\n",
      "2025-05-01 12:35:33,118 - clrnet.utils.culane_metric - INFO - iou thr: 0.50, tp: 67713, fp: 7804, fn: 37173,precision: 0.8966590304169922, recall: 0.6455866369200847, f1: 0.7506859642023691\n",
      "2025-05-01 12:35:33,145 - clrnet.utils.culane_metric - INFO - iou thr: 0.55, tp: 66251, fp: 9266, fn: 38635,precision: 0.8772991511845015, recall: 0.6316476936864787, f1: 0.7344778080187137\n",
      "2025-05-01 12:35:33,172 - clrnet.utils.culane_metric - INFO - iou thr: 0.60, tp: 64238, fp: 11279, fn: 40648,precision: 0.8506429015983156, recall: 0.6124554277977995, f1: 0.7121611059683043\n",
      "2025-05-01 12:35:33,199 - clrnet.utils.culane_metric - INFO - iou thr: 0.65, tp: 61373, fp: 14144, fn: 43513,precision: 0.8127044241693924, recall: 0.5851400568235989, f1: 0.680398884719212\n",
      "2025-05-01 12:35:33,225 - clrnet.utils.culane_metric - INFO - iou thr: 0.70, tp: 57361, fp: 18156, fn: 47525,precision: 0.7595773137174411, recall: 0.5468890032988196, f1: 0.6359206886803433\n",
      "2025-05-01 12:35:33,251 - clrnet.utils.culane_metric - INFO - iou thr: 0.75, tp: 51260, fp: 24257, fn: 53626,precision: 0.6787875577684495, recall: 0.4887210876570753, f1: 0.5682832325404787\n",
      "2025-05-01 12:35:33,277 - clrnet.utils.culane_metric - INFO - iou thr: 0.80, tp: 42089, fp: 33428, fn: 62797,precision: 0.5573447038415191, recall: 0.401283298056938, f1: 0.4666108656729655\n",
      "2025-05-01 12:35:33,303 - clrnet.utils.culane_metric - INFO - iou thr: 0.85, tp: 28419, fp: 47098, fn: 76467,precision: 0.37632586040229354, recall: 0.27095131857445226, f1: 0.315061279468745\n",
      "2025-05-01 12:35:33,330 - clrnet.utils.culane_metric - INFO - iou thr: 0.90, tp: 11483, fp: 64034, fn: 93403,precision: 0.15205847689924124, recall: 0.10948076959746773, f1: 0.12730386966957313\n",
      "2025-05-01 12:35:33,356 - clrnet.utils.culane_metric - INFO - iou thr: 0.95, tp: 572, fp: 74945, fn: 104314,precision: 0.007574453434326046, recall: 0.005453540033941613, f1: 0.006341357959679162\n",
      "2025-05-01 12:35:33,357 - clrnet.utils.culane_metric - INFO - mean result, total_tp: 450759, total_fp: 304411, total_fn: 598101,precision: 0.5968973873432472, recall: 0.4297608832446656, f1: 0.4997245056900385\n",
      "2025-05-01 12:35:33,685 - clrnet.utils.recorder - INFO - metric: 0.7506859642023691\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7506859642023691"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_control.eval()\n",
    "validate_lane(model_control, recorder, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-01 12:38:56,826 - clrnet.datasets.base_dataset - INFO - Loading CULane annotations...\n",
      "Validate: 100%|██████████| 1445/1445 [02:41<00:00,  8.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating prediction output...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-01 12:41:47,110 - clrnet.utils.culane_metric - INFO - Calculating metric for List: ./data/CULane/list/test_split/test0_normal.txt\n",
      "2025-05-01 12:42:47,622 - clrnet.utils.culane_metric - INFO - iou thr: 0.50, tp: 29739, fp: 2439, fn: 3038,precision: 0.9242028715271303, recall: 0.9073130548860482, f1: 0.9156800862135325\n",
      "2025-05-01 12:42:47,738 - clrnet.utils.culane_metric - INFO - Calculating metric for List: ./data/CULane/list/test_split/test1_crowd.txt\n",
      "2025-05-01 12:43:41,651 - clrnet.utils.culane_metric - INFO - iou thr: 0.50, tp: 19346, fp: 5564, fn: 8657,precision: 0.776635889201124, recall: 0.6908545512980752, f1: 0.7312380700394988\n",
      "2025-05-01 12:43:41,743 - clrnet.utils.culane_metric - INFO - Calculating metric for List: ./data/CULane/list/test_split/test2_hlight.txt\n",
      "2025-05-01 12:44:12,062 - clrnet.utils.culane_metric - INFO - iou thr: 0.50, tp: 1055, fp: 316, fn: 630,precision: 0.7695113056163384, recall: 0.6261127596439169, f1: 0.6904450261780105\n",
      "2025-05-01 12:44:12,070 - clrnet.utils.culane_metric - INFO - Calculating metric for List: ./data/CULane/list/test_split/test3_shadow.txt\n",
      "2025-05-01 12:44:43,693 - clrnet.utils.culane_metric - INFO - iou thr: 0.50, tp: 2096, fp: 553, fn: 780,precision: 0.7912419781049452, recall: 0.7287899860917941, f1: 0.7587330316742081\n",
      "2025-05-01 12:44:43,705 - clrnet.utils.culane_metric - INFO - Calculating metric for List: ./data/CULane/list/test_split/test4_noline.txt\n",
      "2025-05-01 12:45:21,742 - clrnet.utils.culane_metric - INFO - iou thr: 0.50, tp: 5643, fp: 3050, fn: 8378,precision: 0.6491429886115265, recall: 0.4024677269809571, f1: 0.4968741745179185\n",
      "2025-05-01 12:45:21,786 - clrnet.utils.culane_metric - INFO - Calculating metric for List: ./data/CULane/list/test_split/test5_arrow.txt\n",
      "2025-05-01 12:45:53,694 - clrnet.utils.culane_metric - INFO - iou thr: 0.50, tp: 2694, fp: 309, fn: 488,precision: 0.8971028971028971, recall: 0.8466373350094281, f1: 0.8711398544866613\n",
      "2025-05-01 12:45:53,708 - clrnet.utils.culane_metric - INFO - Calculating metric for List: ./data/CULane/list/test_split/test6_curve.txt\n",
      "2025-05-01 12:46:23,693 - clrnet.utils.culane_metric - INFO - iou thr: 0.50, tp: 767, fp: 223, fn: 545,precision: 0.7747474747474747, recall: 0.5846036585365854, f1: 0.6663770634231104\n",
      "2025-05-01 12:46:23,702 - clrnet.utils.culane_metric - INFO - Calculating metric for List: ./data/CULane/list/test_split/test7_cross.txt\n",
      "2025-05-01 12:46:53,168 - clrnet.utils.culane_metric - INFO - iou thr: 0.50, tp: 0, fp: 1665, fn: 0,precision: 0, recall: 0, f1: 0\n",
      "2025-05-01 12:46:53,174 - clrnet.utils.culane_metric - INFO - Calculating metric for List: ./data/CULane/list/test_split/test8_night.txt\n",
      "2025-05-01 12:47:39,331 - clrnet.utils.culane_metric - INFO - iou thr: 0.50, tp: 13284, fp: 3311, fn: 7746,precision: 0.8004820729135281, recall: 0.6316690442225392, f1: 0.7061262458471761\n",
      "2025-05-01 12:47:39,399 - clrnet.utils.culane_metric - INFO - Calculating metric for List: ./data/CULane/list/test.txt\n"
     ]
    }
   ],
   "source": [
    "model_cross_stitch.eval()\n",
    "validate_lane(model_cross_stitch, recorder, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-01 20:02:46,553 - clrnet.datasets.base_dataset - INFO - Loading CULane annotations...\n",
      "Validate: 100%|██████████| 1445/1445 [02:42<00:00,  8.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating prediction output...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-01 20:05:38,885 - clrnet.utils.culane_metric - INFO - Calculating metric for List: ./data/CULane/list/test_split/test0_normal.txt\n",
      "2025-05-01 20:06:28,943 - clrnet.utils.culane_metric - INFO - iou thr: 0.50, tp: 29283, fp: 2511, fn: 3494,precision: 0.9210228344970749, recall: 0.8934008603593984, f1: 0.9070015951433305\n",
      "2025-05-01 20:06:29,073 - clrnet.utils.culane_metric - INFO - Calculating metric for List: ./data/CULane/list/test_split/test1_crowd.txt\n",
      "2025-05-01 20:07:12,859 - clrnet.utils.culane_metric - INFO - iou thr: 0.50, tp: 18857, fp: 4463, fn: 9146,precision: 0.8086192109777015, recall: 0.6733921365567975, f1: 0.7348362332677357\n",
      "2025-05-01 20:07:12,959 - clrnet.utils.culane_metric - INFO - Calculating metric for List: ./data/CULane/list/test_split/test2_hlight.txt\n",
      "2025-05-01 20:07:33,494 - clrnet.utils.culane_metric - INFO - iou thr: 0.50, tp: 998, fp: 285, fn: 687,precision: 0.7778643803585347, recall: 0.5922848664688427, f1: 0.6725067385444744\n",
      "2025-05-01 20:07:33,503 - clrnet.utils.culane_metric - INFO - Calculating metric for List: ./data/CULane/list/test_split/test3_shadow.txt\n",
      "2025-05-01 20:07:55,024 - clrnet.utils.culane_metric - INFO - iou thr: 0.50, tp: 2071, fp: 389, fn: 805,precision: 0.841869918699187, recall: 0.7200973574408901, f1: 0.7762368815592204\n",
      "2025-05-01 20:07:55,037 - clrnet.utils.culane_metric - INFO - Calculating metric for List: ./data/CULane/list/test_split/test4_noline.txt\n",
      "2025-05-01 20:08:22,906 - clrnet.utils.culane_metric - INFO - iou thr: 0.50, tp: 5329, fp: 2598, fn: 8692,precision: 0.6722593667213321, recall: 0.3800727480208259, f1: 0.48560233278658643\n",
      "2025-05-01 20:08:22,951 - clrnet.utils.culane_metric - INFO - Calculating metric for List: ./data/CULane/list/test_split/test5_arrow.txt\n",
      "2025-05-01 20:08:45,224 - clrnet.utils.culane_metric - INFO - iou thr: 0.50, tp: 2595, fp: 328, fn: 587,precision: 0.8877865206979131, recall: 0.8155248271527341, f1: 0.85012285012285\n",
      "2025-05-01 20:08:45,239 - clrnet.utils.culane_metric - INFO - Calculating metric for List: ./data/CULane/list/test_split/test6_curve.txt\n",
      "2025-05-01 20:09:05,296 - clrnet.utils.culane_metric - INFO - iou thr: 0.50, tp: 789, fp: 169, fn: 523,precision: 0.8235908141962421, recall: 0.6013719512195121, f1: 0.6951541850220264\n",
      "2025-05-01 20:09:05,305 - clrnet.utils.culane_metric - INFO - Calculating metric for List: ./data/CULane/list/test_split/test7_cross.txt\n",
      "2025-05-01 20:09:24,715 - clrnet.utils.culane_metric - INFO - iou thr: 0.50, tp: 0, fp: 1361, fn: 0,precision: 0, recall: 0, f1: 0\n",
      "2025-05-01 20:09:24,723 - clrnet.utils.culane_metric - INFO - Calculating metric for List: ./data/CULane/list/test_split/test8_night.txt\n",
      "2025-05-01 20:09:59,570 - clrnet.utils.culane_metric - INFO - iou thr: 0.50, tp: 12479, fp: 2725, fn: 8551,precision: 0.8207708497763746, recall: 0.5933903946742748, f1: 0.6888005740464755\n",
      "2025-05-01 20:09:59,648 - clrnet.utils.culane_metric - INFO - Calculating metric for List: ./data/CULane/list/test.txt\n",
      "2025-05-01 20:11:47,578 - clrnet.utils.culane_metric - INFO - iou thr: 0.50, tp: 72401, fp: 14829, fn: 32485,precision: 0.830001146394589, recall: 0.6902827832122495, f1: 0.7537217098003289\n",
      "2025-05-01 20:11:47,608 - clrnet.utils.culane_metric - INFO - iou thr: 0.55, tp: 70309, fp: 16921, fn: 34577,precision: 0.8060185715923421, recall: 0.6703373186125889, f1: 0.7319432009827397\n",
      "2025-05-01 20:11:47,637 - clrnet.utils.culane_metric - INFO - iou thr: 0.60, tp: 67635, fp: 19595, fn: 37251,precision: 0.775363980282013, recall: 0.6448429723700018, f1: 0.7041058527139853\n",
      "2025-05-01 20:11:47,666 - clrnet.utils.culane_metric - INFO - iou thr: 0.65, tp: 64091, fp: 23139, fn: 40795,precision: 0.7347357560472314, recall: 0.6110539061457201, f1: 0.6672114763996752\n",
      "2025-05-01 20:11:47,694 - clrnet.utils.culane_metric - INFO - iou thr: 0.70, tp: 59489, fp: 27741, fn: 45397,precision: 0.6819786770606443, recall: 0.5671776976908263, f1: 0.6193029211518042\n",
      "2025-05-01 20:11:47,723 - clrnet.utils.culane_metric - INFO - iou thr: 0.75, tp: 52758, fp: 34472, fn: 52128,precision: 0.6048148572738736, recall: 0.5030032606830273, f1: 0.5492306731349809\n",
      "2025-05-01 20:11:47,750 - clrnet.utils.culane_metric - INFO - iou thr: 0.80, tp: 43337, fp: 43893, fn: 61549,precision: 0.4968130230425312, recall: 0.41318193085826516, f1: 0.4511545108163818\n",
      "2025-05-01 20:11:47,779 - clrnet.utils.culane_metric - INFO - iou thr: 0.85, tp: 29559, fp: 57671, fn: 75327,precision: 0.3388627765676946, recall: 0.2818202619987415, f1: 0.3077203356305565\n",
      "2025-05-01 20:11:47,807 - clrnet.utils.culane_metric - INFO - iou thr: 0.90, tp: 13105, fp: 74125, fn: 91781,precision: 0.1502350108907486, recall: 0.12494517857483363, f1: 0.1364279914218493\n",
      "2025-05-01 20:11:47,835 - clrnet.utils.culane_metric - INFO - iou thr: 0.95, tp: 1184, fp: 86046, fn: 103702,precision: 0.013573311933967672, recall: 0.011288446503823199, f1: 0.012325886443606989\n",
      "2025-05-01 20:11:47,835 - clrnet.utils.culane_metric - INFO - mean result, total_tp: 473868, total_fp: 398432, total_fn: 574992,precision: 0.5432397111085636, recall: 0.45179337566500766, f1: 0.4933144558495908\n",
      "2025-05-01 20:11:48,240 - clrnet.utils.recorder - INFO - metric: 0.7537217098003289\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7537217098003289"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cross_stitch.eval()\n",
    "validate_lane(model_cross_stitch, recorder, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4427957"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in model_cross_stitch.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3663537"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in model_control.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vehicle_pcgrad \n",
    "model.eval()\n",
    "validate_lane(model, recorder, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vehicle only\n",
    "model.eval()\n",
    "validate_lane(model, recorder, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "# conf_threshold=0.1, iou_threshold=0.65\n",
    "test_obj(args, params, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conf_threshold=0.25, iou_threshold=0.65\n",
    "test_obj(args, params, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conf_threshold=0.001, iou_threshold=0.65\n",
    "test_obj(args, params, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conf_threshold=0.25, iou_threshold=0.45\n",
    "test_obj(args, params, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conf_threshold=0.25, iou_threshold=0.5\n",
    "test_obj(args, params, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conf_threshold=0.3, iou_threshold=0.5\n",
    "test_obj(args, params, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vehicle only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conf_threshold=0.3, iou_threshold=0.5\n",
    "test_obj(args, params, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conf_threshold=0.3, iou_threshold=0.45\n",
    "test_obj(args, params, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conf_threshold=0.25, iou_threshold=0.45\n",
    "test_obj(args, params, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = 'cpu'\n",
    "# net.backbone = net.backbone.to(device)\n",
    "# net.neck = net.neck.to(device)\n",
    "# net.clrhead= net.clrhead.to(device)\n",
    "# net.yolo_head = net.yolo_head.to(device)\n",
    "# net.offset_0 = net.offset_0.to(device)\n",
    "# net.offset_1 = net.offset_1.to(device)\n",
    "# net.offset_2 = net.offset_2.to(device)\n",
    "\n",
    "# devices = {param.device for param in net.clrhead.parameters()}\n",
    "# print(devices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.eval()\n",
    "validate_lane(net, recorder, 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accumulate = max(round(64 / (args.batch_size * args.world_size)), 1)\n",
    "net = YOLOL(darknet_backbone, darknet_neck, darknet_head, clrnet_head)\n",
    "net = net.to(device)\n",
    "\n",
    "optimizer = build_optimizer(cfg, net)\n",
    "scheduler = build_scheduler(cfg, optimizer)\n",
    "criterion_obj = util.ComputeLoss(net, params)\n",
    "\n",
    "net.eval()\n",
    "\n",
    "# test_obj(args, params, net)\n",
    "validate_lane()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# net = MMDataParallel(net,\n",
    "#                                 #   device_ids=[2]).cuda(torch.device('cuda:2'))\n",
    "#                                   device_ids=range(cfg.gpus)).cuda()\n",
    "\n",
    "\n",
    "accumulate = max(round(64 / (args.batch_size * args.world_size)), 1)\n",
    "net = YOLOL(darknet_backbone, darknet_neck, darknet_head, clrnet_head)\n",
    "net = net.to(device)\n",
    "\n",
    "optimizer = build_optimizer(cfg, net)\n",
    "scheduler = build_scheduler(cfg, optimizer)\n",
    "criterion_obj = util.ComputeLoss(net, params)\n",
    "\n",
    "\n",
    "end = time.time()\n",
    "max_iter = len(train_loader_lane)\n",
    "\n",
    "f = open(\"all_loss.txt\", \"a\")\n",
    "print(\"total_loss, loss_cls_obj, loss_box_obj, loss_dfl_obj, loss_cls_lane, loss_reg_xytl_lane, loss_seg_lane, loss_iou_lane\")\n",
    "f.write(\"total_loss, loss_cls_obj, loss_box_obj, loss_dfl_obj, loss_cls_lane, loss_reg_xytl_lane, loss_seg_lane, loss_iou_lane\")\n",
    "\n",
    "for epoch in range(args.epoch):\n",
    "    if epoch == 1:\n",
    "        break\n",
    "    \n",
    "    \n",
    "    net.train()\n",
    "    zipped_dls = zip(train_loader_obj, train_loader_lane)\n",
    "    \n",
    "    loss_scaler = 0.2\n",
    "\n",
    "    p_bar = enumerate(zipped_dls)\n",
    "    p_bar = tqdm(p_bar, total=len(train_loader_lane))\n",
    "    \n",
    "\n",
    "    # for i, data in enumerate(train_loader_lane):\n",
    "    for i, (data_obj, data_lane) in p_bar:\n",
    "        x = i + max_iter #* epoch\n",
    "        date_time = time.time() - end\n",
    "        samples = data_obj[0].to(device).float() / 255\n",
    "        targets = data_obj[1].to(device)\n",
    "        # data_obj = to_cuda(data_obj)\n",
    "        data_lane = to_cuda(data_lane, device)\n",
    "        \n",
    "        \n",
    "        \n",
    "        # experiment = net2(data_lane)\n",
    "        output_lane = net(data_lane, 0)\n",
    "        output_obj = net(samples, 1)\n",
    "        \n",
    "        amp_scale = torch.cuda.amp.GradScaler()\n",
    "        # optimizer.zero_grad()\n",
    "        # print(f\"{output_lane['loss']}\")\n",
    "        loss_lane = output_lane['loss'].sum()\n",
    "        loss_cls_obj, loss_box_obj, loss_dfl_obj = criterion_obj(output_obj, targets)\n",
    "        \n",
    "        \n",
    "        \n",
    "        total_loss = loss_scaler*loss_lane + loss_cls_obj + loss_box_obj + loss_dfl_obj\n",
    "        # print(f\"{output_lane['loss_stats']}\")\n",
    "        # f.write(f\"{output_lane['loss'].item():.6f}, {loss_obj.item():.6f}, {total_loss.item():.6f}\\n\")\n",
    "        f.write(f\"{total_loss.item():.6f}, {loss_cls_obj.item():.6f}, {loss_box_obj.item():.6f}, {loss_dfl_obj.item():.6f}, {output_lane['loss_stats']['cls_loss'].item():.6f}, {output_lane['loss_stats']['reg_xytl_loss'].item():.6f}, {output_lane['loss_stats']['seg_loss'].item():.6f}, {output_lane['loss_stats']['iou_loss'].item():.6f}\\n\")\n",
    "\n",
    "        # p_bar.set_description(str(str(total_loss), str(loss_cls_obj), str(loss_box_obj), str(loss_dfl_obj), str(output_lane['loss_stats']['cls_loss']), str(output_lane['loss_stats']['reg_xytl_loss']), str(output_lane['loss_stats']['seg_loss']), str(output_lane['loss_stats']['iou_loss'])))\n",
    "        p_bar.set_description(f\"{total_loss.item():.6f}, {loss_cls_obj.item():.6f}, {loss_box_obj.item():.6f}, {loss_dfl_obj.item():.6f}, {output_lane['loss_stats']['cls_loss'].item():.6f}, {output_lane['loss_stats']['reg_xytl_loss'].item():.6f}, {output_lane['loss_stats']['seg_loss'].item():.6f}, {output_lane['loss_stats']['iou_loss'].item():.6f}\")\n",
    "        amp_scale.scale(total_loss).backward()\n",
    "        # if i%2:\n",
    "        #     amp_scale.scale(loss_lane).backward()\n",
    "        # else:\n",
    "        #     amp_scale.scale(loss_obj).backward()\n",
    "        \n",
    "        if x % accumulate == 0:\n",
    "            amp_scale.unscale_(optimizer)  # unscale gradients\n",
    "            util.clip_gradients(net)  # clip gradients\n",
    "            amp_scale.step(optimizer)  # optimizer.step\n",
    "            amp_scale.update()\n",
    "            optimizer.zero_grad()\n",
    "        # optimizer.step()\n",
    "        # del loss_lane, loss_obj, total_loss, output_lane, output_obj, samples, targets\n",
    "\n",
    "        \n",
    "    \n",
    "    print(f\"Epoch {epoch} finished\")\n",
    "    net.eval()\n",
    "    test_obj(args, params, net)\n",
    "    # validate_lane(net, recorder)\n",
    "    \n",
    "    \n",
    "\n",
    "f.close()\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = \"loss_log.txt\"  # Update this with the correct file path\n",
    "df = pd.read_csv(file_path, sep=',', header=None)\n",
    "\n",
    "df.columns = [\"Loss Lane\", \"Loss Obj\", \"Loss Total\"]\n",
    "\n",
    "# Moving Average Smoothing\n",
    "def smooth(y, box_pts=50):\n",
    "    box = np.ones(box_pts) / box_pts\n",
    "    return np.convolve(y, box, mode='same')\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.style.use('seaborn-darkgrid')\n",
    "\n",
    "for column in df.columns:\n",
    "    plt.plot(df.index, smooth(df[column], box_pts=100), label=column, linewidth=2)\n",
    "\n",
    "# Titles and Labels\n",
    "plt.xlabel(\"Batch\", fontsize=14)\n",
    "plt.ylabel(\"Loss\", fontsize=14)\n",
    "plt.title(\"Smoothed Loss Over Batches\", fontsize=16, fontweight='bold')\n",
    "plt.legend(fontsize=12)\n",
    "\n",
    "# Enhanced Grid\n",
    "plt.grid(True, linestyle=\"-\", linewidth=1, color=\"gray\", alpha=0.7)\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = \"loss_log_randomized_weights.txt\"  # Update this with the correct file path\n",
    "df = pd.read_csv(file_path, sep=',', header=None)\n",
    "\n",
    "df.columns = [\"Loss Lane\", \"Loss Obj\", \"Loss Total\"]\n",
    "\n",
    "# Moving Average Smoothing\n",
    "def smooth(y, box_pts=50):\n",
    "    box = np.ones(box_pts) / box_pts\n",
    "    return np.convolve(y, box, mode='same')\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.style.use('seaborn-darkgrid')\n",
    "\n",
    "for column in df.columns:\n",
    "    plt.plot(df.index, smooth(df[column], box_pts=100), label=column, linewidth=2)\n",
    "\n",
    "# Titles and Labels\n",
    "plt.xlabel(\"Batch\", fontsize=14)\n",
    "plt.ylabel(\"Loss\", fontsize=14)\n",
    "plt.title(\"Smoothed Loss Over Batches\", fontsize=16, fontweight='bold')\n",
    "plt.legend(fontsize=12)\n",
    "\n",
    "# Enhanced Grid\n",
    "plt.grid(True, linestyle=\"-\", linewidth=1, color=\"gray\", alpha=0.7)\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = \"loss_log_randomized_weights_reverse_gradient.txt\"  # Update this with the correct file path\n",
    "df = pd.read_csv(file_path, sep=',', header=None)\n",
    "\n",
    "df.columns = [\"Loss Lane\", \"Loss Obj\", \"Loss Total\"]\n",
    "\n",
    "# Moving Average Smoothing\n",
    "def smooth(y, box_pts=50):\n",
    "    box = np.ones(box_pts) / box_pts\n",
    "    return np.convolve(y, box, mode='same')\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.style.use('seaborn-darkgrid')\n",
    "\n",
    "for column in df.columns:\n",
    "    plt.plot(df.index, smooth(df[column], box_pts=100), label=column, linewidth=2)\n",
    "\n",
    "# Titles and Labels\n",
    "plt.xlabel(\"Batch\", fontsize=14)\n",
    "plt.ylabel(\"Loss\", fontsize=14)\n",
    "plt.title(\"Smoothed Loss Over Batches\", fontsize=16, fontweight='bold')\n",
    "plt.legend(fontsize=12)\n",
    "\n",
    "# Enhanced Grid\n",
    "plt.grid(True, linestyle=\"-\", linewidth=1, color=\"gray\", alpha=0.7)\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.epoch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.eval()\n",
    "validate_lane(net, recorder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.lib.backgroundjobs import BackgroundJobManager\n",
    "import time\n",
    "\n",
    "jobs = BackgroundJobManager()\n",
    "\n",
    "import time\n",
    "import cv2\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import pytorch_warmup as warmup\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "\n",
    "from clrnet.models.registry import build_net\n",
    "from clrnet.engine.registry import build_trainer, build_evaluator\n",
    "from clrnet.engine.optimizer import build_optimizer\n",
    "from clrnet.engine.scheduler import build_scheduler\n",
    "from clrnet.datasets import build_dataloader\n",
    "from clrnet.utils.recorder import build_recorder\n",
    "from clrnet.utils.net_utils import save_model, load_network, resume_network\n",
    "from clrnet.utils.recorder import build_recorder\n",
    "from mmcv.parallel import MMDataParallel\n",
    "from nets.nn import DarkNet\n",
    "from utils import util\n",
    "\n",
    "import argparse\n",
    "\n",
    "import yaml\n",
    "import os\n",
    "import glob\n",
    "from torch.utils import data\n",
    "\n",
    "\n",
    "# yolo\n",
    "\n",
    "from utils.dataset import Dataset\n",
    "from clrnet.utils.config import Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"/home/mmm9886/Desktop/Datasets/bdd100k/images/train/\"\n",
    "filenames = glob.glob(os.path.join(folder_path, '*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script bash\n",
    "nohup python -u -c '\n",
    "\n",
    "import time\n",
    "import cv2\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import pytorch_warmup as warmup\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "\n",
    "from clrnet.models.registry import build_net\n",
    "from clrnet.engine.registry import build_trainer, build_evaluator\n",
    "from clrnet.engine.optimizer import build_optimizer\n",
    "from clrnet.engine.scheduler import build_scheduler\n",
    "from clrnet.datasets import build_dataloader\n",
    "from clrnet.utils.recorder import build_recorder\n",
    "from clrnet.utils.net_utils import save_model, load_network, resume_network\n",
    "from clrnet.utils.recorder import build_recorder\n",
    "from mmcv.parallel import MMDataParallel\n",
    "from nets.nn import DarkNet\n",
    "from utils import util\n",
    "\n",
    "import argparse\n",
    "\n",
    "import yaml\n",
    "import os\n",
    "import glob\n",
    "from torch.utils import data\n",
    "\n",
    "\n",
    "# yolo\n",
    "\n",
    "from utils.dataset import Dataset\n",
    "from clrnet.utils.config import Config\n",
    "\n",
    "\n",
    "device = \"cuda:0\"\n",
    "\n",
    "cfg = Config.fromfile(\"configs/clrnet/clr_resnet18_culane.py\")\n",
    "\n",
    "cfg.load_from = None\n",
    "cfg.resume_from = None\n",
    "cfg.finetune_from = None\n",
    "cfg.view = None\n",
    "cfg.seed = 0\n",
    "cfg.gpus = 1\n",
    "\n",
    "torch.manual_seed(cfg.seed)\n",
    "np.random.seed(cfg.seed)\n",
    "random.seed(cfg.seed)\n",
    "\n",
    "train_loader_lane = build_dataloader(cfg.dataset.train,\n",
    "                                    cfg,\n",
    "                                    is_train=True)\n",
    "\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "args = parser.parse_args(args=[])\n",
    "args.input_size = 640\n",
    "args.batch_size = 32\n",
    "args.local_rank = 0\n",
    "args.world_size = 1\n",
    "args.epoch = 100\n",
    "\n",
    "\n",
    "with open(os.path.join('utils', 'args.yaml'), errors='ignore') as f:\n",
    "    params = yaml.safe_load(f)\n",
    "\n",
    "folder_path = \"/home/mmm9886/Desktop/Datasets/bdd100k/images/train/\"\n",
    "filenames = glob.glob(os.path.join(folder_path, '*'))\n",
    "\n",
    "train_dataset_obj = Dataset(filenames, args.input_size, params, True)\n",
    "\n",
    "train_loader_obj = data.DataLoader(train_dataset_obj, 18, False, num_workers=8,\n",
    "                            pin_memory=True, collate_fn=Dataset.collate_fn)\n",
    "\n",
    "\n",
    "\n",
    "state_dict = torch.load(\"/home/mmm9886/Desktop/Capstone_Implementation/YOLOv8-pt copy 3/weights/best.pt\")\n",
    "darknet_backbone = state_dict['model'].net\n",
    "darknet_backbone = darknet_backbone.float()\n",
    "darknet_backbone = darknet_backbone.to(device)\n",
    "darknet_neck = state_dict['model'].fpn\n",
    "darknet_neck = darknet_neck.float()\n",
    "darknet_neck = darknet_neck.to(device)\n",
    "darknet_head = state_dict['model'].head\n",
    "darknet_head = darknet_head.float()\n",
    "darknet_head = darknet_head.to(device)\n",
    "\n",
    "net = build_net(cfg)\n",
    "\n",
    "clrnet_head = net.heads\n",
    "\n",
    "net = YOLOL(darknet_backbone, darknet_neck, darknet_head, clrnet_head)\n",
    "\n",
    "accumulate = max(round(64 / (args.batch_size * args.world_size)), 1)\n",
    "net = YOLOL(darknet_backbone, darknet_neck, darknet_head, clrnet_head)\n",
    "net = net.to(device)\n",
    "\n",
    "optimizer = build_optimizer(cfg, net)\n",
    "scheduler = build_scheduler(cfg, optimizer)\n",
    "criterion_obj = util.ComputeLoss(net, params)\n",
    "\n",
    "net.train()\n",
    "end = time.time()\n",
    "max_iter = len(train_loader_lane)\n",
    "\n",
    "\n",
    "\n",
    "zipped_dls = zip(train_loader_obj, train_loader_lane)\n",
    "\n",
    "p_bar = enumerate(zipped_dls)\n",
    "p_bar = tqdm(p_bar, total=len(train_loader_lane))\n",
    "\n",
    "# for i, data in enumerate(train_loader_lane):\n",
    "for i, (data_obj, data_lane) in p_bar:\n",
    "    x = i + max_iter #* epoch\n",
    "    date_time = time.time() - end\n",
    "    samples = data_obj[0].to(device).float() / 255\n",
    "    targets = data_obj[1].to(device)\n",
    "    # data_obj = to_cuda(data_obj)\n",
    "    data_lane = to_cuda(data_lane, device)\n",
    "    output_obj = net(samples, 1)\n",
    "    \n",
    "    \n",
    "    # experiment = net2(data_lane)\n",
    "    output_lane = net(data_lane, 0)\n",
    "    \n",
    "    amp_scale = torch.cuda.amp.GradScaler()\n",
    "    # optimizer.zero_grad()\n",
    "    loss_lane = output_lane['loss'].sum()\n",
    "    loss_obj = criterion_obj(output_obj, targets)\n",
    "    total_loss = loss_lane+loss_obj\n",
    "    p_bar.set_description(str(total_loss))\n",
    "    amp_scale.scale(total_loss).backward()\n",
    "    \n",
    "    if x % accumulate == 0:\n",
    "        amp_scale.unscale_(optimizer)  # unscale gradients\n",
    "        util.clip_gradients(net)  # clip gradients\n",
    "        amp_scale.step(optimizer)  # optimizer.step\n",
    "        amp_scale.update()\n",
    "        optimizer.zero_grad()\n",
    "    # optimizer.step()\n",
    "    del loss_lane, loss_obj, total_loss, output_lane, output_obj, samples, targets, data_lane\n",
    "' > output.log 2>&1 &\n",
    "echo $! > process_id.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.lib.backgroundjobs import BackgroundJobManager\n",
    "import time\n",
    "\n",
    "jobs = BackgroundJobManager()\n",
    "\n",
    "import time\n",
    "import cv2\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import pytorch_warmup as warmup\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "\n",
    "from clrnet.models.registry import build_net\n",
    "from clrnet.engine.registry import build_trainer, build_evaluator\n",
    "from clrnet.engine.optimizer import build_optimizer\n",
    "from clrnet.engine.scheduler import build_scheduler\n",
    "from clrnet.datasets import build_dataloader\n",
    "from clrnet.utils.recorder import build_recorder\n",
    "from clrnet.utils.net_utils import save_model, load_network, resume_network\n",
    "from clrnet.utils.recorder import build_recorder\n",
    "from mmcv.parallel import MMDataParallel\n",
    "from nets.nn import DarkNet\n",
    "from utils import util\n",
    "\n",
    "import argparse\n",
    "\n",
    "import yaml\n",
    "import os\n",
    "import glob\n",
    "from torch.utils import data\n",
    "\n",
    "\n",
    "# yolo\n",
    "\n",
    "from utils.dataset import Dataset\n",
    "from clrnet.utils.config import Config\n",
    "\n",
    "\n",
    "def long_running_task():\n",
    "    device = 'cuda:0'\n",
    "\n",
    "    cfg = Config.fromfile(\"configs/clrnet/clr_resnet18_culane.py\")\n",
    "    \n",
    "    cfg.load_from = None\n",
    "    cfg.resume_from = None\n",
    "    cfg.finetune_from = None\n",
    "    cfg.view = None\n",
    "    cfg.seed = 0\n",
    "    cfg.gpus = 1\n",
    "    \n",
    "    torch.manual_seed(cfg.seed)\n",
    "    np.random.seed(cfg.seed)\n",
    "    random.seed(cfg.seed)\n",
    "    \n",
    "    train_loader_lane = build_dataloader(cfg.dataset.train,\n",
    "                                        cfg,\n",
    "                                        is_train=True)\n",
    "    \n",
    "    \n",
    "    \n",
    "    parser = argparse.ArgumentParser()\n",
    "    args = parser.parse_args(args=[])\n",
    "    args.input_size = 640\n",
    "    args.batch_size = 32\n",
    "    args.local_rank = 0\n",
    "    args.world_size = 1\n",
    "    args.epoch = 100\n",
    "    \n",
    "    \n",
    "    with open(os.path.join('utils', 'args.yaml'), errors='ignore') as f:\n",
    "        params = yaml.safe_load(f)\n",
    "\n",
    "    folder_path = \"/home/mmm9886/Desktop/Datasets/bdd100k/images/train/\"\n",
    "    filenames = glob.glob(os.path.join(folder_path, '*'))\n",
    "\n",
    "    train_dataset_obj = Dataset(filenames, args.input_size, params, True)\n",
    "    \n",
    "    train_loader_obj = data.DataLoader(train_dataset_obj, 18, False, num_workers=8,\n",
    "                             pin_memory=True, collate_fn=Dataset.collate_fn)\n",
    "    \n",
    "    \n",
    "    \n",
    "    state_dict = torch.load(\"/home/mmm9886/Desktop/Capstone_Implementation/YOLOv8-pt copy 3/weights/best.pt\")\n",
    "    darknet_backbone = state_dict['model'].net\n",
    "    darknet_backbone = darknet_backbone.float()\n",
    "    darknet_backbone = darknet_backbone.to(device)\n",
    "    darknet_neck = state_dict['model'].fpn\n",
    "    darknet_neck = darknet_neck.float()\n",
    "    darknet_neck = darknet_neck.to(device)\n",
    "    darknet_head = state_dict['model'].head\n",
    "    darknet_head = darknet_head.float()\n",
    "    darknet_head = darknet_head.to(device)\n",
    "    \n",
    "    net = build_net(cfg)\n",
    "    \n",
    "    clrnet_head = net.heads\n",
    "    \n",
    "    net = YOLOL(darknet_backbone, darknet_neck, darknet_head, clrnet_head)\n",
    "    \n",
    "    \n",
    "    accumulate = max(round(64 / (args.batch_size * args.world_size)), 1)\n",
    "    net = YOLOL(darknet_backbone, darknet_neck, darknet_head, clrnet_head)\n",
    "    net = net.to(device)\n",
    "\n",
    "    optimizer = build_optimizer(cfg, net)\n",
    "    scheduler = build_scheduler(cfg, optimizer)\n",
    "    criterion_obj = util.ComputeLoss(net, params)\n",
    "\n",
    "    net.train()\n",
    "    end = time.time()\n",
    "    max_iter = len(train_loader_lane)\n",
    "\n",
    "\n",
    "\n",
    "    zipped_dls = zip(train_loader_obj, train_loader_lane)\n",
    "\n",
    "    p_bar = enumerate(zipped_dls)\n",
    "    p_bar = tqdm(p_bar, total=len(train_loader_lane))\n",
    "\n",
    "    # for i, data in enumerate(train_loader_lane):\n",
    "    for i, (data_obj, data_lane) in p_bar:\n",
    "        x = i + max_iter #* epoch\n",
    "        date_time = time.time() - end\n",
    "        samples = data_obj[0].to(device).float() / 255\n",
    "        targets = data_obj[1].to(device)\n",
    "        # data_obj = to_cuda(data_obj)\n",
    "        data_lane = to_cuda(data_lane, device)\n",
    "        output_obj = net(samples, 1)\n",
    "        \n",
    "        \n",
    "        # experiment = net2(data_lane)\n",
    "        output_lane = net(data_lane, 0)\n",
    "        \n",
    "        amp_scale = torch.cuda.amp.GradScaler()\n",
    "        # optimizer.zero_grad()\n",
    "        loss_lane = output_lane['loss'].sum()\n",
    "        loss_obj = criterion_obj(output_obj, targets)\n",
    "        total_loss = loss_lane+loss_obj\n",
    "        p_bar.set_description(str(total_loss))\n",
    "        amp_scale.scale(total_loss).backward()\n",
    "        \n",
    "        if x % accumulate == 0:\n",
    "            amp_scale.unscale_(optimizer)  # unscale gradients\n",
    "            util.clip_gradients(net)  # clip gradients\n",
    "            amp_scale.step(optimizer)  # optimizer.step\n",
    "            amp_scale.update()\n",
    "            optimizer.zero_grad()\n",
    "        # optimizer.step()\n",
    "        del loss_lane, loss_obj, total_loss, output_lane, output_obj, samples, targets, data_lane\n",
    "        \n",
    "jobs.new(long_running_task)\n",
    "\n",
    "print(\"Task started in the background. You can disconnect safely.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.eval()\n",
    "test_obj(args, params, net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.eval()\n",
    "validate_lane(net, recorder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), 'net_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p_bar = enumerate(train_loader_obj)\n",
    "# for i, data in p_bar:\n",
    "#     print(data[1])\n",
    "#     print(\"target\")\n",
    "#     print(target)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zipped_dls = zip(train_loader_obj, train_loader_lane)\n",
    "# # for i, data in enumerate(train_loader_lane):\n",
    "# for i, (data_obj, data_lane) in enumerate(zipped_dls):\n",
    "#     zip = data_obj\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, (samples, target, extra) in p_bar:\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(zip[0].shape)\n",
    "# print(zip[1].shape)\n",
    "# print(len(zip[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(\"yolov8n.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train(\n",
    "            data=\"/home/mmm9886/Desktop/Datasets/bdd100k/bdd100k.yaml\", \n",
    "            project=\"runs/yolo_bdd100k_benchmark\",\n",
    "            epochs=50, \n",
    "            batch=16, \n",
    "            imgsz=640)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "model = YOLO(\"/home/mmm9886/Desktop/Capstone_Implementation/clrnet/runs/yolo_bdd100k_benchmark/train3/weights/best.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.val(conf = 0.25, iou = 0.45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clrnet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
